{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e649671-64ae-4692-a381-33974ffa666a",
   "metadata": {
    "id": "8e649671-64ae-4692-a381-33974ffa666a"
   },
   "source": [
    "# Assignment 3\n",
    "## Econ 8310 - Business Forecasting\n",
    "\n",
    "For homework assignment 3, you will work with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), a more fancier data set.\n",
    "\n",
    "- You must create a custom data loader as described in the first week of neural network lectures [2 points]\n",
    "    - You will NOT receive credit for this if you use the pytorch prebuilt loader for Fashion MNIST!\n",
    "- You must create a working and trained neural network using only pytorch [2 points]\n",
    "- You must store your weights and create an import script so that I can evaluate your model without training it [2 points]\n",
    "\n",
    "Highest accuracy score gets some extra credit!\n",
    "\n",
    "Submit your forked repository URL on Canvas! :) I'll be manually grading this assignment.\n",
    "\n",
    "Some checks you can make on your own:\n",
    "- Did you manually process the data or use a prebuilt loader (see above)?\n",
    "- Does your script train a neural network on the assigned data?\n",
    "- Did your script save your model?\n",
    "- Do you have separate code to import your model for use after training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd35387-b05b-4cb2-9b1f-e1d2c0e43588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcd35387-b05b-4cb2-9b1f-e1d2c0e43588",
    "outputId": "0b5842bc-ab71-40ce-b041-f8c625e04dfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fashion_dataset/t10k-labels-idx1-ubyte.gz',\n",
       " <http.client.HTTPMessage at 0x2dbf2045670>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block is used to download the dataset from the source:\n",
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "# Since the data is already available in the 'fashion_dataset' folder,\n",
    "# it is not necessary to run this part of the code for training.\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "\n",
    "tr_img = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz'\n",
    "tr_labe = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz'\n",
    "te_img = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz'\n",
    "te_labe = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "\n",
    "os.makedirs('fashion_dataset', exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve(tr_img, f'fashion_dataset/train-images-idx3-ubyte.gz')\n",
    "urllib.request.urlretrieve(tr_labe, f'fashion_dataset/train-labels-idx1-ubyte.gz')\n",
    "urllib.request.urlretrieve(te_img, f'fashion_dataset/t10k-images-idx3-ubyte.gz')\n",
    "urllib.request.urlretrieve(te_labe, f'fashion_dataset/t10k-labels-idx1-ubyte.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0WtsPPuVrJ7G",
   "metadata": {
    "id": "0WtsPPuVrJ7G"
   },
   "outputs": [],
   "source": [
    "def Custom_FashionMNIST_Loader(path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"This function reads the Training and Test datasets from the specified 'path'.\"\"\"\n",
    "\n",
    "    # Training\n",
    "    with gzip.open(os.path.join(path, 'train-labels-idx1-ubyte.gz'), 'rb') as lb:\n",
    "        y_train = np.frombuffer(lb.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(os.path.join(path, 'train-images-idx3-ubyte.gz'), 'rb') as img:\n",
    "        X_train = np.frombuffer(img.read(), dtype=np.uint8, offset=16).reshape(len(y_train), 784)\n",
    "\n",
    "    # Test\n",
    "    with gzip.open(os.path.join(path, 't10k-labels-idx1-ubyte.gz'), 'rb') as lb:\n",
    "        y_test = np.frombuffer(lb.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(os.path.join(path, 't10k-images-idx3-ubyte.gz'), 'rb') as img:\n",
    "        X_test = np.frombuffer(img.read(), dtype=np.uint8, offset=16).reshape(len(y_test), 784)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = Custom_FashionMNIST_Loader('fashion_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "EATK1SDcrSoF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "EATK1SDcrSoF",
    "outputId": "d6f31d18-ab22-4371-b38c-44e14769306f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I plotted the data to be sure that the images and labels were correctly loaded.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "random_indices = np.random.choice(len(X_train), size=25, replace=False)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(X_train[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(class_names[y_train[idx]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "islGSqdjr0NV",
   "metadata": {
    "id": "islGSqdjr0NV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, augment=False):\n",
    "        self.images = torch.tensor(images, dtype=torch.float32).reshape(-1, 1, 28, 28) / 255.0\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(10)\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx].cuda(), self.labels[idx].cuda()\n",
    "\n",
    "train_dataset = FashionMNISTDataset(X_train, y_train)\n",
    "test_dataset = FashionMNISTDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "HRl53KEXtaYE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRl53KEXtaYE",
    "outputId": "fc9b6310-21e2-4af8-8699-3ce991be79ca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mroudsari2\\Anaconda33\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "from nnhelpers_modified import train_loop, test_loop, train_net\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, dropout=0.0):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.dropout(Y)\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10, dropout=0.0):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        for i, b in enumerate(arch):\n",
    "            self.net.add_module(f'b{i+2}',\n",
    "                self.block(*b, first_block=(i==0), dropout=dropout))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),nn.Dropout(dropout),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def block(self, num_residuals, num_channels, first_block=False, dropout=0.0):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels,\n",
    "                 use_1x1conv=True, strides=2, dropout=dropout))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels, dropout=dropout))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "class ResNet18(ResNet):\n",
    "    def __init__(self, lr=0.1, num_classes=10, dropout=0.5):\n",
    "        super(ResNet18, self).__init__(((2, 64), (2, 128),\n",
    "         (2, 256), (2, 512)),\n",
    "                       lr, num_classes, dropout=dropout)\n",
    "\n",
    "model = ResNet18().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f8103-af07-4cf0-ba9e-63d6408101df",
   "metadata": {},
   "source": [
    "# Run the next block only to train the dataset and save the model. To load the saved model, use the blocks preceding this section and those following the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8cd845-939a-4c66-919a-f73f8aa8c253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.819378  [   64/60000]\n",
      "loss: 2.651006  [  704/60000]\n",
      "loss: 2.481688  [ 1344/60000]\n",
      "loss: 2.328755  [ 1984/60000]\n",
      "loss: 2.462894  [ 2624/60000]\n",
      "loss: 2.382839  [ 3264/60000]\n",
      "loss: 2.289181  [ 3904/60000]\n",
      "loss: 2.127778  [ 4544/60000]\n",
      "loss: 2.029170  [ 5184/60000]\n",
      "loss: 1.994216  [ 5824/60000]\n",
      "loss: 1.591005  [ 6464/60000]\n",
      "loss: 1.467335  [ 7104/60000]\n",
      "loss: 1.605666  [ 7744/60000]\n",
      "loss: 1.454002  [ 8384/60000]\n",
      "loss: 1.420883  [ 9024/60000]\n",
      "loss: 1.313364  [ 9664/60000]\n",
      "loss: 1.502951  [10304/60000]\n",
      "loss: 1.283563  [10944/60000]\n",
      "loss: 1.317977  [11584/60000]\n",
      "loss: 1.116516  [12224/60000]\n",
      "loss: 1.521580  [12864/60000]\n",
      "loss: 1.106937  [13504/60000]\n",
      "loss: 1.293971  [14144/60000]\n",
      "loss: 0.919304  [14784/60000]\n",
      "loss: 1.031729  [15424/60000]\n",
      "loss: 0.914045  [16064/60000]\n",
      "loss: 1.022111  [16704/60000]\n",
      "loss: 0.832962  [17344/60000]\n",
      "loss: 0.886675  [17984/60000]\n",
      "loss: 0.811860  [18624/60000]\n",
      "loss: 1.015569  [19264/60000]\n",
      "loss: 0.792143  [19904/60000]\n",
      "loss: 0.914088  [20544/60000]\n",
      "loss: 0.736640  [21184/60000]\n",
      "loss: 1.132296  [21824/60000]\n",
      "loss: 0.716451  [22464/60000]\n",
      "loss: 1.233163  [23104/60000]\n",
      "loss: 0.807478  [23744/60000]\n",
      "loss: 0.864639  [24384/60000]\n",
      "loss: 0.752647  [25024/60000]\n",
      "loss: 0.791786  [25664/60000]\n",
      "loss: 0.852367  [26304/60000]\n",
      "loss: 0.717123  [26944/60000]\n",
      "loss: 0.715386  [27584/60000]\n",
      "loss: 0.829650  [28224/60000]\n",
      "loss: 0.660123  [28864/60000]\n",
      "loss: 0.769276  [29504/60000]\n",
      "loss: 0.796738  [30144/60000]\n",
      "loss: 0.918608  [30784/60000]\n",
      "loss: 0.743875  [31424/60000]\n",
      "loss: 0.903811  [32064/60000]\n",
      "loss: 0.826934  [32704/60000]\n",
      "loss: 0.787534  [33344/60000]\n",
      "loss: 0.727308  [33984/60000]\n",
      "loss: 0.790652  [34624/60000]\n",
      "loss: 0.717381  [35264/60000]\n",
      "loss: 0.866956  [35904/60000]\n",
      "loss: 0.615102  [36544/60000]\n",
      "loss: 0.703559  [37184/60000]\n",
      "loss: 0.900441  [37824/60000]\n",
      "loss: 0.703907  [38464/60000]\n",
      "loss: 0.623758  [39104/60000]\n",
      "loss: 0.701500  [39744/60000]\n",
      "loss: 0.586346  [40384/60000]\n",
      "loss: 0.846735  [41024/60000]\n",
      "loss: 0.886158  [41664/60000]\n",
      "loss: 0.700338  [42304/60000]\n",
      "loss: 0.843287  [42944/60000]\n",
      "loss: 0.726283  [43584/60000]\n",
      "loss: 0.724686  [44224/60000]\n",
      "loss: 0.645454  [44864/60000]\n",
      "loss: 0.591298  [45504/60000]\n",
      "loss: 0.630403  [46144/60000]\n",
      "loss: 0.783812  [46784/60000]\n",
      "loss: 0.543195  [47424/60000]\n",
      "loss: 0.713353  [48064/60000]\n",
      "loss: 0.558918  [48704/60000]\n",
      "loss: 0.564700  [49344/60000]\n",
      "loss: 0.574658  [49984/60000]\n",
      "loss: 0.644912  [50624/60000]\n",
      "loss: 0.693979  [51264/60000]\n",
      "loss: 0.612287  [51904/60000]\n",
      "loss: 0.637795  [52544/60000]\n",
      "loss: 0.660091  [53184/60000]\n",
      "loss: 0.599023  [53824/60000]\n",
      "loss: 0.673573  [54464/60000]\n",
      "loss: 0.821346  [55104/60000]\n",
      "loss: 0.739443  [55744/60000]\n",
      "loss: 0.611737  [56384/60000]\n",
      "loss: 0.516653  [57024/60000]\n",
      "loss: 0.785762  [57664/60000]\n",
      "loss: 0.559270  [58304/60000]\n",
      "loss: 0.561556  [58944/60000]\n",
      "loss: 0.502072  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.542251 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.854839  [   64/60000]\n",
      "loss: 0.398606  [  704/60000]\n",
      "loss: 0.336694  [ 1344/60000]\n",
      "loss: 0.587741  [ 1984/60000]\n",
      "loss: 0.615152  [ 2624/60000]\n",
      "loss: 0.727651  [ 3264/60000]\n",
      "loss: 0.880667  [ 3904/60000]\n",
      "loss: 0.440611  [ 4544/60000]\n",
      "loss: 0.769262  [ 5184/60000]\n",
      "loss: 0.479016  [ 5824/60000]\n",
      "loss: 0.713803  [ 6464/60000]\n",
      "loss: 0.610664  [ 7104/60000]\n",
      "loss: 0.841074  [ 7744/60000]\n",
      "loss: 0.658820  [ 8384/60000]\n",
      "loss: 0.772138  [ 9024/60000]\n",
      "loss: 0.656591  [ 9664/60000]\n",
      "loss: 0.605568  [10304/60000]\n",
      "loss: 0.624452  [10944/60000]\n",
      "loss: 0.490320  [11584/60000]\n",
      "loss: 0.553599  [12224/60000]\n",
      "loss: 0.553543  [12864/60000]\n",
      "loss: 0.434179  [13504/60000]\n",
      "loss: 0.684978  [14144/60000]\n",
      "loss: 0.541570  [14784/60000]\n",
      "loss: 0.927399  [15424/60000]\n",
      "loss: 0.553798  [16064/60000]\n",
      "loss: 0.548180  [16704/60000]\n",
      "loss: 0.746599  [17344/60000]\n",
      "loss: 0.675794  [17984/60000]\n",
      "loss: 0.620030  [18624/60000]\n",
      "loss: 0.363619  [19264/60000]\n",
      "loss: 0.492029  [19904/60000]\n",
      "loss: 0.619770  [20544/60000]\n",
      "loss: 0.402685  [21184/60000]\n",
      "loss: 0.415563  [21824/60000]\n",
      "loss: 0.747994  [22464/60000]\n",
      "loss: 0.586643  [23104/60000]\n",
      "loss: 0.552970  [23744/60000]\n",
      "loss: 0.501812  [24384/60000]\n",
      "loss: 0.674349  [25024/60000]\n",
      "loss: 0.482532  [25664/60000]\n",
      "loss: 0.471106  [26304/60000]\n",
      "loss: 0.464336  [26944/60000]\n",
      "loss: 0.525008  [27584/60000]\n",
      "loss: 0.374835  [28224/60000]\n",
      "loss: 0.344731  [28864/60000]\n",
      "loss: 0.524970  [29504/60000]\n",
      "loss: 0.462738  [30144/60000]\n",
      "loss: 0.623299  [30784/60000]\n",
      "loss: 0.650204  [31424/60000]\n",
      "loss: 0.390548  [32064/60000]\n",
      "loss: 0.501075  [32704/60000]\n",
      "loss: 0.788770  [33344/60000]\n",
      "loss: 0.521951  [33984/60000]\n",
      "loss: 0.798981  [34624/60000]\n",
      "loss: 0.508700  [35264/60000]\n",
      "loss: 0.424351  [35904/60000]\n",
      "loss: 0.412577  [36544/60000]\n",
      "loss: 0.447795  [37184/60000]\n",
      "loss: 0.589748  [37824/60000]\n",
      "loss: 0.646965  [38464/60000]\n",
      "loss: 0.553732  [39104/60000]\n",
      "loss: 0.487657  [39744/60000]\n",
      "loss: 0.769342  [40384/60000]\n",
      "loss: 0.444253  [41024/60000]\n",
      "loss: 0.428884  [41664/60000]\n",
      "loss: 0.447757  [42304/60000]\n",
      "loss: 0.603397  [42944/60000]\n",
      "loss: 0.535828  [43584/60000]\n",
      "loss: 0.516052  [44224/60000]\n",
      "loss: 0.614842  [44864/60000]\n",
      "loss: 0.626013  [45504/60000]\n",
      "loss: 0.542729  [46144/60000]\n",
      "loss: 0.408597  [46784/60000]\n",
      "loss: 0.640086  [47424/60000]\n",
      "loss: 0.359251  [48064/60000]\n",
      "loss: 0.732321  [48704/60000]\n",
      "loss: 0.658516  [49344/60000]\n",
      "loss: 0.441238  [49984/60000]\n",
      "loss: 0.487602  [50624/60000]\n",
      "loss: 0.495813  [51264/60000]\n",
      "loss: 0.411072  [51904/60000]\n",
      "loss: 0.407558  [52544/60000]\n",
      "loss: 0.703108  [53184/60000]\n",
      "loss: 0.353900  [53824/60000]\n",
      "loss: 0.690446  [54464/60000]\n",
      "loss: 0.538664  [55104/60000]\n",
      "loss: 0.407192  [55744/60000]\n",
      "loss: 0.417666  [56384/60000]\n",
      "loss: 0.389121  [57024/60000]\n",
      "loss: 0.494073  [57664/60000]\n",
      "loss: 0.448652  [58304/60000]\n",
      "loss: 0.466317  [58944/60000]\n",
      "loss: 0.379003  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.433007 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.678639  [   64/60000]\n",
      "loss: 0.251471  [  704/60000]\n",
      "loss: 0.322743  [ 1344/60000]\n",
      "loss: 0.232546  [ 1984/60000]\n",
      "loss: 0.333192  [ 2624/60000]\n",
      "loss: 0.370178  [ 3264/60000]\n",
      "loss: 0.374485  [ 3904/60000]\n",
      "loss: 0.510183  [ 4544/60000]\n",
      "loss: 0.543844  [ 5184/60000]\n",
      "loss: 0.775046  [ 5824/60000]\n",
      "loss: 0.411865  [ 6464/60000]\n",
      "loss: 0.470301  [ 7104/60000]\n",
      "loss: 0.407483  [ 7744/60000]\n",
      "loss: 0.329642  [ 8384/60000]\n",
      "loss: 0.408136  [ 9024/60000]\n",
      "loss: 0.252446  [ 9664/60000]\n",
      "loss: 0.323121  [10304/60000]\n",
      "loss: 0.406342  [10944/60000]\n",
      "loss: 0.402533  [11584/60000]\n",
      "loss: 0.478408  [12224/60000]\n",
      "loss: 0.360559  [12864/60000]\n",
      "loss: 0.578136  [13504/60000]\n",
      "loss: 0.349778  [14144/60000]\n",
      "loss: 0.379344  [14784/60000]\n",
      "loss: 0.368686  [15424/60000]\n",
      "loss: 0.621009  [16064/60000]\n",
      "loss: 0.327838  [16704/60000]\n",
      "loss: 0.585695  [17344/60000]\n",
      "loss: 0.608354  [17984/60000]\n",
      "loss: 0.468027  [18624/60000]\n",
      "loss: 0.693550  [19264/60000]\n",
      "loss: 0.575311  [19904/60000]\n",
      "loss: 0.444799  [20544/60000]\n",
      "loss: 0.487441  [21184/60000]\n",
      "loss: 0.518082  [21824/60000]\n",
      "loss: 0.597435  [22464/60000]\n",
      "loss: 0.478260  [23104/60000]\n",
      "loss: 0.367656  [23744/60000]\n",
      "loss: 0.468936  [24384/60000]\n",
      "loss: 0.568794  [25024/60000]\n",
      "loss: 0.384635  [25664/60000]\n",
      "loss: 0.508462  [26304/60000]\n",
      "loss: 0.437030  [26944/60000]\n",
      "loss: 0.366377  [27584/60000]\n",
      "loss: 0.280836  [28224/60000]\n",
      "loss: 0.544781  [28864/60000]\n",
      "loss: 0.484641  [29504/60000]\n",
      "loss: 0.550249  [30144/60000]\n",
      "loss: 0.630048  [30784/60000]\n",
      "loss: 0.424424  [31424/60000]\n",
      "loss: 0.373246  [32064/60000]\n",
      "loss: 0.417078  [32704/60000]\n",
      "loss: 0.372910  [33344/60000]\n",
      "loss: 0.493378  [33984/60000]\n",
      "loss: 0.519928  [34624/60000]\n",
      "loss: 0.366218  [35264/60000]\n",
      "loss: 0.386857  [35904/60000]\n",
      "loss: 0.546054  [36544/60000]\n",
      "loss: 0.322983  [37184/60000]\n",
      "loss: 0.426416  [37824/60000]\n",
      "loss: 0.367877  [38464/60000]\n",
      "loss: 0.582081  [39104/60000]\n",
      "loss: 0.524707  [39744/60000]\n",
      "loss: 0.367240  [40384/60000]\n",
      "loss: 0.638527  [41024/60000]\n",
      "loss: 0.429667  [41664/60000]\n",
      "loss: 0.466560  [42304/60000]\n",
      "loss: 0.432671  [42944/60000]\n",
      "loss: 0.306162  [43584/60000]\n",
      "loss: 0.360740  [44224/60000]\n",
      "loss: 0.436206  [44864/60000]\n",
      "loss: 0.458829  [45504/60000]\n",
      "loss: 0.426143  [46144/60000]\n",
      "loss: 0.278461  [46784/60000]\n",
      "loss: 0.555140  [47424/60000]\n",
      "loss: 0.352315  [48064/60000]\n",
      "loss: 0.371957  [48704/60000]\n",
      "loss: 0.584152  [49344/60000]\n",
      "loss: 0.395918  [49984/60000]\n",
      "loss: 0.458552  [50624/60000]\n",
      "loss: 0.395876  [51264/60000]\n",
      "loss: 0.524099  [51904/60000]\n",
      "loss: 0.485662  [52544/60000]\n",
      "loss: 0.472142  [53184/60000]\n",
      "loss: 0.363458  [53824/60000]\n",
      "loss: 0.388979  [54464/60000]\n",
      "loss: 0.652170  [55104/60000]\n",
      "loss: 0.468550  [55744/60000]\n",
      "loss: 0.327542  [56384/60000]\n",
      "loss: 0.474327  [57024/60000]\n",
      "loss: 0.409185  [57664/60000]\n",
      "loss: 0.321615  [58304/60000]\n",
      "loss: 0.394061  [58944/60000]\n",
      "loss: 0.335340  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.388200 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.399704  [   64/60000]\n",
      "loss: 0.280133  [  704/60000]\n",
      "loss: 0.386055  [ 1344/60000]\n",
      "loss: 0.241889  [ 1984/60000]\n",
      "loss: 0.316504  [ 2624/60000]\n",
      "loss: 0.234066  [ 3264/60000]\n",
      "loss: 0.367653  [ 3904/60000]\n",
      "loss: 0.329162  [ 4544/60000]\n",
      "loss: 0.312222  [ 5184/60000]\n",
      "loss: 0.392492  [ 5824/60000]\n",
      "loss: 0.320124  [ 6464/60000]\n",
      "loss: 0.433346  [ 7104/60000]\n",
      "loss: 0.316308  [ 7744/60000]\n",
      "loss: 0.400535  [ 8384/60000]\n",
      "loss: 0.349084  [ 9024/60000]\n",
      "loss: 0.312040  [ 9664/60000]\n",
      "loss: 0.420303  [10304/60000]\n",
      "loss: 0.376213  [10944/60000]\n",
      "loss: 0.439437  [11584/60000]\n",
      "loss: 0.442633  [12224/60000]\n",
      "loss: 0.425835  [12864/60000]\n",
      "loss: 0.408781  [13504/60000]\n",
      "loss: 0.257933  [14144/60000]\n",
      "loss: 0.383326  [14784/60000]\n",
      "loss: 0.483013  [15424/60000]\n",
      "loss: 0.202577  [16064/60000]\n",
      "loss: 0.461376  [16704/60000]\n",
      "loss: 0.458351  [17344/60000]\n",
      "loss: 0.467858  [17984/60000]\n",
      "loss: 0.369822  [18624/60000]\n",
      "loss: 0.467517  [19264/60000]\n",
      "loss: 0.359967  [19904/60000]\n",
      "loss: 0.328442  [20544/60000]\n",
      "loss: 0.473299  [21184/60000]\n",
      "loss: 0.371692  [21824/60000]\n",
      "loss: 0.323320  [22464/60000]\n",
      "loss: 0.429993  [23104/60000]\n",
      "loss: 0.532263  [23744/60000]\n",
      "loss: 0.533809  [24384/60000]\n",
      "loss: 0.282078  [25024/60000]\n",
      "loss: 0.434282  [25664/60000]\n",
      "loss: 0.500705  [26304/60000]\n",
      "loss: 0.432365  [26944/60000]\n",
      "loss: 0.325991  [27584/60000]\n",
      "loss: 0.497779  [28224/60000]\n",
      "loss: 0.283044  [28864/60000]\n",
      "loss: 0.620194  [29504/60000]\n",
      "loss: 0.373928  [30144/60000]\n",
      "loss: 0.522232  [30784/60000]\n",
      "loss: 0.429589  [31424/60000]\n",
      "loss: 0.248678  [32064/60000]\n",
      "loss: 0.622154  [32704/60000]\n",
      "loss: 0.527284  [33344/60000]\n",
      "loss: 0.498116  [33984/60000]\n",
      "loss: 0.413588  [34624/60000]\n",
      "loss: 0.349644  [35264/60000]\n",
      "loss: 0.415461  [35904/60000]\n",
      "loss: 0.398758  [36544/60000]\n",
      "loss: 0.447284  [37184/60000]\n",
      "loss: 0.416919  [37824/60000]\n",
      "loss: 0.518615  [38464/60000]\n",
      "loss: 0.251592  [39104/60000]\n",
      "loss: 0.554188  [39744/60000]\n",
      "loss: 0.301639  [40384/60000]\n",
      "loss: 0.419467  [41024/60000]\n",
      "loss: 0.503267  [41664/60000]\n",
      "loss: 0.340925  [42304/60000]\n",
      "loss: 0.386926  [42944/60000]\n",
      "loss: 0.458656  [43584/60000]\n",
      "loss: 0.452465  [44224/60000]\n",
      "loss: 0.304767  [44864/60000]\n",
      "loss: 0.482588  [45504/60000]\n",
      "loss: 0.497750  [46144/60000]\n",
      "loss: 0.226162  [46784/60000]\n",
      "loss: 0.270164  [47424/60000]\n",
      "loss: 0.346634  [48064/60000]\n",
      "loss: 0.509609  [48704/60000]\n",
      "loss: 0.268727  [49344/60000]\n",
      "loss: 0.362854  [49984/60000]\n",
      "loss: 0.383692  [50624/60000]\n",
      "loss: 0.382394  [51264/60000]\n",
      "loss: 0.173650  [51904/60000]\n",
      "loss: 0.431025  [52544/60000]\n",
      "loss: 0.477649  [53184/60000]\n",
      "loss: 0.570186  [53824/60000]\n",
      "loss: 0.331128  [54464/60000]\n",
      "loss: 0.265942  [55104/60000]\n",
      "loss: 0.408158  [55744/60000]\n",
      "loss: 0.502180  [56384/60000]\n",
      "loss: 0.451503  [57024/60000]\n",
      "loss: 0.258508  [57664/60000]\n",
      "loss: 0.330023  [58304/60000]\n",
      "loss: 0.278781  [58944/60000]\n",
      "loss: 0.476000  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.349833 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.359475  [   64/60000]\n",
      "loss: 0.275333  [  704/60000]\n",
      "loss: 0.255851  [ 1344/60000]\n",
      "loss: 0.152907  [ 1984/60000]\n",
      "loss: 0.472016  [ 2624/60000]\n",
      "loss: 0.482194  [ 3264/60000]\n",
      "loss: 0.236481  [ 3904/60000]\n",
      "loss: 0.263856  [ 4544/60000]\n",
      "loss: 0.375214  [ 5184/60000]\n",
      "loss: 0.245348  [ 5824/60000]\n",
      "loss: 0.141417  [ 6464/60000]\n",
      "loss: 0.453339  [ 7104/60000]\n",
      "loss: 0.224769  [ 7744/60000]\n",
      "loss: 0.221798  [ 8384/60000]\n",
      "loss: 0.267448  [ 9024/60000]\n",
      "loss: 0.600992  [ 9664/60000]\n",
      "loss: 0.409907  [10304/60000]\n",
      "loss: 0.234898  [10944/60000]\n",
      "loss: 0.236973  [11584/60000]\n",
      "loss: 0.216403  [12224/60000]\n",
      "loss: 0.326976  [12864/60000]\n",
      "loss: 0.260209  [13504/60000]\n",
      "loss: 0.338195  [14144/60000]\n",
      "loss: 0.373935  [14784/60000]\n",
      "loss: 0.388710  [15424/60000]\n",
      "loss: 0.533945  [16064/60000]\n",
      "loss: 0.338885  [16704/60000]\n",
      "loss: 0.477848  [17344/60000]\n",
      "loss: 0.406788  [17984/60000]\n",
      "loss: 0.345110  [18624/60000]\n",
      "loss: 0.203043  [19264/60000]\n",
      "loss: 0.508646  [19904/60000]\n",
      "loss: 0.422855  [20544/60000]\n",
      "loss: 0.359652  [21184/60000]\n",
      "loss: 0.304880  [21824/60000]\n",
      "loss: 0.361321  [22464/60000]\n",
      "loss: 0.259841  [23104/60000]\n",
      "loss: 0.372628  [23744/60000]\n",
      "loss: 0.268906  [24384/60000]\n",
      "loss: 0.396702  [25024/60000]\n",
      "loss: 0.357685  [25664/60000]\n",
      "loss: 0.424062  [26304/60000]\n",
      "loss: 0.226353  [26944/60000]\n",
      "loss: 0.177505  [27584/60000]\n",
      "loss: 0.398815  [28224/60000]\n",
      "loss: 0.361972  [28864/60000]\n",
      "loss: 0.406547  [29504/60000]\n",
      "loss: 0.323544  [30144/60000]\n",
      "loss: 0.297773  [30784/60000]\n",
      "loss: 0.637184  [31424/60000]\n",
      "loss: 0.330149  [32064/60000]\n",
      "loss: 0.426522  [32704/60000]\n",
      "loss: 0.308130  [33344/60000]\n",
      "loss: 0.502893  [33984/60000]\n",
      "loss: 0.230437  [34624/60000]\n",
      "loss: 0.206250  [35264/60000]\n",
      "loss: 0.281606  [35904/60000]\n",
      "loss: 0.344213  [36544/60000]\n",
      "loss: 0.174490  [37184/60000]\n",
      "loss: 0.303355  [37824/60000]\n",
      "loss: 0.202299  [38464/60000]\n",
      "loss: 0.368100  [39104/60000]\n",
      "loss: 0.278371  [39744/60000]\n",
      "loss: 0.713780  [40384/60000]\n",
      "loss: 0.500157  [41024/60000]\n",
      "loss: 0.180666  [41664/60000]\n",
      "loss: 0.333019  [42304/60000]\n",
      "loss: 0.226932  [42944/60000]\n",
      "loss: 0.354206  [43584/60000]\n",
      "loss: 0.188686  [44224/60000]\n",
      "loss: 0.331818  [44864/60000]\n",
      "loss: 0.521166  [45504/60000]\n",
      "loss: 0.282981  [46144/60000]\n",
      "loss: 0.352327  [46784/60000]\n",
      "loss: 0.304152  [47424/60000]\n",
      "loss: 0.477007  [48064/60000]\n",
      "loss: 0.291353  [48704/60000]\n",
      "loss: 0.332756  [49344/60000]\n",
      "loss: 0.347492  [49984/60000]\n",
      "loss: 0.334926  [50624/60000]\n",
      "loss: 0.512693  [51264/60000]\n",
      "loss: 0.327492  [51904/60000]\n",
      "loss: 0.304398  [52544/60000]\n",
      "loss: 0.318364  [53184/60000]\n",
      "loss: 0.304617  [53824/60000]\n",
      "loss: 0.216619  [54464/60000]\n",
      "loss: 0.526059  [55104/60000]\n",
      "loss: 0.290615  [55744/60000]\n",
      "loss: 0.231952  [56384/60000]\n",
      "loss: 0.308684  [57024/60000]\n",
      "loss: 0.384824  [57664/60000]\n",
      "loss: 0.239179  [58304/60000]\n",
      "loss: 0.385635  [58944/60000]\n",
      "loss: 0.450655  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.334481 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.260081  [   64/60000]\n",
      "loss: 0.360039  [  704/60000]\n",
      "loss: 0.338016  [ 1344/60000]\n",
      "loss: 0.324468  [ 1984/60000]\n",
      "loss: 0.339748  [ 2624/60000]\n",
      "loss: 0.387690  [ 3264/60000]\n",
      "loss: 0.342956  [ 3904/60000]\n",
      "loss: 0.344614  [ 4544/60000]\n",
      "loss: 0.408758  [ 5184/60000]\n",
      "loss: 0.462516  [ 5824/60000]\n",
      "loss: 0.344898  [ 6464/60000]\n",
      "loss: 0.510282  [ 7104/60000]\n",
      "loss: 0.465080  [ 7744/60000]\n",
      "loss: 0.427360  [ 8384/60000]\n",
      "loss: 0.424789  [ 9024/60000]\n",
      "loss: 0.309269  [ 9664/60000]\n",
      "loss: 0.203517  [10304/60000]\n",
      "loss: 0.209997  [10944/60000]\n",
      "loss: 0.312725  [11584/60000]\n",
      "loss: 0.331948  [12224/60000]\n",
      "loss: 0.210515  [12864/60000]\n",
      "loss: 0.300523  [13504/60000]\n",
      "loss: 0.309567  [14144/60000]\n",
      "loss: 0.447302  [14784/60000]\n",
      "loss: 0.246077  [15424/60000]\n",
      "loss: 0.241223  [16064/60000]\n",
      "loss: 0.313463  [16704/60000]\n",
      "loss: 0.330260  [17344/60000]\n",
      "loss: 0.418880  [17984/60000]\n",
      "loss: 0.190624  [18624/60000]\n",
      "loss: 0.324779  [19264/60000]\n",
      "loss: 0.249924  [19904/60000]\n",
      "loss: 0.323214  [20544/60000]\n",
      "loss: 0.278929  [21184/60000]\n",
      "loss: 0.360244  [21824/60000]\n",
      "loss: 0.383106  [22464/60000]\n",
      "loss: 0.304216  [23104/60000]\n",
      "loss: 0.276994  [23744/60000]\n",
      "loss: 0.438111  [24384/60000]\n",
      "loss: 0.214473  [25024/60000]\n",
      "loss: 0.333542  [25664/60000]\n",
      "loss: 0.225834  [26304/60000]\n",
      "loss: 0.245978  [26944/60000]\n",
      "loss: 0.361058  [27584/60000]\n",
      "loss: 0.153699  [28224/60000]\n",
      "loss: 0.202525  [28864/60000]\n",
      "loss: 0.282291  [29504/60000]\n",
      "loss: 0.221210  [30144/60000]\n",
      "loss: 0.194380  [30784/60000]\n",
      "loss: 0.245354  [31424/60000]\n",
      "loss: 0.375932  [32064/60000]\n",
      "loss: 0.295576  [32704/60000]\n",
      "loss: 0.403778  [33344/60000]\n",
      "loss: 0.317262  [33984/60000]\n",
      "loss: 0.366681  [34624/60000]\n",
      "loss: 0.478532  [35264/60000]\n",
      "loss: 0.411382  [35904/60000]\n",
      "loss: 0.260652  [36544/60000]\n",
      "loss: 0.257990  [37184/60000]\n",
      "loss: 0.384193  [37824/60000]\n",
      "loss: 0.469972  [38464/60000]\n",
      "loss: 0.307264  [39104/60000]\n",
      "loss: 0.340683  [39744/60000]\n",
      "loss: 0.246449  [40384/60000]\n",
      "loss: 0.172515  [41024/60000]\n",
      "loss: 0.327169  [41664/60000]\n",
      "loss: 0.299776  [42304/60000]\n",
      "loss: 0.513178  [42944/60000]\n",
      "loss: 0.279465  [43584/60000]\n",
      "loss: 0.254872  [44224/60000]\n",
      "loss: 0.388038  [44864/60000]\n",
      "loss: 0.174175  [45504/60000]\n",
      "loss: 0.583058  [46144/60000]\n",
      "loss: 0.410707  [46784/60000]\n",
      "loss: 0.275023  [47424/60000]\n",
      "loss: 0.265045  [48064/60000]\n",
      "loss: 0.298140  [48704/60000]\n",
      "loss: 0.303831  [49344/60000]\n",
      "loss: 0.310150  [49984/60000]\n",
      "loss: 0.308695  [50624/60000]\n",
      "loss: 0.412161  [51264/60000]\n",
      "loss: 0.364228  [51904/60000]\n",
      "loss: 0.521353  [52544/60000]\n",
      "loss: 0.402091  [53184/60000]\n",
      "loss: 0.359020  [53824/60000]\n",
      "loss: 0.355197  [54464/60000]\n",
      "loss: 0.254950  [55104/60000]\n",
      "loss: 0.273990  [55744/60000]\n",
      "loss: 0.296048  [56384/60000]\n",
      "loss: 0.317401  [57024/60000]\n",
      "loss: 0.508384  [57664/60000]\n",
      "loss: 0.281683  [58304/60000]\n",
      "loss: 0.274437  [58944/60000]\n",
      "loss: 0.204301  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.317385 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.211707  [   64/60000]\n",
      "loss: 0.197479  [  704/60000]\n",
      "loss: 0.303942  [ 1344/60000]\n",
      "loss: 0.226370  [ 1984/60000]\n",
      "loss: 0.298665  [ 2624/60000]\n",
      "loss: 0.297566  [ 3264/60000]\n",
      "loss: 0.425365  [ 3904/60000]\n",
      "loss: 0.389321  [ 4544/60000]\n",
      "loss: 0.317316  [ 5184/60000]\n",
      "loss: 0.239308  [ 5824/60000]\n",
      "loss: 0.450004  [ 6464/60000]\n",
      "loss: 0.374655  [ 7104/60000]\n",
      "loss: 0.431964  [ 7744/60000]\n",
      "loss: 0.317828  [ 8384/60000]\n",
      "loss: 0.293460  [ 9024/60000]\n",
      "loss: 0.387590  [ 9664/60000]\n",
      "loss: 0.221979  [10304/60000]\n",
      "loss: 0.493477  [10944/60000]\n",
      "loss: 0.259420  [11584/60000]\n",
      "loss: 0.341423  [12224/60000]\n",
      "loss: 0.333837  [12864/60000]\n",
      "loss: 0.161270  [13504/60000]\n",
      "loss: 0.246975  [14144/60000]\n",
      "loss: 0.216121  [14784/60000]\n",
      "loss: 0.301400  [15424/60000]\n",
      "loss: 0.378887  [16064/60000]\n",
      "loss: 0.413195  [16704/60000]\n",
      "loss: 0.539631  [17344/60000]\n",
      "loss: 0.475621  [17984/60000]\n",
      "loss: 0.430527  [18624/60000]\n",
      "loss: 0.495309  [19264/60000]\n",
      "loss: 0.312184  [19904/60000]\n",
      "loss: 0.325906  [20544/60000]\n",
      "loss: 0.449982  [21184/60000]\n",
      "loss: 0.174794  [21824/60000]\n",
      "loss: 0.167960  [22464/60000]\n",
      "loss: 0.494659  [23104/60000]\n",
      "loss: 0.135957  [23744/60000]\n",
      "loss: 0.295437  [24384/60000]\n",
      "loss: 0.351650  [25024/60000]\n",
      "loss: 0.264635  [25664/60000]\n",
      "loss: 0.426141  [26304/60000]\n",
      "loss: 0.540669  [26944/60000]\n",
      "loss: 0.296898  [27584/60000]\n",
      "loss: 0.408020  [28224/60000]\n",
      "loss: 0.219520  [28864/60000]\n",
      "loss: 0.235324  [29504/60000]\n",
      "loss: 0.180613  [30144/60000]\n",
      "loss: 0.245734  [30784/60000]\n",
      "loss: 0.109730  [31424/60000]\n",
      "loss: 0.392920  [32064/60000]\n",
      "loss: 0.383732  [32704/60000]\n",
      "loss: 0.344662  [33344/60000]\n",
      "loss: 0.322362  [33984/60000]\n",
      "loss: 0.373896  [34624/60000]\n",
      "loss: 0.261076  [35264/60000]\n",
      "loss: 0.187606  [35904/60000]\n",
      "loss: 0.306161  [36544/60000]\n",
      "loss: 0.313079  [37184/60000]\n",
      "loss: 0.308171  [37824/60000]\n",
      "loss: 0.181509  [38464/60000]\n",
      "loss: 0.377075  [39104/60000]\n",
      "loss: 0.323360  [39744/60000]\n",
      "loss: 0.254685  [40384/60000]\n",
      "loss: 0.282647  [41024/60000]\n",
      "loss: 0.429851  [41664/60000]\n",
      "loss: 0.284305  [42304/60000]\n",
      "loss: 0.378452  [42944/60000]\n",
      "loss: 0.200125  [43584/60000]\n",
      "loss: 0.343352  [44224/60000]\n",
      "loss: 0.343067  [44864/60000]\n",
      "loss: 0.250389  [45504/60000]\n",
      "loss: 0.388597  [46144/60000]\n",
      "loss: 0.489275  [46784/60000]\n",
      "loss: 0.477924  [47424/60000]\n",
      "loss: 0.302874  [48064/60000]\n",
      "loss: 0.267048  [48704/60000]\n",
      "loss: 0.182729  [49344/60000]\n",
      "loss: 0.282947  [49984/60000]\n",
      "loss: 0.204441  [50624/60000]\n",
      "loss: 0.226557  [51264/60000]\n",
      "loss: 0.388868  [51904/60000]\n",
      "loss: 0.232456  [52544/60000]\n",
      "loss: 0.286368  [53184/60000]\n",
      "loss: 0.299584  [53824/60000]\n",
      "loss: 0.276331  [54464/60000]\n",
      "loss: 0.213020  [55104/60000]\n",
      "loss: 0.293160  [55744/60000]\n",
      "loss: 0.288254  [56384/60000]\n",
      "loss: 0.271094  [57024/60000]\n",
      "loss: 0.228076  [57664/60000]\n",
      "loss: 0.307151  [58304/60000]\n",
      "loss: 0.186367  [58944/60000]\n",
      "loss: 0.371785  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.304249 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.299858  [   64/60000]\n",
      "loss: 0.374843  [  704/60000]\n",
      "loss: 0.269379  [ 1344/60000]\n",
      "loss: 0.377886  [ 1984/60000]\n",
      "loss: 0.304519  [ 2624/60000]\n",
      "loss: 0.252077  [ 3264/60000]\n",
      "loss: 0.230741  [ 3904/60000]\n",
      "loss: 0.220930  [ 4544/60000]\n",
      "loss: 0.257369  [ 5184/60000]\n",
      "loss: 0.119239  [ 5824/60000]\n",
      "loss: 0.346976  [ 6464/60000]\n",
      "loss: 0.410137  [ 7104/60000]\n",
      "loss: 0.199927  [ 7744/60000]\n",
      "loss: 0.391044  [ 8384/60000]\n",
      "loss: 0.280908  [ 9024/60000]\n",
      "loss: 0.325829  [ 9664/60000]\n",
      "loss: 0.331660  [10304/60000]\n",
      "loss: 0.194552  [10944/60000]\n",
      "loss: 0.280261  [11584/60000]\n",
      "loss: 0.299316  [12224/60000]\n",
      "loss: 0.132549  [12864/60000]\n",
      "loss: 0.194173  [13504/60000]\n",
      "loss: 0.305034  [14144/60000]\n",
      "loss: 0.352048  [14784/60000]\n",
      "loss: 0.303499  [15424/60000]\n",
      "loss: 0.263813  [16064/60000]\n",
      "loss: 0.370159  [16704/60000]\n",
      "loss: 0.310270  [17344/60000]\n",
      "loss: 0.337913  [17984/60000]\n",
      "loss: 0.400110  [18624/60000]\n",
      "loss: 0.362187  [19264/60000]\n",
      "loss: 0.206868  [19904/60000]\n",
      "loss: 0.200551  [20544/60000]\n",
      "loss: 0.416962  [21184/60000]\n",
      "loss: 0.334286  [21824/60000]\n",
      "loss: 0.210808  [22464/60000]\n",
      "loss: 0.224444  [23104/60000]\n",
      "loss: 0.439467  [23744/60000]\n",
      "loss: 0.422199  [24384/60000]\n",
      "loss: 0.166527  [25024/60000]\n",
      "loss: 0.343349  [25664/60000]\n",
      "loss: 0.173950  [26304/60000]\n",
      "loss: 0.296951  [26944/60000]\n",
      "loss: 0.368570  [27584/60000]\n",
      "loss: 0.290150  [28224/60000]\n",
      "loss: 0.367147  [28864/60000]\n",
      "loss: 0.318097  [29504/60000]\n",
      "loss: 0.262021  [30144/60000]\n",
      "loss: 0.468236  [30784/60000]\n",
      "loss: 0.270020  [31424/60000]\n",
      "loss: 0.311081  [32064/60000]\n",
      "loss: 0.219081  [32704/60000]\n",
      "loss: 0.373684  [33344/60000]\n",
      "loss: 0.581931  [33984/60000]\n",
      "loss: 0.255546  [34624/60000]\n",
      "loss: 0.291655  [35264/60000]\n",
      "loss: 0.262661  [35904/60000]\n",
      "loss: 0.358291  [36544/60000]\n",
      "loss: 0.543829  [37184/60000]\n",
      "loss: 0.504967  [37824/60000]\n",
      "loss: 0.360053  [38464/60000]\n",
      "loss: 0.457319  [39104/60000]\n",
      "loss: 0.182818  [39744/60000]\n",
      "loss: 0.206339  [40384/60000]\n",
      "loss: 0.226011  [41024/60000]\n",
      "loss: 0.252900  [41664/60000]\n",
      "loss: 0.281811  [42304/60000]\n",
      "loss: 0.287418  [42944/60000]\n",
      "loss: 0.219064  [43584/60000]\n",
      "loss: 0.377179  [44224/60000]\n",
      "loss: 0.443450  [44864/60000]\n",
      "loss: 0.398820  [45504/60000]\n",
      "loss: 0.255250  [46144/60000]\n",
      "loss: 0.379967  [46784/60000]\n",
      "loss: 0.295577  [47424/60000]\n",
      "loss: 0.260270  [48064/60000]\n",
      "loss: 0.226278  [48704/60000]\n",
      "loss: 0.234623  [49344/60000]\n",
      "loss: 0.166717  [49984/60000]\n",
      "loss: 0.345700  [50624/60000]\n",
      "loss: 0.178533  [51264/60000]\n",
      "loss: 0.311196  [51904/60000]\n",
      "loss: 0.200525  [52544/60000]\n",
      "loss: 0.260886  [53184/60000]\n",
      "loss: 0.305706  [53824/60000]\n",
      "loss: 0.287825  [54464/60000]\n",
      "loss: 0.272511  [55104/60000]\n",
      "loss: 0.214771  [55744/60000]\n",
      "loss: 0.211884  [56384/60000]\n",
      "loss: 0.329314  [57024/60000]\n",
      "loss: 0.328497  [57664/60000]\n",
      "loss: 0.318937  [58304/60000]\n",
      "loss: 0.359274  [58944/60000]\n",
      "loss: 0.431276  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.295202 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.336789  [   64/60000]\n",
      "loss: 0.163927  [  704/60000]\n",
      "loss: 0.316636  [ 1344/60000]\n",
      "loss: 0.279424  [ 1984/60000]\n",
      "loss: 0.219102  [ 2624/60000]\n",
      "loss: 0.281881  [ 3264/60000]\n",
      "loss: 0.272622  [ 3904/60000]\n",
      "loss: 0.199822  [ 4544/60000]\n",
      "loss: 0.208037  [ 5184/60000]\n",
      "loss: 0.224419  [ 5824/60000]\n",
      "loss: 0.235794  [ 6464/60000]\n",
      "loss: 0.213722  [ 7104/60000]\n",
      "loss: 0.264729  [ 7744/60000]\n",
      "loss: 0.234826  [ 8384/60000]\n",
      "loss: 0.440953  [ 9024/60000]\n",
      "loss: 0.244281  [ 9664/60000]\n",
      "loss: 0.322809  [10304/60000]\n",
      "loss: 0.214041  [10944/60000]\n",
      "loss: 0.577785  [11584/60000]\n",
      "loss: 0.236453  [12224/60000]\n",
      "loss: 0.183656  [12864/60000]\n",
      "loss: 0.211325  [13504/60000]\n",
      "loss: 0.357474  [14144/60000]\n",
      "loss: 0.328280  [14784/60000]\n",
      "loss: 0.339502  [15424/60000]\n",
      "loss: 0.180475  [16064/60000]\n",
      "loss: 0.418615  [16704/60000]\n",
      "loss: 0.245621  [17344/60000]\n",
      "loss: 0.221227  [17984/60000]\n",
      "loss: 0.179304  [18624/60000]\n",
      "loss: 0.207308  [19264/60000]\n",
      "loss: 0.207167  [19904/60000]\n",
      "loss: 0.257305  [20544/60000]\n",
      "loss: 0.445189  [21184/60000]\n",
      "loss: 0.240566  [21824/60000]\n",
      "loss: 0.274258  [22464/60000]\n",
      "loss: 0.503459  [23104/60000]\n",
      "loss: 0.253058  [23744/60000]\n",
      "loss: 0.284323  [24384/60000]\n",
      "loss: 0.319993  [25024/60000]\n",
      "loss: 0.313840  [25664/60000]\n",
      "loss: 0.135068  [26304/60000]\n",
      "loss: 0.397285  [26944/60000]\n",
      "loss: 0.377277  [27584/60000]\n",
      "loss: 0.306800  [28224/60000]\n",
      "loss: 0.184860  [28864/60000]\n",
      "loss: 0.258381  [29504/60000]\n",
      "loss: 0.239625  [30144/60000]\n",
      "loss: 0.268389  [30784/60000]\n",
      "loss: 0.254069  [31424/60000]\n",
      "loss: 0.226950  [32064/60000]\n",
      "loss: 0.318039  [32704/60000]\n",
      "loss: 0.227323  [33344/60000]\n",
      "loss: 0.249901  [33984/60000]\n",
      "loss: 0.206493  [34624/60000]\n",
      "loss: 0.358424  [35264/60000]\n",
      "loss: 0.141627  [35904/60000]\n",
      "loss: 0.229971  [36544/60000]\n",
      "loss: 0.236187  [37184/60000]\n",
      "loss: 0.304141  [37824/60000]\n",
      "loss: 0.279022  [38464/60000]\n",
      "loss: 0.350498  [39104/60000]\n",
      "loss: 0.194311  [39744/60000]\n",
      "loss: 0.171274  [40384/60000]\n",
      "loss: 0.273210  [41024/60000]\n",
      "loss: 0.305789  [41664/60000]\n",
      "loss: 0.389215  [42304/60000]\n",
      "loss: 0.161807  [42944/60000]\n",
      "loss: 0.242049  [43584/60000]\n",
      "loss: 0.178820  [44224/60000]\n",
      "loss: 0.258562  [44864/60000]\n",
      "loss: 0.236418  [45504/60000]\n",
      "loss: 0.260924  [46144/60000]\n",
      "loss: 0.249049  [46784/60000]\n",
      "loss: 0.401160  [47424/60000]\n",
      "loss: 0.335569  [48064/60000]\n",
      "loss: 0.327430  [48704/60000]\n",
      "loss: 0.334584  [49344/60000]\n",
      "loss: 0.258846  [49984/60000]\n",
      "loss: 0.330539  [50624/60000]\n",
      "loss: 0.336369  [51264/60000]\n",
      "loss: 0.275679  [51904/60000]\n",
      "loss: 0.225083  [52544/60000]\n",
      "loss: 0.411899  [53184/60000]\n",
      "loss: 0.266155  [53824/60000]\n",
      "loss: 0.217237  [54464/60000]\n",
      "loss: 0.230003  [55104/60000]\n",
      "loss: 0.311304  [55744/60000]\n",
      "loss: 0.174022  [56384/60000]\n",
      "loss: 0.187777  [57024/60000]\n",
      "loss: 0.243904  [57664/60000]\n",
      "loss: 0.236852  [58304/60000]\n",
      "loss: 0.244189  [58944/60000]\n",
      "loss: 0.299252  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.286090 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.179421  [   64/60000]\n",
      "loss: 0.378738  [  704/60000]\n",
      "loss: 0.145794  [ 1344/60000]\n",
      "loss: 0.208110  [ 1984/60000]\n",
      "loss: 0.201413  [ 2624/60000]\n",
      "loss: 0.148618  [ 3264/60000]\n",
      "loss: 0.268023  [ 3904/60000]\n",
      "loss: 0.242473  [ 4544/60000]\n",
      "loss: 0.335867  [ 5184/60000]\n",
      "loss: 0.169469  [ 5824/60000]\n",
      "loss: 0.168288  [ 6464/60000]\n",
      "loss: 0.512762  [ 7104/60000]\n",
      "loss: 0.311435  [ 7744/60000]\n",
      "loss: 0.192387  [ 8384/60000]\n",
      "loss: 0.207044  [ 9024/60000]\n",
      "loss: 0.297508  [ 9664/60000]\n",
      "loss: 0.261238  [10304/60000]\n",
      "loss: 0.280626  [10944/60000]\n",
      "loss: 0.190038  [11584/60000]\n",
      "loss: 0.311084  [12224/60000]\n",
      "loss: 0.209959  [12864/60000]\n",
      "loss: 0.152641  [13504/60000]\n",
      "loss: 0.306255  [14144/60000]\n",
      "loss: 0.237898  [14784/60000]\n",
      "loss: 0.209100  [15424/60000]\n",
      "loss: 0.306986  [16064/60000]\n",
      "loss: 0.298226  [16704/60000]\n",
      "loss: 0.228822  [17344/60000]\n",
      "loss: 0.365972  [17984/60000]\n",
      "loss: 0.383009  [18624/60000]\n",
      "loss: 0.319967  [19264/60000]\n",
      "loss: 0.522983  [19904/60000]\n",
      "loss: 0.454568  [20544/60000]\n",
      "loss: 0.270664  [21184/60000]\n",
      "loss: 0.232942  [21824/60000]\n",
      "loss: 0.439759  [22464/60000]\n",
      "loss: 0.448270  [23104/60000]\n",
      "loss: 0.285299  [23744/60000]\n",
      "loss: 0.295718  [24384/60000]\n",
      "loss: 0.242406  [25024/60000]\n",
      "loss: 0.252526  [25664/60000]\n",
      "loss: 0.365013  [26304/60000]\n",
      "loss: 0.264492  [26944/60000]\n",
      "loss: 0.266700  [27584/60000]\n",
      "loss: 0.133391  [28224/60000]\n",
      "loss: 0.602790  [28864/60000]\n",
      "loss: 0.203122  [29504/60000]\n",
      "loss: 0.257201  [30144/60000]\n",
      "loss: 0.280247  [30784/60000]\n",
      "loss: 0.319592  [31424/60000]\n",
      "loss: 0.190560  [32064/60000]\n",
      "loss: 0.236159  [32704/60000]\n",
      "loss: 0.412297  [33344/60000]\n",
      "loss: 0.315596  [33984/60000]\n",
      "loss: 0.289435  [34624/60000]\n",
      "loss: 0.391964  [35264/60000]\n",
      "loss: 0.312849  [35904/60000]\n",
      "loss: 0.455690  [36544/60000]\n",
      "loss: 0.202211  [37184/60000]\n",
      "loss: 0.301816  [37824/60000]\n",
      "loss: 0.283539  [38464/60000]\n",
      "loss: 0.221798  [39104/60000]\n",
      "loss: 0.341532  [39744/60000]\n",
      "loss: 0.168543  [40384/60000]\n",
      "loss: 0.337305  [41024/60000]\n",
      "loss: 0.323626  [41664/60000]\n",
      "loss: 0.227908  [42304/60000]\n",
      "loss: 0.273321  [42944/60000]\n",
      "loss: 0.272221  [43584/60000]\n",
      "loss: 0.246463  [44224/60000]\n",
      "loss: 0.330063  [44864/60000]\n",
      "loss: 0.229825  [45504/60000]\n",
      "loss: 0.295226  [46144/60000]\n",
      "loss: 0.300882  [46784/60000]\n",
      "loss: 0.186633  [47424/60000]\n",
      "loss: 0.148504  [48064/60000]\n",
      "loss: 0.276003  [48704/60000]\n",
      "loss: 0.328875  [49344/60000]\n",
      "loss: 0.406537  [49984/60000]\n",
      "loss: 0.276644  [50624/60000]\n",
      "loss: 0.203906  [51264/60000]\n",
      "loss: 0.331575  [51904/60000]\n",
      "loss: 0.398850  [52544/60000]\n",
      "loss: 0.482547  [53184/60000]\n",
      "loss: 0.317540  [53824/60000]\n",
      "loss: 0.391647  [54464/60000]\n",
      "loss: 0.320725  [55104/60000]\n",
      "loss: 0.361576  [55744/60000]\n",
      "loss: 0.371335  [56384/60000]\n",
      "loss: 0.128340  [57024/60000]\n",
      "loss: 0.202779  [57664/60000]\n",
      "loss: 0.460257  [58304/60000]\n",
      "loss: 0.222955  [58944/60000]\n",
      "loss: 0.200391  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.282161 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.281797  [   64/60000]\n",
      "loss: 0.257638  [  704/60000]\n",
      "loss: 0.195501  [ 1344/60000]\n",
      "loss: 0.258716  [ 1984/60000]\n",
      "loss: 0.371493  [ 2624/60000]\n",
      "loss: 0.244812  [ 3264/60000]\n",
      "loss: 0.215859  [ 3904/60000]\n",
      "loss: 0.283475  [ 4544/60000]\n",
      "loss: 0.430928  [ 5184/60000]\n",
      "loss: 0.202845  [ 5824/60000]\n",
      "loss: 0.229216  [ 6464/60000]\n",
      "loss: 0.243283  [ 7104/60000]\n",
      "loss: 0.233068  [ 7744/60000]\n",
      "loss: 0.309077  [ 8384/60000]\n",
      "loss: 0.389018  [ 9024/60000]\n",
      "loss: 0.367115  [ 9664/60000]\n",
      "loss: 0.421893  [10304/60000]\n",
      "loss: 0.301151  [10944/60000]\n",
      "loss: 0.165933  [11584/60000]\n",
      "loss: 0.243458  [12224/60000]\n",
      "loss: 0.507777  [12864/60000]\n",
      "loss: 0.166933  [13504/60000]\n",
      "loss: 0.210314  [14144/60000]\n",
      "loss: 0.174748  [14784/60000]\n",
      "loss: 0.307679  [15424/60000]\n",
      "loss: 0.322192  [16064/60000]\n",
      "loss: 0.226412  [16704/60000]\n",
      "loss: 0.377042  [17344/60000]\n",
      "loss: 0.302561  [17984/60000]\n",
      "loss: 0.215106  [18624/60000]\n",
      "loss: 0.233888  [19264/60000]\n",
      "loss: 0.263801  [19904/60000]\n",
      "loss: 0.289839  [20544/60000]\n",
      "loss: 0.431351  [21184/60000]\n",
      "loss: 0.425010  [21824/60000]\n",
      "loss: 0.146079  [22464/60000]\n",
      "loss: 0.214877  [23104/60000]\n",
      "loss: 0.382613  [23744/60000]\n",
      "loss: 0.170217  [24384/60000]\n",
      "loss: 0.237690  [25024/60000]\n",
      "loss: 0.258995  [25664/60000]\n",
      "loss: 0.194936  [26304/60000]\n",
      "loss: 0.187025  [26944/60000]\n",
      "loss: 0.244044  [27584/60000]\n",
      "loss: 0.372669  [28224/60000]\n",
      "loss: 0.150063  [28864/60000]\n",
      "loss: 0.376794  [29504/60000]\n",
      "loss: 0.365395  [30144/60000]\n",
      "loss: 0.184169  [30784/60000]\n",
      "loss: 0.157092  [31424/60000]\n",
      "loss: 0.164925  [32064/60000]\n",
      "loss: 0.257241  [32704/60000]\n",
      "loss: 0.288681  [33344/60000]\n",
      "loss: 0.200306  [33984/60000]\n",
      "loss: 0.327770  [34624/60000]\n",
      "loss: 0.116887  [35264/60000]\n",
      "loss: 0.386685  [35904/60000]\n",
      "loss: 0.212065  [36544/60000]\n",
      "loss: 0.216779  [37184/60000]\n",
      "loss: 0.316220  [37824/60000]\n",
      "loss: 0.235666  [38464/60000]\n",
      "loss: 0.175708  [39104/60000]\n",
      "loss: 0.234864  [39744/60000]\n",
      "loss: 0.314297  [40384/60000]\n",
      "loss: 0.272353  [41024/60000]\n",
      "loss: 0.237271  [41664/60000]\n",
      "loss: 0.373073  [42304/60000]\n",
      "loss: 0.520367  [42944/60000]\n",
      "loss: 0.255194  [43584/60000]\n",
      "loss: 0.256706  [44224/60000]\n",
      "loss: 0.279528  [44864/60000]\n",
      "loss: 0.312615  [45504/60000]\n",
      "loss: 0.357679  [46144/60000]\n",
      "loss: 0.270298  [46784/60000]\n",
      "loss: 0.361009  [47424/60000]\n",
      "loss: 0.231844  [48064/60000]\n",
      "loss: 0.224161  [48704/60000]\n",
      "loss: 0.164007  [49344/60000]\n",
      "loss: 0.322157  [49984/60000]\n",
      "loss: 0.371516  [50624/60000]\n",
      "loss: 0.216373  [51264/60000]\n",
      "loss: 0.269429  [51904/60000]\n",
      "loss: 0.213125  [52544/60000]\n",
      "loss: 0.269126  [53184/60000]\n",
      "loss: 0.160779  [53824/60000]\n",
      "loss: 0.295336  [54464/60000]\n",
      "loss: 0.295793  [55104/60000]\n",
      "loss: 0.269849  [55744/60000]\n",
      "loss: 0.101054  [56384/60000]\n",
      "loss: 0.220440  [57024/60000]\n",
      "loss: 0.133850  [57664/60000]\n",
      "loss: 0.192241  [58304/60000]\n",
      "loss: 0.290064  [58944/60000]\n",
      "loss: 0.163766  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.286089 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.396450  [   64/60000]\n",
      "loss: 0.231692  [  704/60000]\n",
      "loss: 0.233254  [ 1344/60000]\n",
      "loss: 0.228443  [ 1984/60000]\n",
      "loss: 0.292714  [ 2624/60000]\n",
      "loss: 0.209545  [ 3264/60000]\n",
      "loss: 0.279625  [ 3904/60000]\n",
      "loss: 0.208119  [ 4544/60000]\n",
      "loss: 0.284048  [ 5184/60000]\n",
      "loss: 0.172221  [ 5824/60000]\n",
      "loss: 0.312511  [ 6464/60000]\n",
      "loss: 0.311512  [ 7104/60000]\n",
      "loss: 0.180893  [ 7744/60000]\n",
      "loss: 0.131415  [ 8384/60000]\n",
      "loss: 0.130096  [ 9024/60000]\n",
      "loss: 0.322445  [ 9664/60000]\n",
      "loss: 0.164139  [10304/60000]\n",
      "loss: 0.374576  [10944/60000]\n",
      "loss: 0.268870  [11584/60000]\n",
      "loss: 0.181149  [12224/60000]\n",
      "loss: 0.213343  [12864/60000]\n",
      "loss: 0.294371  [13504/60000]\n",
      "loss: 0.431387  [14144/60000]\n",
      "loss: 0.411578  [14784/60000]\n",
      "loss: 0.212766  [15424/60000]\n",
      "loss: 0.271021  [16064/60000]\n",
      "loss: 0.396491  [16704/60000]\n",
      "loss: 0.344962  [17344/60000]\n",
      "loss: 0.230462  [17984/60000]\n",
      "loss: 0.240038  [18624/60000]\n",
      "loss: 0.135768  [19264/60000]\n",
      "loss: 0.295588  [19904/60000]\n",
      "loss: 0.191148  [20544/60000]\n",
      "loss: 0.118486  [21184/60000]\n",
      "loss: 0.252981  [21824/60000]\n",
      "loss: 0.231448  [22464/60000]\n",
      "loss: 0.470211  [23104/60000]\n",
      "loss: 0.354012  [23744/60000]\n",
      "loss: 0.285283  [24384/60000]\n",
      "loss: 0.264715  [25024/60000]\n",
      "loss: 0.184155  [25664/60000]\n",
      "loss: 0.171767  [26304/60000]\n",
      "loss: 0.148402  [26944/60000]\n",
      "loss: 0.329356  [27584/60000]\n",
      "loss: 0.265837  [28224/60000]\n",
      "loss: 0.293644  [28864/60000]\n",
      "loss: 0.177346  [29504/60000]\n",
      "loss: 0.332661  [30144/60000]\n",
      "loss: 0.294506  [30784/60000]\n",
      "loss: 0.205561  [31424/60000]\n",
      "loss: 0.265199  [32064/60000]\n",
      "loss: 0.190629  [32704/60000]\n",
      "loss: 0.244502  [33344/60000]\n",
      "loss: 0.296205  [33984/60000]\n",
      "loss: 0.345022  [34624/60000]\n",
      "loss: 0.208825  [35264/60000]\n",
      "loss: 0.263539  [35904/60000]\n",
      "loss: 0.309768  [36544/60000]\n",
      "loss: 0.278924  [37184/60000]\n",
      "loss: 0.200807  [37824/60000]\n",
      "loss: 0.236453  [38464/60000]\n",
      "loss: 0.179040  [39104/60000]\n",
      "loss: 0.099776  [39744/60000]\n",
      "loss: 0.177876  [40384/60000]\n",
      "loss: 0.216551  [41024/60000]\n",
      "loss: 0.154144  [41664/60000]\n",
      "loss: 0.120774  [42304/60000]\n",
      "loss: 0.126122  [42944/60000]\n",
      "loss: 0.312736  [43584/60000]\n",
      "loss: 0.141545  [44224/60000]\n",
      "loss: 0.184494  [44864/60000]\n",
      "loss: 0.271751  [45504/60000]\n",
      "loss: 0.318943  [46144/60000]\n",
      "loss: 0.141344  [46784/60000]\n",
      "loss: 0.164854  [47424/60000]\n",
      "loss: 0.199009  [48064/60000]\n",
      "loss: 0.159247  [48704/60000]\n",
      "loss: 0.479923  [49344/60000]\n",
      "loss: 0.305173  [49984/60000]\n",
      "loss: 0.401239  [50624/60000]\n",
      "loss: 0.219851  [51264/60000]\n",
      "loss: 0.266252  [51904/60000]\n",
      "loss: 0.143088  [52544/60000]\n",
      "loss: 0.393723  [53184/60000]\n",
      "loss: 0.257834  [53824/60000]\n",
      "loss: 0.127330  [54464/60000]\n",
      "loss: 0.250259  [55104/60000]\n",
      "loss: 0.218218  [55744/60000]\n",
      "loss: 0.251520  [56384/60000]\n",
      "loss: 0.189878  [57024/60000]\n",
      "loss: 0.270494  [57664/60000]\n",
      "loss: 0.129667  [58304/60000]\n",
      "loss: 0.201607  [58944/60000]\n",
      "loss: 0.233366  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.279255 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.224546  [   64/60000]\n",
      "loss: 0.267820  [  704/60000]\n",
      "loss: 0.253891  [ 1344/60000]\n",
      "loss: 0.253718  [ 1984/60000]\n",
      "loss: 0.404873  [ 2624/60000]\n",
      "loss: 0.270562  [ 3264/60000]\n",
      "loss: 0.099931  [ 3904/60000]\n",
      "loss: 0.349832  [ 4544/60000]\n",
      "loss: 0.196363  [ 5184/60000]\n",
      "loss: 0.320334  [ 5824/60000]\n",
      "loss: 0.176482  [ 6464/60000]\n",
      "loss: 0.282016  [ 7104/60000]\n",
      "loss: 0.249656  [ 7744/60000]\n",
      "loss: 0.370984  [ 8384/60000]\n",
      "loss: 0.309109  [ 9024/60000]\n",
      "loss: 0.219488  [ 9664/60000]\n",
      "loss: 0.097746  [10304/60000]\n",
      "loss: 0.302509  [10944/60000]\n",
      "loss: 0.168624  [11584/60000]\n",
      "loss: 0.355415  [12224/60000]\n",
      "loss: 0.255311  [12864/60000]\n",
      "loss: 0.286738  [13504/60000]\n",
      "loss: 0.310938  [14144/60000]\n",
      "loss: 0.257540  [14784/60000]\n",
      "loss: 0.256542  [15424/60000]\n",
      "loss: 0.295154  [16064/60000]\n",
      "loss: 0.416787  [16704/60000]\n",
      "loss: 0.097412  [17344/60000]\n",
      "loss: 0.207214  [17984/60000]\n",
      "loss: 0.178665  [18624/60000]\n",
      "loss: 0.200416  [19264/60000]\n",
      "loss: 0.321120  [19904/60000]\n",
      "loss: 0.328017  [20544/60000]\n",
      "loss: 0.538707  [21184/60000]\n",
      "loss: 0.204945  [21824/60000]\n",
      "loss: 0.317016  [22464/60000]\n",
      "loss: 0.148708  [23104/60000]\n",
      "loss: 0.215930  [23744/60000]\n",
      "loss: 0.366973  [24384/60000]\n",
      "loss: 0.262992  [25024/60000]\n",
      "loss: 0.183949  [25664/60000]\n",
      "loss: 0.212879  [26304/60000]\n",
      "loss: 0.261854  [26944/60000]\n",
      "loss: 0.195109  [27584/60000]\n",
      "loss: 0.426300  [28224/60000]\n",
      "loss: 0.142745  [28864/60000]\n",
      "loss: 0.140911  [29504/60000]\n",
      "loss: 0.356875  [30144/60000]\n",
      "loss: 0.199479  [30784/60000]\n",
      "loss: 0.204591  [31424/60000]\n",
      "loss: 0.173182  [32064/60000]\n",
      "loss: 0.136995  [32704/60000]\n",
      "loss: 0.302040  [33344/60000]\n",
      "loss: 0.292226  [33984/60000]\n",
      "loss: 0.199868  [34624/60000]\n",
      "loss: 0.201360  [35264/60000]\n",
      "loss: 0.414704  [35904/60000]\n",
      "loss: 0.227101  [36544/60000]\n",
      "loss: 0.230350  [37184/60000]\n",
      "loss: 0.287158  [37824/60000]\n",
      "loss: 0.301860  [38464/60000]\n",
      "loss: 0.281571  [39104/60000]\n",
      "loss: 0.185469  [39744/60000]\n",
      "loss: 0.296517  [40384/60000]\n",
      "loss: 0.334111  [41024/60000]\n",
      "loss: 0.310754  [41664/60000]\n",
      "loss: 0.198688  [42304/60000]\n",
      "loss: 0.182340  [42944/60000]\n",
      "loss: 0.387522  [43584/60000]\n",
      "loss: 0.271753  [44224/60000]\n",
      "loss: 0.336679  [44864/60000]\n",
      "loss: 0.329582  [45504/60000]\n",
      "loss: 0.254325  [46144/60000]\n",
      "loss: 0.183459  [46784/60000]\n",
      "loss: 0.377232  [47424/60000]\n",
      "loss: 0.236714  [48064/60000]\n",
      "loss: 0.277572  [48704/60000]\n",
      "loss: 0.211239  [49344/60000]\n",
      "loss: 0.142253  [49984/60000]\n",
      "loss: 0.204698  [50624/60000]\n",
      "loss: 0.417094  [51264/60000]\n",
      "loss: 0.213672  [51904/60000]\n",
      "loss: 0.263113  [52544/60000]\n",
      "loss: 0.218025  [53184/60000]\n",
      "loss: 0.206080  [53824/60000]\n",
      "loss: 0.188376  [54464/60000]\n",
      "loss: 0.191033  [55104/60000]\n",
      "loss: 0.220488  [55744/60000]\n",
      "loss: 0.442295  [56384/60000]\n",
      "loss: 0.086400  [57024/60000]\n",
      "loss: 0.306778  [57664/60000]\n",
      "loss: 0.362811  [58304/60000]\n",
      "loss: 0.184553  [58944/60000]\n",
      "loss: 0.390286  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.261629 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.187863  [   64/60000]\n",
      "loss: 0.132806  [  704/60000]\n",
      "loss: 0.139146  [ 1344/60000]\n",
      "loss: 0.239124  [ 1984/60000]\n",
      "loss: 0.472208  [ 2624/60000]\n",
      "loss: 0.184168  [ 3264/60000]\n",
      "loss: 0.170507  [ 3904/60000]\n",
      "loss: 0.224331  [ 4544/60000]\n",
      "loss: 0.232215  [ 5184/60000]\n",
      "loss: 0.271382  [ 5824/60000]\n",
      "loss: 0.138585  [ 6464/60000]\n",
      "loss: 0.293373  [ 7104/60000]\n",
      "loss: 0.263260  [ 7744/60000]\n",
      "loss: 0.208008  [ 8384/60000]\n",
      "loss: 0.159930  [ 9024/60000]\n",
      "loss: 0.139214  [ 9664/60000]\n",
      "loss: 0.209009  [10304/60000]\n",
      "loss: 0.284502  [10944/60000]\n",
      "loss: 0.140391  [11584/60000]\n",
      "loss: 0.306086  [12224/60000]\n",
      "loss: 0.210231  [12864/60000]\n",
      "loss: 0.236868  [13504/60000]\n",
      "loss: 0.258304  [14144/60000]\n",
      "loss: 0.219165  [14784/60000]\n",
      "loss: 0.276481  [15424/60000]\n",
      "loss: 0.222398  [16064/60000]\n",
      "loss: 0.359576  [16704/60000]\n",
      "loss: 0.408592  [17344/60000]\n",
      "loss: 0.301168  [17984/60000]\n",
      "loss: 0.162017  [18624/60000]\n",
      "loss: 0.306687  [19264/60000]\n",
      "loss: 0.126098  [19904/60000]\n",
      "loss: 0.458524  [20544/60000]\n",
      "loss: 0.221112  [21184/60000]\n",
      "loss: 0.169719  [21824/60000]\n",
      "loss: 0.218509  [22464/60000]\n",
      "loss: 0.102191  [23104/60000]\n",
      "loss: 0.164411  [23744/60000]\n",
      "loss: 0.191580  [24384/60000]\n",
      "loss: 0.186764  [25024/60000]\n",
      "loss: 0.302374  [25664/60000]\n",
      "loss: 0.297239  [26304/60000]\n",
      "loss: 0.328857  [26944/60000]\n",
      "loss: 0.341462  [27584/60000]\n",
      "loss: 0.258331  [28224/60000]\n",
      "loss: 0.259341  [28864/60000]\n",
      "loss: 0.071034  [29504/60000]\n",
      "loss: 0.282875  [30144/60000]\n",
      "loss: 0.191255  [30784/60000]\n",
      "loss: 0.276457  [31424/60000]\n",
      "loss: 0.230690  [32064/60000]\n",
      "loss: 0.155108  [32704/60000]\n",
      "loss: 0.212908  [33344/60000]\n",
      "loss: 0.173524  [33984/60000]\n",
      "loss: 0.296391  [34624/60000]\n",
      "loss: 0.300691  [35264/60000]\n",
      "loss: 0.277888  [35904/60000]\n",
      "loss: 0.182021  [36544/60000]\n",
      "loss: 0.190204  [37184/60000]\n",
      "loss: 0.266311  [37824/60000]\n",
      "loss: 0.163224  [38464/60000]\n",
      "loss: 0.354913  [39104/60000]\n",
      "loss: 0.391290  [39744/60000]\n",
      "loss: 0.190363  [40384/60000]\n",
      "loss: 0.341054  [41024/60000]\n",
      "loss: 0.318965  [41664/60000]\n",
      "loss: 0.196840  [42304/60000]\n",
      "loss: 0.320596  [42944/60000]\n",
      "loss: 0.127807  [43584/60000]\n",
      "loss: 0.163308  [44224/60000]\n",
      "loss: 0.182286  [44864/60000]\n",
      "loss: 0.157928  [45504/60000]\n",
      "loss: 0.275501  [46144/60000]\n",
      "loss: 0.254050  [46784/60000]\n",
      "loss: 0.211051  [47424/60000]\n",
      "loss: 0.199148  [48064/60000]\n",
      "loss: 0.394530  [48704/60000]\n",
      "loss: 0.311702  [49344/60000]\n",
      "loss: 0.184536  [49984/60000]\n",
      "loss: 0.300348  [50624/60000]\n",
      "loss: 0.371091  [51264/60000]\n",
      "loss: 0.292706  [51904/60000]\n",
      "loss: 0.442357  [52544/60000]\n",
      "loss: 0.170200  [53184/60000]\n",
      "loss: 0.353085  [53824/60000]\n",
      "loss: 0.214732  [54464/60000]\n",
      "loss: 0.303204  [55104/60000]\n",
      "loss: 0.189567  [55744/60000]\n",
      "loss: 0.134604  [56384/60000]\n",
      "loss: 0.289302  [57024/60000]\n",
      "loss: 0.204207  [57664/60000]\n",
      "loss: 0.264341  [58304/60000]\n",
      "loss: 0.239976  [58944/60000]\n",
      "loss: 0.134948  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.266578 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.160345  [   64/60000]\n",
      "loss: 0.208316  [  704/60000]\n",
      "loss: 0.223629  [ 1344/60000]\n",
      "loss: 0.268924  [ 1984/60000]\n",
      "loss: 0.266256  [ 2624/60000]\n",
      "loss: 0.183892  [ 3264/60000]\n",
      "loss: 0.456336  [ 3904/60000]\n",
      "loss: 0.206488  [ 4544/60000]\n",
      "loss: 0.146778  [ 5184/60000]\n",
      "loss: 0.336104  [ 5824/60000]\n",
      "loss: 0.481728  [ 6464/60000]\n",
      "loss: 0.144619  [ 7104/60000]\n",
      "loss: 0.335704  [ 7744/60000]\n",
      "loss: 0.202961  [ 8384/60000]\n",
      "loss: 0.342326  [ 9024/60000]\n",
      "loss: 0.125375  [ 9664/60000]\n",
      "loss: 0.179290  [10304/60000]\n",
      "loss: 0.307284  [10944/60000]\n",
      "loss: 0.246694  [11584/60000]\n",
      "loss: 0.229052  [12224/60000]\n",
      "loss: 0.124680  [12864/60000]\n",
      "loss: 0.196459  [13504/60000]\n",
      "loss: 0.131466  [14144/60000]\n",
      "loss: 0.291231  [14784/60000]\n",
      "loss: 0.139457  [15424/60000]\n",
      "loss: 0.204554  [16064/60000]\n",
      "loss: 0.305922  [16704/60000]\n",
      "loss: 0.169560  [17344/60000]\n",
      "loss: 0.120452  [17984/60000]\n",
      "loss: 0.321586  [18624/60000]\n",
      "loss: 0.224735  [19264/60000]\n",
      "loss: 0.263900  [19904/60000]\n",
      "loss: 0.225839  [20544/60000]\n",
      "loss: 0.280910  [21184/60000]\n",
      "loss: 0.171270  [21824/60000]\n",
      "loss: 0.237767  [22464/60000]\n",
      "loss: 0.319362  [23104/60000]\n",
      "loss: 0.237251  [23744/60000]\n",
      "loss: 0.152242  [24384/60000]\n",
      "loss: 0.273516  [25024/60000]\n",
      "loss: 0.235637  [25664/60000]\n",
      "loss: 0.316491  [26304/60000]\n",
      "loss: 0.278960  [26944/60000]\n",
      "loss: 0.232887  [27584/60000]\n",
      "loss: 0.318261  [28224/60000]\n",
      "loss: 0.184724  [28864/60000]\n",
      "loss: 0.185401  [29504/60000]\n",
      "loss: 0.273171  [30144/60000]\n",
      "loss: 0.284493  [30784/60000]\n",
      "loss: 0.283591  [31424/60000]\n",
      "loss: 0.199044  [32064/60000]\n",
      "loss: 0.348200  [32704/60000]\n",
      "loss: 0.204522  [33344/60000]\n",
      "loss: 0.172391  [33984/60000]\n",
      "loss: 0.241018  [34624/60000]\n",
      "loss: 0.138345  [35264/60000]\n",
      "loss: 0.255192  [35904/60000]\n",
      "loss: 0.320554  [36544/60000]\n",
      "loss: 0.339347  [37184/60000]\n",
      "loss: 0.123963  [37824/60000]\n",
      "loss: 0.425290  [38464/60000]\n",
      "loss: 0.263457  [39104/60000]\n",
      "loss: 0.180179  [39744/60000]\n",
      "loss: 0.289183  [40384/60000]\n",
      "loss: 0.224952  [41024/60000]\n",
      "loss: 0.355975  [41664/60000]\n",
      "loss: 0.241456  [42304/60000]\n",
      "loss: 0.183350  [42944/60000]\n",
      "loss: 0.178515  [43584/60000]\n",
      "loss: 0.253367  [44224/60000]\n",
      "loss: 0.249872  [44864/60000]\n",
      "loss: 0.297534  [45504/60000]\n",
      "loss: 0.304737  [46144/60000]\n",
      "loss: 0.273638  [46784/60000]\n",
      "loss: 0.297921  [47424/60000]\n",
      "loss: 0.373194  [48064/60000]\n",
      "loss: 0.292055  [48704/60000]\n",
      "loss: 0.278685  [49344/60000]\n",
      "loss: 0.306021  [49984/60000]\n",
      "loss: 0.179360  [50624/60000]\n",
      "loss: 0.271990  [51264/60000]\n",
      "loss: 0.108606  [51904/60000]\n",
      "loss: 0.378397  [52544/60000]\n",
      "loss: 0.178779  [53184/60000]\n",
      "loss: 0.432882  [53824/60000]\n",
      "loss: 0.268381  [54464/60000]\n",
      "loss: 0.129788  [55104/60000]\n",
      "loss: 0.252549  [55744/60000]\n",
      "loss: 0.326558  [56384/60000]\n",
      "loss: 0.351720  [57024/60000]\n",
      "loss: 0.339936  [57664/60000]\n",
      "loss: 0.156420  [58304/60000]\n",
      "loss: 0.259981  [58944/60000]\n",
      "loss: 0.311448  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.262782 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.201294  [   64/60000]\n",
      "loss: 0.150840  [  704/60000]\n",
      "loss: 0.216031  [ 1344/60000]\n",
      "loss: 0.231691  [ 1984/60000]\n",
      "loss: 0.152138  [ 2624/60000]\n",
      "loss: 0.312612  [ 3264/60000]\n",
      "loss: 0.228385  [ 3904/60000]\n",
      "loss: 0.334895  [ 4544/60000]\n",
      "loss: 0.342127  [ 5184/60000]\n",
      "loss: 0.137641  [ 5824/60000]\n",
      "loss: 0.131602  [ 6464/60000]\n",
      "loss: 0.411263  [ 7104/60000]\n",
      "loss: 0.165833  [ 7744/60000]\n",
      "loss: 0.158601  [ 8384/60000]\n",
      "loss: 0.156120  [ 9024/60000]\n",
      "loss: 0.218545  [ 9664/60000]\n",
      "loss: 0.137489  [10304/60000]\n",
      "loss: 0.401198  [10944/60000]\n",
      "loss: 0.235941  [11584/60000]\n",
      "loss: 0.459965  [12224/60000]\n",
      "loss: 0.094822  [12864/60000]\n",
      "loss: 0.119445  [13504/60000]\n",
      "loss: 0.211565  [14144/60000]\n",
      "loss: 0.172415  [14784/60000]\n",
      "loss: 0.175257  [15424/60000]\n",
      "loss: 0.375365  [16064/60000]\n",
      "loss: 0.095692  [16704/60000]\n",
      "loss: 0.187144  [17344/60000]\n",
      "loss: 0.373248  [17984/60000]\n",
      "loss: 0.376126  [18624/60000]\n",
      "loss: 0.208560  [19264/60000]\n",
      "loss: 0.166512  [19904/60000]\n",
      "loss: 0.194046  [20544/60000]\n",
      "loss: 0.253439  [21184/60000]\n",
      "loss: 0.292214  [21824/60000]\n",
      "loss: 0.292896  [22464/60000]\n",
      "loss: 0.275720  [23104/60000]\n",
      "loss: 0.291222  [23744/60000]\n",
      "loss: 0.294218  [24384/60000]\n",
      "loss: 0.138563  [25024/60000]\n",
      "loss: 0.248637  [25664/60000]\n",
      "loss: 0.274754  [26304/60000]\n",
      "loss: 0.293592  [26944/60000]\n",
      "loss: 0.175435  [27584/60000]\n",
      "loss: 0.104728  [28224/60000]\n",
      "loss: 0.175279  [28864/60000]\n",
      "loss: 0.211846  [29504/60000]\n",
      "loss: 0.180449  [30144/60000]\n",
      "loss: 0.222618  [30784/60000]\n",
      "loss: 0.103366  [31424/60000]\n",
      "loss: 0.317866  [32064/60000]\n",
      "loss: 0.347067  [32704/60000]\n",
      "loss: 0.107262  [33344/60000]\n",
      "loss: 0.360550  [33984/60000]\n",
      "loss: 0.336558  [34624/60000]\n",
      "loss: 0.458718  [35264/60000]\n",
      "loss: 0.202856  [35904/60000]\n",
      "loss: 0.213295  [36544/60000]\n",
      "loss: 0.267900  [37184/60000]\n",
      "loss: 0.183709  [37824/60000]\n",
      "loss: 0.340578  [38464/60000]\n",
      "loss: 0.281459  [39104/60000]\n",
      "loss: 0.268937  [39744/60000]\n",
      "loss: 0.208242  [40384/60000]\n",
      "loss: 0.308983  [41024/60000]\n",
      "loss: 0.151000  [41664/60000]\n",
      "loss: 0.200673  [42304/60000]\n",
      "loss: 0.229897  [42944/60000]\n",
      "loss: 0.233041  [43584/60000]\n",
      "loss: 0.203297  [44224/60000]\n",
      "loss: 0.188954  [44864/60000]\n",
      "loss: 0.210285  [45504/60000]\n",
      "loss: 0.316625  [46144/60000]\n",
      "loss: 0.262641  [46784/60000]\n",
      "loss: 0.242137  [47424/60000]\n",
      "loss: 0.170145  [48064/60000]\n",
      "loss: 0.125795  [48704/60000]\n",
      "loss: 0.216489  [49344/60000]\n",
      "loss: 0.237285  [49984/60000]\n",
      "loss: 0.229589  [50624/60000]\n",
      "loss: 0.183458  [51264/60000]\n",
      "loss: 0.168404  [51904/60000]\n",
      "loss: 0.196394  [52544/60000]\n",
      "loss: 0.159051  [53184/60000]\n",
      "loss: 0.151011  [53824/60000]\n",
      "loss: 0.126058  [54464/60000]\n",
      "loss: 0.168793  [55104/60000]\n",
      "loss: 0.183952  [55744/60000]\n",
      "loss: 0.169288  [56384/60000]\n",
      "loss: 0.303897  [57024/60000]\n",
      "loss: 0.223364  [57664/60000]\n",
      "loss: 0.379710  [58304/60000]\n",
      "loss: 0.279272  [58944/60000]\n",
      "loss: 0.334900  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.253730 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.159743  [   64/60000]\n",
      "loss: 0.254919  [  704/60000]\n",
      "loss: 0.164041  [ 1344/60000]\n",
      "loss: 0.176840  [ 1984/60000]\n",
      "loss: 0.271962  [ 2624/60000]\n",
      "loss: 0.198977  [ 3264/60000]\n",
      "loss: 0.322899  [ 3904/60000]\n",
      "loss: 0.310189  [ 4544/60000]\n",
      "loss: 0.154606  [ 5184/60000]\n",
      "loss: 0.226980  [ 5824/60000]\n",
      "loss: 0.145550  [ 6464/60000]\n",
      "loss: 0.208742  [ 7104/60000]\n",
      "loss: 0.054622  [ 7744/60000]\n",
      "loss: 0.320341  [ 8384/60000]\n",
      "loss: 0.173843  [ 9024/60000]\n",
      "loss: 0.150480  [ 9664/60000]\n",
      "loss: 0.317246  [10304/60000]\n",
      "loss: 0.342399  [10944/60000]\n",
      "loss: 0.157126  [11584/60000]\n",
      "loss: 0.162145  [12224/60000]\n",
      "loss: 0.256753  [12864/60000]\n",
      "loss: 0.224780  [13504/60000]\n",
      "loss: 0.192791  [14144/60000]\n",
      "loss: 0.286085  [14784/60000]\n",
      "loss: 0.347412  [15424/60000]\n",
      "loss: 0.296997  [16064/60000]\n",
      "loss: 0.324854  [16704/60000]\n",
      "loss: 0.218001  [17344/60000]\n",
      "loss: 0.304405  [17984/60000]\n",
      "loss: 0.215742  [18624/60000]\n",
      "loss: 0.165983  [19264/60000]\n",
      "loss: 0.100090  [19904/60000]\n",
      "loss: 0.243968  [20544/60000]\n",
      "loss: 0.216033  [21184/60000]\n",
      "loss: 0.167961  [21824/60000]\n",
      "loss: 0.145735  [22464/60000]\n",
      "loss: 0.388750  [23104/60000]\n",
      "loss: 0.315285  [23744/60000]\n",
      "loss: 0.216684  [24384/60000]\n",
      "loss: 0.216701  [25024/60000]\n",
      "loss: 0.325979  [25664/60000]\n",
      "loss: 0.192114  [26304/60000]\n",
      "loss: 0.301215  [26944/60000]\n",
      "loss: 0.183955  [27584/60000]\n",
      "loss: 0.181108  [28224/60000]\n",
      "loss: 0.147595  [28864/60000]\n",
      "loss: 0.187199  [29504/60000]\n",
      "loss: 0.247476  [30144/60000]\n",
      "loss: 0.239578  [30784/60000]\n",
      "loss: 0.247960  [31424/60000]\n",
      "loss: 0.269446  [32064/60000]\n",
      "loss: 0.366303  [32704/60000]\n",
      "loss: 0.202646  [33344/60000]\n",
      "loss: 0.196615  [33984/60000]\n",
      "loss: 0.375414  [34624/60000]\n",
      "loss: 0.435692  [35264/60000]\n",
      "loss: 0.121191  [35904/60000]\n",
      "loss: 0.185109  [36544/60000]\n",
      "loss: 0.259906  [37184/60000]\n",
      "loss: 0.261948  [37824/60000]\n",
      "loss: 0.300297  [38464/60000]\n",
      "loss: 0.170682  [39104/60000]\n",
      "loss: 0.320982  [39744/60000]\n",
      "loss: 0.122293  [40384/60000]\n",
      "loss: 0.276031  [41024/60000]\n",
      "loss: 0.255389  [41664/60000]\n",
      "loss: 0.190264  [42304/60000]\n",
      "loss: 0.357460  [42944/60000]\n",
      "loss: 0.307127  [43584/60000]\n",
      "loss: 0.175257  [44224/60000]\n",
      "loss: 0.190160  [44864/60000]\n",
      "loss: 0.165499  [45504/60000]\n",
      "loss: 0.146335  [46144/60000]\n",
      "loss: 0.199241  [46784/60000]\n",
      "loss: 0.120214  [47424/60000]\n",
      "loss: 0.229835  [48064/60000]\n",
      "loss: 0.296805  [48704/60000]\n",
      "loss: 0.239376  [49344/60000]\n",
      "loss: 0.201746  [49984/60000]\n",
      "loss: 0.344942  [50624/60000]\n",
      "loss: 0.157485  [51264/60000]\n",
      "loss: 0.155623  [51904/60000]\n",
      "loss: 0.216423  [52544/60000]\n",
      "loss: 0.128642  [53184/60000]\n",
      "loss: 0.283839  [53824/60000]\n",
      "loss: 0.215653  [54464/60000]\n",
      "loss: 0.204428  [55104/60000]\n",
      "loss: 0.198159  [55744/60000]\n",
      "loss: 0.308241  [56384/60000]\n",
      "loss: 0.091606  [57024/60000]\n",
      "loss: 0.233269  [57664/60000]\n",
      "loss: 0.147763  [58304/60000]\n",
      "loss: 0.393332  [58944/60000]\n",
      "loss: 0.113282  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.260306 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.088628  [   64/60000]\n",
      "loss: 0.212154  [  704/60000]\n",
      "loss: 0.330087  [ 1344/60000]\n",
      "loss: 0.205530  [ 1984/60000]\n",
      "loss: 0.230871  [ 2624/60000]\n",
      "loss: 0.144257  [ 3264/60000]\n",
      "loss: 0.149100  [ 3904/60000]\n",
      "loss: 0.223457  [ 4544/60000]\n",
      "loss: 0.248874  [ 5184/60000]\n",
      "loss: 0.094465  [ 5824/60000]\n",
      "loss: 0.135386  [ 6464/60000]\n",
      "loss: 0.138586  [ 7104/60000]\n",
      "loss: 0.170243  [ 7744/60000]\n",
      "loss: 0.346160  [ 8384/60000]\n",
      "loss: 0.099394  [ 9024/60000]\n",
      "loss: 0.079333  [ 9664/60000]\n",
      "loss: 0.236694  [10304/60000]\n",
      "loss: 0.532526  [10944/60000]\n",
      "loss: 0.251764  [11584/60000]\n",
      "loss: 0.148415  [12224/60000]\n",
      "loss: 0.066432  [12864/60000]\n",
      "loss: 0.332629  [13504/60000]\n",
      "loss: 0.142319  [14144/60000]\n",
      "loss: 0.331251  [14784/60000]\n",
      "loss: 0.192589  [15424/60000]\n",
      "loss: 0.198201  [16064/60000]\n",
      "loss: 0.239084  [16704/60000]\n",
      "loss: 0.217557  [17344/60000]\n",
      "loss: 0.155699  [17984/60000]\n",
      "loss: 0.266322  [18624/60000]\n",
      "loss: 0.191788  [19264/60000]\n",
      "loss: 0.170235  [19904/60000]\n",
      "loss: 0.293194  [20544/60000]\n",
      "loss: 0.126833  [21184/60000]\n",
      "loss: 0.199748  [21824/60000]\n",
      "loss: 0.174472  [22464/60000]\n",
      "loss: 0.117512  [23104/60000]\n",
      "loss: 0.220098  [23744/60000]\n",
      "loss: 0.363492  [24384/60000]\n",
      "loss: 0.191039  [25024/60000]\n",
      "loss: 0.181353  [25664/60000]\n",
      "loss: 0.159485  [26304/60000]\n",
      "loss: 0.234985  [26944/60000]\n",
      "loss: 0.301792  [27584/60000]\n",
      "loss: 0.159696  [28224/60000]\n",
      "loss: 0.201467  [28864/60000]\n",
      "loss: 0.183081  [29504/60000]\n",
      "loss: 0.297741  [30144/60000]\n",
      "loss: 0.185444  [30784/60000]\n",
      "loss: 0.246214  [31424/60000]\n",
      "loss: 0.095734  [32064/60000]\n",
      "loss: 0.125734  [32704/60000]\n",
      "loss: 0.309477  [33344/60000]\n",
      "loss: 0.100887  [33984/60000]\n",
      "loss: 0.451005  [34624/60000]\n",
      "loss: 0.314830  [35264/60000]\n",
      "loss: 0.280037  [35904/60000]\n",
      "loss: 0.262597  [36544/60000]\n",
      "loss: 0.056962  [37184/60000]\n",
      "loss: 0.309183  [37824/60000]\n",
      "loss: 0.119308  [38464/60000]\n",
      "loss: 0.187375  [39104/60000]\n",
      "loss: 0.258847  [39744/60000]\n",
      "loss: 0.306965  [40384/60000]\n",
      "loss: 0.224409  [41024/60000]\n",
      "loss: 0.223843  [41664/60000]\n",
      "loss: 0.224799  [42304/60000]\n",
      "loss: 0.285405  [42944/60000]\n",
      "loss: 0.220541  [43584/60000]\n",
      "loss: 0.165224  [44224/60000]\n",
      "loss: 0.080862  [44864/60000]\n",
      "loss: 0.249346  [45504/60000]\n",
      "loss: 0.101919  [46144/60000]\n",
      "loss: 0.236208  [46784/60000]\n",
      "loss: 0.184087  [47424/60000]\n",
      "loss: 0.338885  [48064/60000]\n",
      "loss: 0.243275  [48704/60000]\n",
      "loss: 0.183945  [49344/60000]\n",
      "loss: 0.188202  [49984/60000]\n",
      "loss: 0.296134  [50624/60000]\n",
      "loss: 0.129449  [51264/60000]\n",
      "loss: 0.113660  [51904/60000]\n",
      "loss: 0.104220  [52544/60000]\n",
      "loss: 0.253271  [53184/60000]\n",
      "loss: 0.204026  [53824/60000]\n",
      "loss: 0.197283  [54464/60000]\n",
      "loss: 0.303350  [55104/60000]\n",
      "loss: 0.235642  [55744/60000]\n",
      "loss: 0.227335  [56384/60000]\n",
      "loss: 0.290229  [57024/60000]\n",
      "loss: 0.160666  [57664/60000]\n",
      "loss: 0.327260  [58304/60000]\n",
      "loss: 0.210737  [58944/60000]\n",
      "loss: 0.100404  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.254778 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.122971  [   64/60000]\n",
      "loss: 0.132888  [  704/60000]\n",
      "loss: 0.148359  [ 1344/60000]\n",
      "loss: 0.395346  [ 1984/60000]\n",
      "loss: 0.252173  [ 2624/60000]\n",
      "loss: 0.182657  [ 3264/60000]\n",
      "loss: 0.200555  [ 3904/60000]\n",
      "loss: 0.249566  [ 4544/60000]\n",
      "loss: 0.153902  [ 5184/60000]\n",
      "loss: 0.288257  [ 5824/60000]\n",
      "loss: 0.227211  [ 6464/60000]\n",
      "loss: 0.311505  [ 7104/60000]\n",
      "loss: 0.191723  [ 7744/60000]\n",
      "loss: 0.378497  [ 8384/60000]\n",
      "loss: 0.182368  [ 9024/60000]\n",
      "loss: 0.146431  [ 9664/60000]\n",
      "loss: 0.183088  [10304/60000]\n",
      "loss: 0.324532  [10944/60000]\n",
      "loss: 0.181083  [11584/60000]\n",
      "loss: 0.266480  [12224/60000]\n",
      "loss: 0.121491  [12864/60000]\n",
      "loss: 0.193886  [13504/60000]\n",
      "loss: 0.291183  [14144/60000]\n",
      "loss: 0.106154  [14784/60000]\n",
      "loss: 0.216390  [15424/60000]\n",
      "loss: 0.056307  [16064/60000]\n",
      "loss: 0.405324  [16704/60000]\n",
      "loss: 0.215359  [17344/60000]\n",
      "loss: 0.080666  [17984/60000]\n",
      "loss: 0.201433  [18624/60000]\n",
      "loss: 0.288546  [19264/60000]\n",
      "loss: 0.228424  [19904/60000]\n",
      "loss: 0.195080  [20544/60000]\n",
      "loss: 0.208236  [21184/60000]\n",
      "loss: 0.210913  [21824/60000]\n",
      "loss: 0.333039  [22464/60000]\n",
      "loss: 0.181129  [23104/60000]\n",
      "loss: 0.153237  [23744/60000]\n",
      "loss: 0.233993  [24384/60000]\n",
      "loss: 0.125597  [25024/60000]\n",
      "loss: 0.234510  [25664/60000]\n",
      "loss: 0.391592  [26304/60000]\n",
      "loss: 0.081402  [26944/60000]\n",
      "loss: 0.274913  [27584/60000]\n",
      "loss: 0.266442  [28224/60000]\n",
      "loss: 0.158489  [28864/60000]\n",
      "loss: 0.396638  [29504/60000]\n",
      "loss: 0.200404  [30144/60000]\n",
      "loss: 0.260418  [30784/60000]\n",
      "loss: 0.131075  [31424/60000]\n",
      "loss: 0.149694  [32064/60000]\n",
      "loss: 0.181347  [32704/60000]\n",
      "loss: 0.342940  [33344/60000]\n",
      "loss: 0.155383  [33984/60000]\n",
      "loss: 0.132873  [34624/60000]\n",
      "loss: 0.175638  [35264/60000]\n",
      "loss: 0.220628  [35904/60000]\n",
      "loss: 0.268579  [36544/60000]\n",
      "loss: 0.259348  [37184/60000]\n",
      "loss: 0.227251  [37824/60000]\n",
      "loss: 0.181595  [38464/60000]\n",
      "loss: 0.099110  [39104/60000]\n",
      "loss: 0.268828  [39744/60000]\n",
      "loss: 0.217314  [40384/60000]\n",
      "loss: 0.194467  [41024/60000]\n",
      "loss: 0.201485  [41664/60000]\n",
      "loss: 0.231647  [42304/60000]\n",
      "loss: 0.109359  [42944/60000]\n",
      "loss: 0.188657  [43584/60000]\n",
      "loss: 0.268544  [44224/60000]\n",
      "loss: 0.339156  [44864/60000]\n",
      "loss: 0.181133  [45504/60000]\n",
      "loss: 0.115976  [46144/60000]\n",
      "loss: 0.175700  [46784/60000]\n",
      "loss: 0.262435  [47424/60000]\n",
      "loss: 0.166938  [48064/60000]\n",
      "loss: 0.165886  [48704/60000]\n",
      "loss: 0.244637  [49344/60000]\n",
      "loss: 0.211758  [49984/60000]\n",
      "loss: 0.177269  [50624/60000]\n",
      "loss: 0.203877  [51264/60000]\n",
      "loss: 0.261798  [51904/60000]\n",
      "loss: 0.193849  [52544/60000]\n",
      "loss: 0.157774  [53184/60000]\n",
      "loss: 0.174580  [53824/60000]\n",
      "loss: 0.102936  [54464/60000]\n",
      "loss: 0.216267  [55104/60000]\n",
      "loss: 0.131999  [55744/60000]\n",
      "loss: 0.132682  [56384/60000]\n",
      "loss: 0.307819  [57024/60000]\n",
      "loss: 0.114362  [57664/60000]\n",
      "loss: 0.121879  [58304/60000]\n",
      "loss: 0.241085  [58944/60000]\n",
      "loss: 0.314594  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245124 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.217589  [   64/60000]\n",
      "loss: 0.118553  [  704/60000]\n",
      "loss: 0.243973  [ 1344/60000]\n",
      "loss: 0.289244  [ 1984/60000]\n",
      "loss: 0.281390  [ 2624/60000]\n",
      "loss: 0.246402  [ 3264/60000]\n",
      "loss: 0.319215  [ 3904/60000]\n",
      "loss: 0.184476  [ 4544/60000]\n",
      "loss: 0.359738  [ 5184/60000]\n",
      "loss: 0.211746  [ 5824/60000]\n",
      "loss: 0.142014  [ 6464/60000]\n",
      "loss: 0.132281  [ 7104/60000]\n",
      "loss: 0.147538  [ 7744/60000]\n",
      "loss: 0.265940  [ 8384/60000]\n",
      "loss: 0.170473  [ 9024/60000]\n",
      "loss: 0.228196  [ 9664/60000]\n",
      "loss: 0.192776  [10304/60000]\n",
      "loss: 0.159687  [10944/60000]\n",
      "loss: 0.121795  [11584/60000]\n",
      "loss: 0.218933  [12224/60000]\n",
      "loss: 0.133270  [12864/60000]\n",
      "loss: 0.164984  [13504/60000]\n",
      "loss: 0.115904  [14144/60000]\n",
      "loss: 0.209499  [14784/60000]\n",
      "loss: 0.288174  [15424/60000]\n",
      "loss: 0.295941  [16064/60000]\n",
      "loss: 0.269080  [16704/60000]\n",
      "loss: 0.133802  [17344/60000]\n",
      "loss: 0.328386  [17984/60000]\n",
      "loss: 0.244103  [18624/60000]\n",
      "loss: 0.148434  [19264/60000]\n",
      "loss: 0.166147  [19904/60000]\n",
      "loss: 0.261964  [20544/60000]\n",
      "loss: 0.210262  [21184/60000]\n",
      "loss: 0.226203  [21824/60000]\n",
      "loss: 0.186948  [22464/60000]\n",
      "loss: 0.135107  [23104/60000]\n",
      "loss: 0.222110  [23744/60000]\n",
      "loss: 0.330042  [24384/60000]\n",
      "loss: 0.135263  [25024/60000]\n",
      "loss: 0.186863  [25664/60000]\n",
      "loss: 0.311890  [26304/60000]\n",
      "loss: 0.236587  [26944/60000]\n",
      "loss: 0.301422  [27584/60000]\n",
      "loss: 0.148992  [28224/60000]\n",
      "loss: 0.245770  [28864/60000]\n",
      "loss: 0.240896  [29504/60000]\n",
      "loss: 0.088331  [30144/60000]\n",
      "loss: 0.268695  [30784/60000]\n",
      "loss: 0.135817  [31424/60000]\n",
      "loss: 0.139514  [32064/60000]\n",
      "loss: 0.194245  [32704/60000]\n",
      "loss: 0.341280  [33344/60000]\n",
      "loss: 0.313578  [33984/60000]\n",
      "loss: 0.081045  [34624/60000]\n",
      "loss: 0.309609  [35264/60000]\n",
      "loss: 0.231128  [35904/60000]\n",
      "loss: 0.173470  [36544/60000]\n",
      "loss: 0.144985  [37184/60000]\n",
      "loss: 0.157786  [37824/60000]\n",
      "loss: 0.363985  [38464/60000]\n",
      "loss: 0.168886  [39104/60000]\n",
      "loss: 0.295073  [39744/60000]\n",
      "loss: 0.229150  [40384/60000]\n",
      "loss: 0.139181  [41024/60000]\n",
      "loss: 0.194124  [41664/60000]\n",
      "loss: 0.214729  [42304/60000]\n",
      "loss: 0.254349  [42944/60000]\n",
      "loss: 0.252803  [43584/60000]\n",
      "loss: 0.256484  [44224/60000]\n",
      "loss: 0.250347  [44864/60000]\n",
      "loss: 0.235033  [45504/60000]\n",
      "loss: 0.078835  [46144/60000]\n",
      "loss: 0.252789  [46784/60000]\n",
      "loss: 0.158026  [47424/60000]\n",
      "loss: 0.171262  [48064/60000]\n",
      "loss: 0.126599  [48704/60000]\n",
      "loss: 0.274394  [49344/60000]\n",
      "loss: 0.076034  [49984/60000]\n",
      "loss: 0.157797  [50624/60000]\n",
      "loss: 0.398475  [51264/60000]\n",
      "loss: 0.326344  [51904/60000]\n",
      "loss: 0.296375  [52544/60000]\n",
      "loss: 0.194354  [53184/60000]\n",
      "loss: 0.368496  [53824/60000]\n",
      "loss: 0.165633  [54464/60000]\n",
      "loss: 0.229131  [55104/60000]\n",
      "loss: 0.167672  [55744/60000]\n",
      "loss: 0.134586  [56384/60000]\n",
      "loss: 0.414580  [57024/60000]\n",
      "loss: 0.182955  [57664/60000]\n",
      "loss: 0.179428  [58304/60000]\n",
      "loss: 0.231504  [58944/60000]\n",
      "loss: 0.246061  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.252709 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.187031  [   64/60000]\n",
      "loss: 0.216943  [  704/60000]\n",
      "loss: 0.135676  [ 1344/60000]\n",
      "loss: 0.275173  [ 1984/60000]\n",
      "loss: 0.142692  [ 2624/60000]\n",
      "loss: 0.265654  [ 3264/60000]\n",
      "loss: 0.132197  [ 3904/60000]\n",
      "loss: 0.124135  [ 4544/60000]\n",
      "loss: 0.118769  [ 5184/60000]\n",
      "loss: 0.180978  [ 5824/60000]\n",
      "loss: 0.195412  [ 6464/60000]\n",
      "loss: 0.100981  [ 7104/60000]\n",
      "loss: 0.218925  [ 7744/60000]\n",
      "loss: 0.103800  [ 8384/60000]\n",
      "loss: 0.216045  [ 9024/60000]\n",
      "loss: 0.194790  [ 9664/60000]\n",
      "loss: 0.120943  [10304/60000]\n",
      "loss: 0.093480  [10944/60000]\n",
      "loss: 0.213489  [11584/60000]\n",
      "loss: 0.136795  [12224/60000]\n",
      "loss: 0.188997  [12864/60000]\n",
      "loss: 0.157311  [13504/60000]\n",
      "loss: 0.128613  [14144/60000]\n",
      "loss: 0.169569  [14784/60000]\n",
      "loss: 0.297384  [15424/60000]\n",
      "loss: 0.148042  [16064/60000]\n",
      "loss: 0.173095  [16704/60000]\n",
      "loss: 0.147280  [17344/60000]\n",
      "loss: 0.129317  [17984/60000]\n",
      "loss: 0.227389  [18624/60000]\n",
      "loss: 0.120847  [19264/60000]\n",
      "loss: 0.220278  [19904/60000]\n",
      "loss: 0.262124  [20544/60000]\n",
      "loss: 0.209246  [21184/60000]\n",
      "loss: 0.217991  [21824/60000]\n",
      "loss: 0.157964  [22464/60000]\n",
      "loss: 0.390414  [23104/60000]\n",
      "loss: 0.169988  [23744/60000]\n",
      "loss: 0.121471  [24384/60000]\n",
      "loss: 0.291859  [25024/60000]\n",
      "loss: 0.208540  [25664/60000]\n",
      "loss: 0.198543  [26304/60000]\n",
      "loss: 0.161116  [26944/60000]\n",
      "loss: 0.226730  [27584/60000]\n",
      "loss: 0.415612  [28224/60000]\n",
      "loss: 0.213428  [28864/60000]\n",
      "loss: 0.151041  [29504/60000]\n",
      "loss: 0.180711  [30144/60000]\n",
      "loss: 0.099843  [30784/60000]\n",
      "loss: 0.191514  [31424/60000]\n",
      "loss: 0.356360  [32064/60000]\n",
      "loss: 0.108721  [32704/60000]\n",
      "loss: 0.145025  [33344/60000]\n",
      "loss: 0.218277  [33984/60000]\n",
      "loss: 0.318053  [34624/60000]\n",
      "loss: 0.249894  [35264/60000]\n",
      "loss: 0.188475  [35904/60000]\n",
      "loss: 0.192932  [36544/60000]\n",
      "loss: 0.107438  [37184/60000]\n",
      "loss: 0.260624  [37824/60000]\n",
      "loss: 0.212104  [38464/60000]\n",
      "loss: 0.193269  [39104/60000]\n",
      "loss: 0.245461  [39744/60000]\n",
      "loss: 0.148079  [40384/60000]\n",
      "loss: 0.146045  [41024/60000]\n",
      "loss: 0.401857  [41664/60000]\n",
      "loss: 0.152692  [42304/60000]\n",
      "loss: 0.268044  [42944/60000]\n",
      "loss: 0.147178  [43584/60000]\n",
      "loss: 0.161253  [44224/60000]\n",
      "loss: 0.203628  [44864/60000]\n",
      "loss: 0.178778  [45504/60000]\n",
      "loss: 0.208762  [46144/60000]\n",
      "loss: 0.126136  [46784/60000]\n",
      "loss: 0.141205  [47424/60000]\n",
      "loss: 0.277958  [48064/60000]\n",
      "loss: 0.224633  [48704/60000]\n",
      "loss: 0.158217  [49344/60000]\n",
      "loss: 0.243556  [49984/60000]\n",
      "loss: 0.213603  [50624/60000]\n",
      "loss: 0.218961  [51264/60000]\n",
      "loss: 0.178136  [51904/60000]\n",
      "loss: 0.168788  [52544/60000]\n",
      "loss: 0.229635  [53184/60000]\n",
      "loss: 0.160163  [53824/60000]\n",
      "loss: 0.226953  [54464/60000]\n",
      "loss: 0.269542  [55104/60000]\n",
      "loss: 0.166177  [55744/60000]\n",
      "loss: 0.216635  [56384/60000]\n",
      "loss: 0.222281  [57024/60000]\n",
      "loss: 0.163696  [57664/60000]\n",
      "loss: 0.109547  [58304/60000]\n",
      "loss: 0.219488  [58944/60000]\n",
      "loss: 0.146646  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.252633 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.294378  [   64/60000]\n",
      "loss: 0.156949  [  704/60000]\n",
      "loss: 0.231319  [ 1344/60000]\n",
      "loss: 0.098593  [ 1984/60000]\n",
      "loss: 0.103157  [ 2624/60000]\n",
      "loss: 0.165463  [ 3264/60000]\n",
      "loss: 0.146369  [ 3904/60000]\n",
      "loss: 0.124765  [ 4544/60000]\n",
      "loss: 0.092838  [ 5184/60000]\n",
      "loss: 0.227562  [ 5824/60000]\n",
      "loss: 0.065618  [ 6464/60000]\n",
      "loss: 0.118243  [ 7104/60000]\n",
      "loss: 0.222967  [ 7744/60000]\n",
      "loss: 0.193657  [ 8384/60000]\n",
      "loss: 0.197227  [ 9024/60000]\n",
      "loss: 0.108039  [ 9664/60000]\n",
      "loss: 0.202047  [10304/60000]\n",
      "loss: 0.137533  [10944/60000]\n",
      "loss: 0.234634  [11584/60000]\n",
      "loss: 0.154397  [12224/60000]\n",
      "loss: 0.149532  [12864/60000]\n",
      "loss: 0.116124  [13504/60000]\n",
      "loss: 0.149608  [14144/60000]\n",
      "loss: 0.233101  [14784/60000]\n",
      "loss: 0.193315  [15424/60000]\n",
      "loss: 0.082170  [16064/60000]\n",
      "loss: 0.149505  [16704/60000]\n",
      "loss: 0.113013  [17344/60000]\n",
      "loss: 0.118582  [17984/60000]\n",
      "loss: 0.277115  [18624/60000]\n",
      "loss: 0.134648  [19264/60000]\n",
      "loss: 0.193982  [19904/60000]\n",
      "loss: 0.091456  [20544/60000]\n",
      "loss: 0.155821  [21184/60000]\n",
      "loss: 0.161065  [21824/60000]\n",
      "loss: 0.142893  [22464/60000]\n",
      "loss: 0.229156  [23104/60000]\n",
      "loss: 0.099582  [23744/60000]\n",
      "loss: 0.179445  [24384/60000]\n",
      "loss: 0.252427  [25024/60000]\n",
      "loss: 0.157089  [25664/60000]\n",
      "loss: 0.175778  [26304/60000]\n",
      "loss: 0.125173  [26944/60000]\n",
      "loss: 0.220627  [27584/60000]\n",
      "loss: 0.138158  [28224/60000]\n",
      "loss: 0.274003  [28864/60000]\n",
      "loss: 0.193928  [29504/60000]\n",
      "loss: 0.168671  [30144/60000]\n",
      "loss: 0.178957  [30784/60000]\n",
      "loss: 0.051893  [31424/60000]\n",
      "loss: 0.173100  [32064/60000]\n",
      "loss: 0.155584  [32704/60000]\n",
      "loss: 0.239768  [33344/60000]\n",
      "loss: 0.168422  [33984/60000]\n",
      "loss: 0.189656  [34624/60000]\n",
      "loss: 0.285111  [35264/60000]\n",
      "loss: 0.160565  [35904/60000]\n",
      "loss: 0.214107  [36544/60000]\n",
      "loss: 0.208849  [37184/60000]\n",
      "loss: 0.113119  [37824/60000]\n",
      "loss: 0.351756  [38464/60000]\n",
      "loss: 0.164072  [39104/60000]\n",
      "loss: 0.168476  [39744/60000]\n",
      "loss: 0.170430  [40384/60000]\n",
      "loss: 0.125511  [41024/60000]\n",
      "loss: 0.081939  [41664/60000]\n",
      "loss: 0.204497  [42304/60000]\n",
      "loss: 0.275390  [42944/60000]\n",
      "loss: 0.265205  [43584/60000]\n",
      "loss: 0.138666  [44224/60000]\n",
      "loss: 0.282294  [44864/60000]\n",
      "loss: 0.200786  [45504/60000]\n",
      "loss: 0.101487  [46144/60000]\n",
      "loss: 0.259029  [46784/60000]\n",
      "loss: 0.103272  [47424/60000]\n",
      "loss: 0.118586  [48064/60000]\n",
      "loss: 0.197606  [48704/60000]\n",
      "loss: 0.350658  [49344/60000]\n",
      "loss: 0.198778  [49984/60000]\n",
      "loss: 0.143451  [50624/60000]\n",
      "loss: 0.090532  [51264/60000]\n",
      "loss: 0.285938  [51904/60000]\n",
      "loss: 0.153378  [52544/60000]\n",
      "loss: 0.254630  [53184/60000]\n",
      "loss: 0.233777  [53824/60000]\n",
      "loss: 0.223705  [54464/60000]\n",
      "loss: 0.151720  [55104/60000]\n",
      "loss: 0.292838  [55744/60000]\n",
      "loss: 0.086235  [56384/60000]\n",
      "loss: 0.104186  [57024/60000]\n",
      "loss: 0.135362  [57664/60000]\n",
      "loss: 0.261242  [58304/60000]\n",
      "loss: 0.155852  [58944/60000]\n",
      "loss: 0.099855  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.251356 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.158243  [   64/60000]\n",
      "loss: 0.261067  [  704/60000]\n",
      "loss: 0.097292  [ 1344/60000]\n",
      "loss: 0.210828  [ 1984/60000]\n",
      "loss: 0.145548  [ 2624/60000]\n",
      "loss: 0.143957  [ 3264/60000]\n",
      "loss: 0.279323  [ 3904/60000]\n",
      "loss: 0.284039  [ 4544/60000]\n",
      "loss: 0.195262  [ 5184/60000]\n",
      "loss: 0.086034  [ 5824/60000]\n",
      "loss: 0.382931  [ 6464/60000]\n",
      "loss: 0.460395  [ 7104/60000]\n",
      "loss: 0.193178  [ 7744/60000]\n",
      "loss: 0.253825  [ 8384/60000]\n",
      "loss: 0.174622  [ 9024/60000]\n",
      "loss: 0.210601  [ 9664/60000]\n",
      "loss: 0.172013  [10304/60000]\n",
      "loss: 0.131317  [10944/60000]\n",
      "loss: 0.153334  [11584/60000]\n",
      "loss: 0.109076  [12224/60000]\n",
      "loss: 0.220004  [12864/60000]\n",
      "loss: 0.277001  [13504/60000]\n",
      "loss: 0.169309  [14144/60000]\n",
      "loss: 0.151819  [14784/60000]\n",
      "loss: 0.170742  [15424/60000]\n",
      "loss: 0.233024  [16064/60000]\n",
      "loss: 0.160634  [16704/60000]\n",
      "loss: 0.338133  [17344/60000]\n",
      "loss: 0.250936  [17984/60000]\n",
      "loss: 0.115524  [18624/60000]\n",
      "loss: 0.250330  [19264/60000]\n",
      "loss: 0.303605  [19904/60000]\n",
      "loss: 0.277749  [20544/60000]\n",
      "loss: 0.324527  [21184/60000]\n",
      "loss: 0.257431  [21824/60000]\n",
      "loss: 0.163748  [22464/60000]\n",
      "loss: 0.088770  [23104/60000]\n",
      "loss: 0.237077  [23744/60000]\n",
      "loss: 0.309928  [24384/60000]\n",
      "loss: 0.105442  [25024/60000]\n",
      "loss: 0.189969  [25664/60000]\n",
      "loss: 0.261806  [26304/60000]\n",
      "loss: 0.228880  [26944/60000]\n",
      "loss: 0.196352  [27584/60000]\n",
      "loss: 0.262205  [28224/60000]\n",
      "loss: 0.146585  [28864/60000]\n",
      "loss: 0.123600  [29504/60000]\n",
      "loss: 0.250300  [30144/60000]\n",
      "loss: 0.207687  [30784/60000]\n",
      "loss: 0.101557  [31424/60000]\n",
      "loss: 0.193247  [32064/60000]\n",
      "loss: 0.174983  [32704/60000]\n",
      "loss: 0.193914  [33344/60000]\n",
      "loss: 0.175120  [33984/60000]\n",
      "loss: 0.147708  [34624/60000]\n",
      "loss: 0.126041  [35264/60000]\n",
      "loss: 0.118074  [35904/60000]\n",
      "loss: 0.095341  [36544/60000]\n",
      "loss: 0.290575  [37184/60000]\n",
      "loss: 0.227745  [37824/60000]\n",
      "loss: 0.118184  [38464/60000]\n",
      "loss: 0.162146  [39104/60000]\n",
      "loss: 0.069611  [39744/60000]\n",
      "loss: 0.218607  [40384/60000]\n",
      "loss: 0.182053  [41024/60000]\n",
      "loss: 0.137136  [41664/60000]\n",
      "loss: 0.051470  [42304/60000]\n",
      "loss: 0.188902  [42944/60000]\n",
      "loss: 0.225706  [43584/60000]\n",
      "loss: 0.111088  [44224/60000]\n",
      "loss: 0.232488  [44864/60000]\n",
      "loss: 0.137021  [45504/60000]\n",
      "loss: 0.169518  [46144/60000]\n",
      "loss: 0.244925  [46784/60000]\n",
      "loss: 0.254361  [47424/60000]\n",
      "loss: 0.144689  [48064/60000]\n",
      "loss: 0.136076  [48704/60000]\n",
      "loss: 0.128850  [49344/60000]\n",
      "loss: 0.330752  [49984/60000]\n",
      "loss: 0.300091  [50624/60000]\n",
      "loss: 0.245368  [51264/60000]\n",
      "loss: 0.149913  [51904/60000]\n",
      "loss: 0.186114  [52544/60000]\n",
      "loss: 0.077048  [53184/60000]\n",
      "loss: 0.177882  [53824/60000]\n",
      "loss: 0.114185  [54464/60000]\n",
      "loss: 0.137917  [55104/60000]\n",
      "loss: 0.190153  [55744/60000]\n",
      "loss: 0.248693  [56384/60000]\n",
      "loss: 0.152330  [57024/60000]\n",
      "loss: 0.233662  [57664/60000]\n",
      "loss: 0.129309  [58304/60000]\n",
      "loss: 0.210035  [58944/60000]\n",
      "loss: 0.179899  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.248867 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.249708  [   64/60000]\n",
      "loss: 0.106252  [  704/60000]\n",
      "loss: 0.150910  [ 1344/60000]\n",
      "loss: 0.147822  [ 1984/60000]\n",
      "loss: 0.162784  [ 2624/60000]\n",
      "loss: 0.418448  [ 3264/60000]\n",
      "loss: 0.274045  [ 3904/60000]\n",
      "loss: 0.168583  [ 4544/60000]\n",
      "loss: 0.074921  [ 5184/60000]\n",
      "loss: 0.140451  [ 5824/60000]\n",
      "loss: 0.113086  [ 6464/60000]\n",
      "loss: 0.128389  [ 7104/60000]\n",
      "loss: 0.144391  [ 7744/60000]\n",
      "loss: 0.213540  [ 8384/60000]\n",
      "loss: 0.210075  [ 9024/60000]\n",
      "loss: 0.281063  [ 9664/60000]\n",
      "loss: 0.156792  [10304/60000]\n",
      "loss: 0.199383  [10944/60000]\n",
      "loss: 0.228739  [11584/60000]\n",
      "loss: 0.288954  [12224/60000]\n",
      "loss: 0.252751  [12864/60000]\n",
      "loss: 0.223963  [13504/60000]\n",
      "loss: 0.195678  [14144/60000]\n",
      "loss: 0.208133  [14784/60000]\n",
      "loss: 0.112441  [15424/60000]\n",
      "loss: 0.218702  [16064/60000]\n",
      "loss: 0.124385  [16704/60000]\n",
      "loss: 0.151245  [17344/60000]\n",
      "loss: 0.109821  [17984/60000]\n",
      "loss: 0.118017  [18624/60000]\n",
      "loss: 0.197834  [19264/60000]\n",
      "loss: 0.123045  [19904/60000]\n",
      "loss: 0.088466  [20544/60000]\n",
      "loss: 0.246330  [21184/60000]\n",
      "loss: 0.186676  [21824/60000]\n",
      "loss: 0.135956  [22464/60000]\n",
      "loss: 0.152906  [23104/60000]\n",
      "loss: 0.204754  [23744/60000]\n",
      "loss: 0.205310  [24384/60000]\n",
      "loss: 0.176343  [25024/60000]\n",
      "loss: 0.138696  [25664/60000]\n",
      "loss: 0.158820  [26304/60000]\n",
      "loss: 0.129257  [26944/60000]\n",
      "loss: 0.239337  [27584/60000]\n",
      "loss: 0.278094  [28224/60000]\n",
      "loss: 0.146606  [28864/60000]\n",
      "loss: 0.170100  [29504/60000]\n",
      "loss: 0.271768  [30144/60000]\n",
      "loss: 0.133038  [30784/60000]\n",
      "loss: 0.141781  [31424/60000]\n",
      "loss: 0.305263  [32064/60000]\n",
      "loss: 0.299574  [32704/60000]\n",
      "loss: 0.213427  [33344/60000]\n",
      "loss: 0.426805  [33984/60000]\n",
      "loss: 0.225047  [34624/60000]\n",
      "loss: 0.112727  [35264/60000]\n",
      "loss: 0.143867  [35904/60000]\n",
      "loss: 0.229040  [36544/60000]\n",
      "loss: 0.235417  [37184/60000]\n",
      "loss: 0.192873  [37824/60000]\n",
      "loss: 0.160659  [38464/60000]\n",
      "loss: 0.243362  [39104/60000]\n",
      "loss: 0.214897  [39744/60000]\n",
      "loss: 0.177704  [40384/60000]\n",
      "loss: 0.118275  [41024/60000]\n",
      "loss: 0.162745  [41664/60000]\n",
      "loss: 0.270199  [42304/60000]\n",
      "loss: 0.094291  [42944/60000]\n",
      "loss: 0.239872  [43584/60000]\n",
      "loss: 0.164165  [44224/60000]\n",
      "loss: 0.144936  [44864/60000]\n",
      "loss: 0.316965  [45504/60000]\n",
      "loss: 0.089713  [46144/60000]\n",
      "loss: 0.120247  [46784/60000]\n",
      "loss: 0.323594  [47424/60000]\n",
      "loss: 0.156470  [48064/60000]\n",
      "loss: 0.135967  [48704/60000]\n",
      "loss: 0.252544  [49344/60000]\n",
      "loss: 0.112144  [49984/60000]\n",
      "loss: 0.253350  [50624/60000]\n",
      "loss: 0.175115  [51264/60000]\n",
      "loss: 0.263432  [51904/60000]\n",
      "loss: 0.093711  [52544/60000]\n",
      "loss: 0.078453  [53184/60000]\n",
      "loss: 0.183787  [53824/60000]\n",
      "loss: 0.187989  [54464/60000]\n",
      "loss: 0.315574  [55104/60000]\n",
      "loss: 0.264921  [55744/60000]\n",
      "loss: 0.244671  [56384/60000]\n",
      "loss: 0.127779  [57024/60000]\n",
      "loss: 0.194313  [57664/60000]\n",
      "loss: 0.235655  [58304/60000]\n",
      "loss: 0.181240  [58944/60000]\n",
      "loss: 0.267405  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.250936 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.316726  [   64/60000]\n",
      "loss: 0.209761  [  704/60000]\n",
      "loss: 0.190389  [ 1344/60000]\n",
      "loss: 0.112362  [ 1984/60000]\n",
      "loss: 0.221615  [ 2624/60000]\n",
      "loss: 0.158906  [ 3264/60000]\n",
      "loss: 0.232390  [ 3904/60000]\n",
      "loss: 0.299164  [ 4544/60000]\n",
      "loss: 0.103528  [ 5184/60000]\n",
      "loss: 0.183834  [ 5824/60000]\n",
      "loss: 0.077421  [ 6464/60000]\n",
      "loss: 0.217538  [ 7104/60000]\n",
      "loss: 0.103669  [ 7744/60000]\n",
      "loss: 0.082236  [ 8384/60000]\n",
      "loss: 0.164848  [ 9024/60000]\n",
      "loss: 0.154833  [ 9664/60000]\n",
      "loss: 0.291101  [10304/60000]\n",
      "loss: 0.195269  [10944/60000]\n",
      "loss: 0.269776  [11584/60000]\n",
      "loss: 0.326750  [12224/60000]\n",
      "loss: 0.252355  [12864/60000]\n",
      "loss: 0.222813  [13504/60000]\n",
      "loss: 0.253312  [14144/60000]\n",
      "loss: 0.216155  [14784/60000]\n",
      "loss: 0.192601  [15424/60000]\n",
      "loss: 0.308925  [16064/60000]\n",
      "loss: 0.175444  [16704/60000]\n",
      "loss: 0.132055  [17344/60000]\n",
      "loss: 0.068863  [17984/60000]\n",
      "loss: 0.268546  [18624/60000]\n",
      "loss: 0.320321  [19264/60000]\n",
      "loss: 0.186525  [19904/60000]\n",
      "loss: 0.253617  [20544/60000]\n",
      "loss: 0.263765  [21184/60000]\n",
      "loss: 0.070472  [21824/60000]\n",
      "loss: 0.395801  [22464/60000]\n",
      "loss: 0.253373  [23104/60000]\n",
      "loss: 0.099966  [23744/60000]\n",
      "loss: 0.282346  [24384/60000]\n",
      "loss: 0.173386  [25024/60000]\n",
      "loss: 0.148070  [25664/60000]\n",
      "loss: 0.306130  [26304/60000]\n",
      "loss: 0.113087  [26944/60000]\n",
      "loss: 0.162335  [27584/60000]\n",
      "loss: 0.178883  [28224/60000]\n",
      "loss: 0.250832  [28864/60000]\n",
      "loss: 0.088047  [29504/60000]\n",
      "loss: 0.198325  [30144/60000]\n",
      "loss: 0.136596  [30784/60000]\n",
      "loss: 0.272327  [31424/60000]\n",
      "loss: 0.114427  [32064/60000]\n",
      "loss: 0.250222  [32704/60000]\n",
      "loss: 0.158689  [33344/60000]\n",
      "loss: 0.251232  [33984/60000]\n",
      "loss: 0.364122  [34624/60000]\n",
      "loss: 0.285933  [35264/60000]\n",
      "loss: 0.288059  [35904/60000]\n",
      "loss: 0.370126  [36544/60000]\n",
      "loss: 0.121245  [37184/60000]\n",
      "loss: 0.354802  [37824/60000]\n",
      "loss: 0.238970  [38464/60000]\n",
      "loss: 0.133543  [39104/60000]\n",
      "loss: 0.223503  [39744/60000]\n",
      "loss: 0.156217  [40384/60000]\n",
      "loss: 0.137682  [41024/60000]\n",
      "loss: 0.281644  [41664/60000]\n",
      "loss: 0.217022  [42304/60000]\n",
      "loss: 0.162645  [42944/60000]\n",
      "loss: 0.134788  [43584/60000]\n",
      "loss: 0.107798  [44224/60000]\n",
      "loss: 0.167710  [44864/60000]\n",
      "loss: 0.167595  [45504/60000]\n",
      "loss: 0.254672  [46144/60000]\n",
      "loss: 0.196331  [46784/60000]\n",
      "loss: 0.048437  [47424/60000]\n",
      "loss: 0.179242  [48064/60000]\n",
      "loss: 0.114050  [48704/60000]\n",
      "loss: 0.100276  [49344/60000]\n",
      "loss: 0.167860  [49984/60000]\n",
      "loss: 0.285194  [50624/60000]\n",
      "loss: 0.124696  [51264/60000]\n",
      "loss: 0.178683  [51904/60000]\n",
      "loss: 0.158731  [52544/60000]\n",
      "loss: 0.166452  [53184/60000]\n",
      "loss: 0.125540  [53824/60000]\n",
      "loss: 0.090699  [54464/60000]\n",
      "loss: 0.189657  [55104/60000]\n",
      "loss: 0.122580  [55744/60000]\n",
      "loss: 0.327123  [56384/60000]\n",
      "loss: 0.356756  [57024/60000]\n",
      "loss: 0.312050  [57664/60000]\n",
      "loss: 0.107717  [58304/60000]\n",
      "loss: 0.101163  [58944/60000]\n",
      "loss: 0.286891  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.252005 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.323739  [   64/60000]\n",
      "loss: 0.118245  [  704/60000]\n",
      "loss: 0.126209  [ 1344/60000]\n",
      "loss: 0.272247  [ 1984/60000]\n",
      "loss: 0.214228  [ 2624/60000]\n",
      "loss: 0.254613  [ 3264/60000]\n",
      "loss: 0.225432  [ 3904/60000]\n",
      "loss: 0.185706  [ 4544/60000]\n",
      "loss: 0.083871  [ 5184/60000]\n",
      "loss: 0.076446  [ 5824/60000]\n",
      "loss: 0.108447  [ 6464/60000]\n",
      "loss: 0.156214  [ 7104/60000]\n",
      "loss: 0.139017  [ 7744/60000]\n",
      "loss: 0.336148  [ 8384/60000]\n",
      "loss: 0.150488  [ 9024/60000]\n",
      "loss: 0.132347  [ 9664/60000]\n",
      "loss: 0.151446  [10304/60000]\n",
      "loss: 0.091820  [10944/60000]\n",
      "loss: 0.113807  [11584/60000]\n",
      "loss: 0.093023  [12224/60000]\n",
      "loss: 0.276463  [12864/60000]\n",
      "loss: 0.209215  [13504/60000]\n",
      "loss: 0.303847  [14144/60000]\n",
      "loss: 0.193711  [14784/60000]\n",
      "loss: 0.151129  [15424/60000]\n",
      "loss: 0.168350  [16064/60000]\n",
      "loss: 0.199594  [16704/60000]\n",
      "loss: 0.306304  [17344/60000]\n",
      "loss: 0.255751  [17984/60000]\n",
      "loss: 0.216708  [18624/60000]\n",
      "loss: 0.119413  [19264/60000]\n",
      "loss: 0.047161  [19904/60000]\n",
      "loss: 0.090547  [20544/60000]\n",
      "loss: 0.101083  [21184/60000]\n",
      "loss: 0.296369  [21824/60000]\n",
      "loss: 0.142466  [22464/60000]\n",
      "loss: 0.122744  [23104/60000]\n",
      "loss: 0.228367  [23744/60000]\n",
      "loss: 0.141344  [24384/60000]\n",
      "loss: 0.198967  [25024/60000]\n",
      "loss: 0.195584  [25664/60000]\n",
      "loss: 0.255018  [26304/60000]\n",
      "loss: 0.073127  [26944/60000]\n",
      "loss: 0.195198  [27584/60000]\n",
      "loss: 0.101726  [28224/60000]\n",
      "loss: 0.298728  [28864/60000]\n",
      "loss: 0.162117  [29504/60000]\n",
      "loss: 0.409140  [30144/60000]\n",
      "loss: 0.163092  [30784/60000]\n",
      "loss: 0.241966  [31424/60000]\n",
      "loss: 0.127385  [32064/60000]\n",
      "loss: 0.197884  [32704/60000]\n",
      "loss: 0.095939  [33344/60000]\n",
      "loss: 0.127591  [33984/60000]\n",
      "loss: 0.149121  [34624/60000]\n",
      "loss: 0.120402  [35264/60000]\n",
      "loss: 0.257502  [35904/60000]\n",
      "loss: 0.153496  [36544/60000]\n",
      "loss: 0.057419  [37184/60000]\n",
      "loss: 0.146409  [37824/60000]\n",
      "loss: 0.125594  [38464/60000]\n",
      "loss: 0.076681  [39104/60000]\n",
      "loss: 0.207820  [39744/60000]\n",
      "loss: 0.082655  [40384/60000]\n",
      "loss: 0.392754  [41024/60000]\n",
      "loss: 0.217440  [41664/60000]\n",
      "loss: 0.148754  [42304/60000]\n",
      "loss: 0.360094  [42944/60000]\n",
      "loss: 0.140298  [43584/60000]\n",
      "loss: 0.311516  [44224/60000]\n",
      "loss: 0.260752  [44864/60000]\n",
      "loss: 0.144908  [45504/60000]\n",
      "loss: 0.052568  [46144/60000]\n",
      "loss: 0.182152  [46784/60000]\n",
      "loss: 0.098021  [47424/60000]\n",
      "loss: 0.099988  [48064/60000]\n",
      "loss: 0.130311  [48704/60000]\n",
      "loss: 0.075206  [49344/60000]\n",
      "loss: 0.105737  [49984/60000]\n",
      "loss: 0.176043  [50624/60000]\n",
      "loss: 0.136531  [51264/60000]\n",
      "loss: 0.223380  [51904/60000]\n",
      "loss: 0.147010  [52544/60000]\n",
      "loss: 0.097002  [53184/60000]\n",
      "loss: 0.125409  [53824/60000]\n",
      "loss: 0.253378  [54464/60000]\n",
      "loss: 0.267876  [55104/60000]\n",
      "loss: 0.132961  [55744/60000]\n",
      "loss: 0.189168  [56384/60000]\n",
      "loss: 0.277767  [57024/60000]\n",
      "loss: 0.221447  [57664/60000]\n",
      "loss: 0.116510  [58304/60000]\n",
      "loss: 0.267018  [58944/60000]\n",
      "loss: 0.102494  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.248145 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.226350  [   64/60000]\n",
      "loss: 0.078449  [  704/60000]\n",
      "loss: 0.086050  [ 1344/60000]\n",
      "loss: 0.168210  [ 1984/60000]\n",
      "loss: 0.091479  [ 2624/60000]\n",
      "loss: 0.297826  [ 3264/60000]\n",
      "loss: 0.109514  [ 3904/60000]\n",
      "loss: 0.195892  [ 4544/60000]\n",
      "loss: 0.084865  [ 5184/60000]\n",
      "loss: 0.157841  [ 5824/60000]\n",
      "loss: 0.259366  [ 6464/60000]\n",
      "loss: 0.172532  [ 7104/60000]\n",
      "loss: 0.078312  [ 7744/60000]\n",
      "loss: 0.274949  [ 8384/60000]\n",
      "loss: 0.109433  [ 9024/60000]\n",
      "loss: 0.252570  [ 9664/60000]\n",
      "loss: 0.127228  [10304/60000]\n",
      "loss: 0.079472  [10944/60000]\n",
      "loss: 0.165138  [11584/60000]\n",
      "loss: 0.141430  [12224/60000]\n",
      "loss: 0.148363  [12864/60000]\n",
      "loss: 0.223330  [13504/60000]\n",
      "loss: 0.200138  [14144/60000]\n",
      "loss: 0.063019  [14784/60000]\n",
      "loss: 0.239345  [15424/60000]\n",
      "loss: 0.158472  [16064/60000]\n",
      "loss: 0.101746  [16704/60000]\n",
      "loss: 0.117509  [17344/60000]\n",
      "loss: 0.145068  [17984/60000]\n",
      "loss: 0.100094  [18624/60000]\n",
      "loss: 0.108731  [19264/60000]\n",
      "loss: 0.102771  [19904/60000]\n",
      "loss: 0.211435  [20544/60000]\n",
      "loss: 0.091857  [21184/60000]\n",
      "loss: 0.254733  [21824/60000]\n",
      "loss: 0.193031  [22464/60000]\n",
      "loss: 0.278968  [23104/60000]\n",
      "loss: 0.278689  [23744/60000]\n",
      "loss: 0.113898  [24384/60000]\n",
      "loss: 0.173866  [25024/60000]\n",
      "loss: 0.147547  [25664/60000]\n",
      "loss: 0.062064  [26304/60000]\n",
      "loss: 0.101768  [26944/60000]\n",
      "loss: 0.140635  [27584/60000]\n",
      "loss: 0.122123  [28224/60000]\n",
      "loss: 0.295930  [28864/60000]\n",
      "loss: 0.212584  [29504/60000]\n",
      "loss: 0.121525  [30144/60000]\n",
      "loss: 0.105659  [30784/60000]\n",
      "loss: 0.099163  [31424/60000]\n",
      "loss: 0.237768  [32064/60000]\n",
      "loss: 0.370239  [32704/60000]\n",
      "loss: 0.133872  [33344/60000]\n",
      "loss: 0.220610  [33984/60000]\n",
      "loss: 0.131115  [34624/60000]\n",
      "loss: 0.219430  [35264/60000]\n",
      "loss: 0.185556  [35904/60000]\n",
      "loss: 0.260884  [36544/60000]\n",
      "loss: 0.135615  [37184/60000]\n",
      "loss: 0.146142  [37824/60000]\n",
      "loss: 0.194585  [38464/60000]\n",
      "loss: 0.054105  [39104/60000]\n",
      "loss: 0.173747  [39744/60000]\n",
      "loss: 0.215598  [40384/60000]\n",
      "loss: 0.236208  [41024/60000]\n",
      "loss: 0.146109  [41664/60000]\n",
      "loss: 0.214809  [42304/60000]\n",
      "loss: 0.184309  [42944/60000]\n",
      "loss: 0.143796  [43584/60000]\n",
      "loss: 0.181640  [44224/60000]\n",
      "loss: 0.057795  [44864/60000]\n",
      "loss: 0.184787  [45504/60000]\n",
      "loss: 0.110782  [46144/60000]\n",
      "loss: 0.225150  [46784/60000]\n",
      "loss: 0.193936  [47424/60000]\n",
      "loss: 0.167188  [48064/60000]\n",
      "loss: 0.131088  [48704/60000]\n",
      "loss: 0.270780  [49344/60000]\n",
      "loss: 0.065773  [49984/60000]\n",
      "loss: 0.329973  [50624/60000]\n",
      "loss: 0.106474  [51264/60000]\n",
      "loss: 0.124723  [51904/60000]\n",
      "loss: 0.110434  [52544/60000]\n",
      "loss: 0.186697  [53184/60000]\n",
      "loss: 0.072260  [53824/60000]\n",
      "loss: 0.152492  [54464/60000]\n",
      "loss: 0.086544  [55104/60000]\n",
      "loss: 0.191128  [55744/60000]\n",
      "loss: 0.312188  [56384/60000]\n",
      "loss: 0.244006  [57024/60000]\n",
      "loss: 0.179029  [57664/60000]\n",
      "loss: 0.239621  [58304/60000]\n",
      "loss: 0.178497  [58944/60000]\n",
      "loss: 0.266146  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.245775 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.070025  [   64/60000]\n",
      "loss: 0.164167  [  704/60000]\n",
      "loss: 0.241488  [ 1344/60000]\n",
      "loss: 0.169290  [ 1984/60000]\n",
      "loss: 0.140355  [ 2624/60000]\n",
      "loss: 0.194379  [ 3264/60000]\n",
      "loss: 0.160462  [ 3904/60000]\n",
      "loss: 0.101824  [ 4544/60000]\n",
      "loss: 0.160087  [ 5184/60000]\n",
      "loss: 0.180755  [ 5824/60000]\n",
      "loss: 0.125603  [ 6464/60000]\n",
      "loss: 0.053213  [ 7104/60000]\n",
      "loss: 0.129219  [ 7744/60000]\n",
      "loss: 0.203487  [ 8384/60000]\n",
      "loss: 0.238099  [ 9024/60000]\n",
      "loss: 0.205812  [ 9664/60000]\n",
      "loss: 0.083980  [10304/60000]\n",
      "loss: 0.301658  [10944/60000]\n",
      "loss: 0.146220  [11584/60000]\n",
      "loss: 0.226744  [12224/60000]\n",
      "loss: 0.373803  [12864/60000]\n",
      "loss: 0.099522  [13504/60000]\n",
      "loss: 0.094876  [14144/60000]\n",
      "loss: 0.316105  [14784/60000]\n",
      "loss: 0.081508  [15424/60000]\n",
      "loss: 0.166025  [16064/60000]\n",
      "loss: 0.268038  [16704/60000]\n",
      "loss: 0.072151  [17344/60000]\n",
      "loss: 0.175881  [17984/60000]\n",
      "loss: 0.151437  [18624/60000]\n",
      "loss: 0.220711  [19264/60000]\n",
      "loss: 0.147471  [19904/60000]\n",
      "loss: 0.144645  [20544/60000]\n",
      "loss: 0.120190  [21184/60000]\n",
      "loss: 0.154345  [21824/60000]\n",
      "loss: 0.061688  [22464/60000]\n",
      "loss: 0.131944  [23104/60000]\n",
      "loss: 0.229818  [23744/60000]\n",
      "loss: 0.048544  [24384/60000]\n",
      "loss: 0.108210  [25024/60000]\n",
      "loss: 0.275825  [25664/60000]\n",
      "loss: 0.130496  [26304/60000]\n",
      "loss: 0.229804  [26944/60000]\n",
      "loss: 0.106608  [27584/60000]\n",
      "loss: 0.093152  [28224/60000]\n",
      "loss: 0.146717  [28864/60000]\n",
      "loss: 0.318235  [29504/60000]\n",
      "loss: 0.217098  [30144/60000]\n",
      "loss: 0.181035  [30784/60000]\n",
      "loss: 0.279190  [31424/60000]\n",
      "loss: 0.163020  [32064/60000]\n",
      "loss: 0.259090  [32704/60000]\n",
      "loss: 0.206195  [33344/60000]\n",
      "loss: 0.176935  [33984/60000]\n",
      "loss: 0.163129  [34624/60000]\n",
      "loss: 0.196073  [35264/60000]\n",
      "loss: 0.166634  [35904/60000]\n",
      "loss: 0.228255  [36544/60000]\n",
      "loss: 0.143754  [37184/60000]\n",
      "loss: 0.187855  [37824/60000]\n",
      "loss: 0.168891  [38464/60000]\n",
      "loss: 0.202237  [39104/60000]\n",
      "loss: 0.167528  [39744/60000]\n",
      "loss: 0.128651  [40384/60000]\n",
      "loss: 0.221793  [41024/60000]\n",
      "loss: 0.118450  [41664/60000]\n",
      "loss: 0.062301  [42304/60000]\n",
      "loss: 0.051805  [42944/60000]\n",
      "loss: 0.186322  [43584/60000]\n",
      "loss: 0.183082  [44224/60000]\n",
      "loss: 0.146061  [44864/60000]\n",
      "loss: 0.044784  [45504/60000]\n",
      "loss: 0.197952  [46144/60000]\n",
      "loss: 0.194497  [46784/60000]\n",
      "loss: 0.231486  [47424/60000]\n",
      "loss: 0.228337  [48064/60000]\n",
      "loss: 0.329080  [48704/60000]\n",
      "loss: 0.284672  [49344/60000]\n",
      "loss: 0.249502  [49984/60000]\n",
      "loss: 0.137277  [50624/60000]\n",
      "loss: 0.164618  [51264/60000]\n",
      "loss: 0.214540  [51904/60000]\n",
      "loss: 0.303214  [52544/60000]\n",
      "loss: 0.209551  [53184/60000]\n",
      "loss: 0.272815  [53824/60000]\n",
      "loss: 0.159785  [54464/60000]\n",
      "loss: 0.212436  [55104/60000]\n",
      "loss: 0.156401  [55744/60000]\n",
      "loss: 0.269405  [56384/60000]\n",
      "loss: 0.137451  [57024/60000]\n",
      "loss: 0.153508  [57664/60000]\n",
      "loss: 0.087160  [58304/60000]\n",
      "loss: 0.078029  [58944/60000]\n",
      "loss: 0.190930  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.246851 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.166051  [   64/60000]\n",
      "loss: 0.233401  [  704/60000]\n",
      "loss: 0.165097  [ 1344/60000]\n",
      "loss: 0.169160  [ 1984/60000]\n",
      "loss: 0.244441  [ 2624/60000]\n",
      "loss: 0.246962  [ 3264/60000]\n",
      "loss: 0.056723  [ 3904/60000]\n",
      "loss: 0.106797  [ 4544/60000]\n",
      "loss: 0.118375  [ 5184/60000]\n",
      "loss: 0.188633  [ 5824/60000]\n",
      "loss: 0.136648  [ 6464/60000]\n",
      "loss: 0.262259  [ 7104/60000]\n",
      "loss: 0.136653  [ 7744/60000]\n",
      "loss: 0.120520  [ 8384/60000]\n",
      "loss: 0.074239  [ 9024/60000]\n",
      "loss: 0.164151  [ 9664/60000]\n",
      "loss: 0.093758  [10304/60000]\n",
      "loss: 0.142851  [10944/60000]\n",
      "loss: 0.154577  [11584/60000]\n",
      "loss: 0.127658  [12224/60000]\n",
      "loss: 0.208582  [12864/60000]\n",
      "loss: 0.191865  [13504/60000]\n",
      "loss: 0.110855  [14144/60000]\n",
      "loss: 0.070714  [14784/60000]\n",
      "loss: 0.139103  [15424/60000]\n",
      "loss: 0.153291  [16064/60000]\n",
      "loss: 0.103656  [16704/60000]\n",
      "loss: 0.211614  [17344/60000]\n",
      "loss: 0.189193  [17984/60000]\n",
      "loss: 0.304845  [18624/60000]\n",
      "loss: 0.088816  [19264/60000]\n",
      "loss: 0.254793  [19904/60000]\n",
      "loss: 0.123191  [20544/60000]\n",
      "loss: 0.110444  [21184/60000]\n",
      "loss: 0.145074  [21824/60000]\n",
      "loss: 0.161513  [22464/60000]\n",
      "loss: 0.049848  [23104/60000]\n",
      "loss: 0.093305  [23744/60000]\n",
      "loss: 0.103907  [24384/60000]\n",
      "loss: 0.164149  [25024/60000]\n",
      "loss: 0.220478  [25664/60000]\n",
      "loss: 0.131525  [26304/60000]\n",
      "loss: 0.145444  [26944/60000]\n",
      "loss: 0.236754  [27584/60000]\n",
      "loss: 0.082545  [28224/60000]\n",
      "loss: 0.183104  [28864/60000]\n",
      "loss: 0.159932  [29504/60000]\n",
      "loss: 0.205262  [30144/60000]\n",
      "loss: 0.141996  [30784/60000]\n",
      "loss: 0.187290  [31424/60000]\n",
      "loss: 0.141272  [32064/60000]\n",
      "loss: 0.201419  [32704/60000]\n",
      "loss: 0.209717  [33344/60000]\n",
      "loss: 0.222466  [33984/60000]\n",
      "loss: 0.209143  [34624/60000]\n",
      "loss: 0.096532  [35264/60000]\n",
      "loss: 0.237873  [35904/60000]\n",
      "loss: 0.189378  [36544/60000]\n",
      "loss: 0.128090  [37184/60000]\n",
      "loss: 0.260762  [37824/60000]\n",
      "loss: 0.090029  [38464/60000]\n",
      "loss: 0.203965  [39104/60000]\n",
      "loss: 0.186004  [39744/60000]\n",
      "loss: 0.172720  [40384/60000]\n",
      "loss: 0.091707  [41024/60000]\n",
      "loss: 0.098550  [41664/60000]\n",
      "loss: 0.173142  [42304/60000]\n",
      "loss: 0.162328  [42944/60000]\n",
      "loss: 0.282928  [43584/60000]\n",
      "loss: 0.280482  [44224/60000]\n",
      "loss: 0.129307  [44864/60000]\n",
      "loss: 0.177242  [45504/60000]\n",
      "loss: 0.213052  [46144/60000]\n",
      "loss: 0.149000  [46784/60000]\n",
      "loss: 0.238973  [47424/60000]\n",
      "loss: 0.111252  [48064/60000]\n",
      "loss: 0.207918  [48704/60000]\n",
      "loss: 0.148802  [49344/60000]\n",
      "loss: 0.111623  [49984/60000]\n",
      "loss: 0.203653  [50624/60000]\n",
      "loss: 0.136315  [51264/60000]\n",
      "loss: 0.238382  [51904/60000]\n",
      "loss: 0.144046  [52544/60000]\n",
      "loss: 0.140976  [53184/60000]\n",
      "loss: 0.088910  [53824/60000]\n",
      "loss: 0.090302  [54464/60000]\n",
      "loss: 0.166371  [55104/60000]\n",
      "loss: 0.182541  [55744/60000]\n",
      "loss: 0.130627  [56384/60000]\n",
      "loss: 0.163000  [57024/60000]\n",
      "loss: 0.123972  [57664/60000]\n",
      "loss: 0.095932  [58304/60000]\n",
      "loss: 0.135445  [58944/60000]\n",
      "loss: 0.225953  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.243125 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.190296  [   64/60000]\n",
      "loss: 0.124522  [  704/60000]\n",
      "loss: 0.239711  [ 1344/60000]\n",
      "loss: 0.185706  [ 1984/60000]\n",
      "loss: 0.112309  [ 2624/60000]\n",
      "loss: 0.187893  [ 3264/60000]\n",
      "loss: 0.120774  [ 3904/60000]\n",
      "loss: 0.175105  [ 4544/60000]\n",
      "loss: 0.131451  [ 5184/60000]\n",
      "loss: 0.140009  [ 5824/60000]\n",
      "loss: 0.211109  [ 6464/60000]\n",
      "loss: 0.249479  [ 7104/60000]\n",
      "loss: 0.144389  [ 7744/60000]\n",
      "loss: 0.137590  [ 8384/60000]\n",
      "loss: 0.143477  [ 9024/60000]\n",
      "loss: 0.132994  [ 9664/60000]\n",
      "loss: 0.187714  [10304/60000]\n",
      "loss: 0.231610  [10944/60000]\n",
      "loss: 0.105610  [11584/60000]\n",
      "loss: 0.311374  [12224/60000]\n",
      "loss: 0.098143  [12864/60000]\n",
      "loss: 0.149337  [13504/60000]\n",
      "loss: 0.137125  [14144/60000]\n",
      "loss: 0.133745  [14784/60000]\n",
      "loss: 0.113631  [15424/60000]\n",
      "loss: 0.289974  [16064/60000]\n",
      "loss: 0.203414  [16704/60000]\n",
      "loss: 0.143466  [17344/60000]\n",
      "loss: 0.114975  [17984/60000]\n",
      "loss: 0.094627  [18624/60000]\n",
      "loss: 0.152406  [19264/60000]\n",
      "loss: 0.140769  [19904/60000]\n",
      "loss: 0.205737  [20544/60000]\n",
      "loss: 0.124082  [21184/60000]\n",
      "loss: 0.111542  [21824/60000]\n",
      "loss: 0.159711  [22464/60000]\n",
      "loss: 0.295040  [23104/60000]\n",
      "loss: 0.069007  [23744/60000]\n",
      "loss: 0.158099  [24384/60000]\n",
      "loss: 0.123501  [25024/60000]\n",
      "loss: 0.168744  [25664/60000]\n",
      "loss: 0.024793  [26304/60000]\n",
      "loss: 0.256339  [26944/60000]\n",
      "loss: 0.152368  [27584/60000]\n",
      "loss: 0.129101  [28224/60000]\n",
      "loss: 0.308338  [28864/60000]\n",
      "loss: 0.069102  [29504/60000]\n",
      "loss: 0.085034  [30144/60000]\n",
      "loss: 0.162570  [30784/60000]\n",
      "loss: 0.237664  [31424/60000]\n",
      "loss: 0.139679  [32064/60000]\n",
      "loss: 0.123359  [32704/60000]\n",
      "loss: 0.158049  [33344/60000]\n",
      "loss: 0.124381  [33984/60000]\n",
      "loss: 0.173428  [34624/60000]\n",
      "loss: 0.263001  [35264/60000]\n",
      "loss: 0.104226  [35904/60000]\n",
      "loss: 0.179051  [36544/60000]\n",
      "loss: 0.091142  [37184/60000]\n",
      "loss: 0.107717  [37824/60000]\n",
      "loss: 0.238118  [38464/60000]\n",
      "loss: 0.361088  [39104/60000]\n",
      "loss: 0.103061  [39744/60000]\n",
      "loss: 0.124887  [40384/60000]\n",
      "loss: 0.135292  [41024/60000]\n",
      "loss: 0.142524  [41664/60000]\n",
      "loss: 0.266314  [42304/60000]\n",
      "loss: 0.076862  [42944/60000]\n",
      "loss: 0.202393  [43584/60000]\n",
      "loss: 0.262502  [44224/60000]\n",
      "loss: 0.145540  [44864/60000]\n",
      "loss: 0.181997  [45504/60000]\n",
      "loss: 0.045817  [46144/60000]\n",
      "loss: 0.113387  [46784/60000]\n",
      "loss: 0.154707  [47424/60000]\n",
      "loss: 0.189444  [48064/60000]\n",
      "loss: 0.178137  [48704/60000]\n",
      "loss: 0.207115  [49344/60000]\n",
      "loss: 0.179686  [49984/60000]\n",
      "loss: 0.078332  [50624/60000]\n",
      "loss: 0.383575  [51264/60000]\n",
      "loss: 0.118808  [51904/60000]\n",
      "loss: 0.215141  [52544/60000]\n",
      "loss: 0.098350  [53184/60000]\n",
      "loss: 0.222110  [53824/60000]\n",
      "loss: 0.182281  [54464/60000]\n",
      "loss: 0.095217  [55104/60000]\n",
      "loss: 0.220897  [55744/60000]\n",
      "loss: 0.182616  [56384/60000]\n",
      "loss: 0.116871  [57024/60000]\n",
      "loss: 0.281176  [57664/60000]\n",
      "loss: 0.066728  [58304/60000]\n",
      "loss: 0.052347  [58944/60000]\n",
      "loss: 0.038453  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.244634 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = train_net(model, train_dataloader, test_dataloader,\n",
    "                  epochs=30, learning_rate=1e-4, batch_size=64)\n",
    "\n",
    "torch.save(model.state_dict(), 'Trained_Model_fashionMNIST_resnet18_dropout.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe308dbb-4f70-499f-9452-08f7f7e429cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.235854  [   64/60000]\n",
      "loss: 0.127294  [  704/60000]\n",
      "loss: 0.171857  [ 1344/60000]\n",
      "loss: 0.117219  [ 1984/60000]\n",
      "loss: 0.122641  [ 2624/60000]\n",
      "loss: 0.041131  [ 3264/60000]\n",
      "loss: 0.094798  [ 3904/60000]\n",
      "loss: 0.047461  [ 4544/60000]\n",
      "loss: 0.127100  [ 5184/60000]\n",
      "loss: 0.166388  [ 5824/60000]\n",
      "loss: 0.086882  [ 6464/60000]\n",
      "loss: 0.165028  [ 7104/60000]\n",
      "loss: 0.302822  [ 7744/60000]\n",
      "loss: 0.093313  [ 8384/60000]\n",
      "loss: 0.159726  [ 9024/60000]\n",
      "loss: 0.070048  [ 9664/60000]\n",
      "loss: 0.060592  [10304/60000]\n",
      "loss: 0.096488  [10944/60000]\n",
      "loss: 0.132220  [11584/60000]\n",
      "loss: 0.156359  [12224/60000]\n",
      "loss: 0.132595  [12864/60000]\n",
      "loss: 0.030394  [13504/60000]\n",
      "loss: 0.049550  [14144/60000]\n",
      "loss: 0.149849  [14784/60000]\n",
      "loss: 0.069050  [15424/60000]\n",
      "loss: 0.261114  [16064/60000]\n",
      "loss: 0.179416  [16704/60000]\n",
      "loss: 0.086094  [17344/60000]\n",
      "loss: 0.179800  [17984/60000]\n",
      "loss: 0.336379  [18624/60000]\n",
      "loss: 0.071156  [19264/60000]\n",
      "loss: 0.060839  [19904/60000]\n",
      "loss: 0.195797  [20544/60000]\n",
      "loss: 0.083580  [21184/60000]\n",
      "loss: 0.194695  [21824/60000]\n",
      "loss: 0.056149  [22464/60000]\n",
      "loss: 0.084370  [23104/60000]\n",
      "loss: 0.042132  [23744/60000]\n",
      "loss: 0.083261  [24384/60000]\n",
      "loss: 0.164729  [25024/60000]\n",
      "loss: 0.142769  [25664/60000]\n",
      "loss: 0.203661  [26304/60000]\n",
      "loss: 0.140992  [26944/60000]\n",
      "loss: 0.041741  [27584/60000]\n",
      "loss: 0.116261  [28224/60000]\n",
      "loss: 0.198383  [28864/60000]\n",
      "loss: 0.222558  [29504/60000]\n",
      "loss: 0.126848  [30144/60000]\n",
      "loss: 0.024507  [30784/60000]\n",
      "loss: 0.195355  [31424/60000]\n",
      "loss: 0.153300  [32064/60000]\n",
      "loss: 0.053202  [32704/60000]\n",
      "loss: 0.167231  [33344/60000]\n",
      "loss: 0.131096  [33984/60000]\n",
      "loss: 0.352774  [34624/60000]\n",
      "loss: 0.105796  [35264/60000]\n",
      "loss: 0.259620  [35904/60000]\n",
      "loss: 0.082503  [36544/60000]\n",
      "loss: 0.200462  [37184/60000]\n",
      "loss: 0.075314  [37824/60000]\n",
      "loss: 0.171120  [38464/60000]\n",
      "loss: 0.132557  [39104/60000]\n",
      "loss: 0.100485  [39744/60000]\n",
      "loss: 0.064248  [40384/60000]\n",
      "loss: 0.092810  [41024/60000]\n",
      "loss: 0.147552  [41664/60000]\n",
      "loss: 0.098347  [42304/60000]\n",
      "loss: 0.166634  [42944/60000]\n",
      "loss: 0.116589  [43584/60000]\n",
      "loss: 0.042698  [44224/60000]\n",
      "loss: 0.231492  [44864/60000]\n",
      "loss: 0.063667  [45504/60000]\n",
      "loss: 0.078821  [46144/60000]\n",
      "loss: 0.117517  [46784/60000]\n",
      "loss: 0.133073  [47424/60000]\n",
      "loss: 0.279300  [48064/60000]\n",
      "loss: 0.164346  [48704/60000]\n",
      "loss: 0.066100  [49344/60000]\n",
      "loss: 0.213693  [49984/60000]\n",
      "loss: 0.107547  [50624/60000]\n",
      "loss: 0.120865  [51264/60000]\n",
      "loss: 0.114910  [51904/60000]\n",
      "loss: 0.143154  [52544/60000]\n",
      "loss: 0.074354  [53184/60000]\n",
      "loss: 0.083112  [53824/60000]\n",
      "loss: 0.271751  [54464/60000]\n",
      "loss: 0.130024  [55104/60000]\n",
      "loss: 0.069323  [55744/60000]\n",
      "loss: 0.024303  [56384/60000]\n",
      "loss: 0.143738  [57024/60000]\n",
      "loss: 0.107861  [57664/60000]\n",
      "loss: 0.156998  [58304/60000]\n",
      "loss: 0.057241  [58944/60000]\n",
      "loss: 0.080195  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.258182 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.030889  [   64/60000]\n",
      "loss: 0.068262  [  704/60000]\n",
      "loss: 0.080054  [ 1344/60000]\n",
      "loss: 0.082314  [ 1984/60000]\n",
      "loss: 0.045602  [ 2624/60000]\n",
      "loss: 0.089619  [ 3264/60000]\n",
      "loss: 0.127588  [ 3904/60000]\n",
      "loss: 0.183952  [ 4544/60000]\n",
      "loss: 0.237656  [ 5184/60000]\n",
      "loss: 0.260700  [ 5824/60000]\n",
      "loss: 0.090608  [ 6464/60000]\n",
      "loss: 0.076274  [ 7104/60000]\n",
      "loss: 0.076015  [ 7744/60000]\n",
      "loss: 0.179213  [ 8384/60000]\n",
      "loss: 0.128155  [ 9024/60000]\n",
      "loss: 0.118220  [ 9664/60000]\n",
      "loss: 0.104424  [10304/60000]\n",
      "loss: 0.252451  [10944/60000]\n",
      "loss: 0.294438  [11584/60000]\n",
      "loss: 0.219480  [12224/60000]\n",
      "loss: 0.123797  [12864/60000]\n",
      "loss: 0.125743  [13504/60000]\n",
      "loss: 0.209565  [14144/60000]\n",
      "loss: 0.095488  [14784/60000]\n",
      "loss: 0.430855  [15424/60000]\n",
      "loss: 0.129542  [16064/60000]\n",
      "loss: 0.087559  [16704/60000]\n",
      "loss: 0.054330  [17344/60000]\n",
      "loss: 0.154959  [17984/60000]\n",
      "loss: 0.070234  [18624/60000]\n",
      "loss: 0.185342  [19264/60000]\n",
      "loss: 0.131301  [19904/60000]\n",
      "loss: 0.165058  [20544/60000]\n",
      "loss: 0.163875  [21184/60000]\n",
      "loss: 0.101073  [21824/60000]\n",
      "loss: 0.054519  [22464/60000]\n",
      "loss: 0.092861  [23104/60000]\n",
      "loss: 0.142356  [23744/60000]\n",
      "loss: 0.086583  [24384/60000]\n",
      "loss: 0.053178  [25024/60000]\n",
      "loss: 0.088940  [25664/60000]\n",
      "loss: 0.089036  [26304/60000]\n",
      "loss: 0.191757  [26944/60000]\n",
      "loss: 0.124201  [27584/60000]\n",
      "loss: 0.133731  [28224/60000]\n",
      "loss: 0.104953  [28864/60000]\n",
      "loss: 0.164022  [29504/60000]\n",
      "loss: 0.228566  [30144/60000]\n",
      "loss: 0.091950  [30784/60000]\n",
      "loss: 0.051988  [31424/60000]\n",
      "loss: 0.102862  [32064/60000]\n",
      "loss: 0.063395  [32704/60000]\n",
      "loss: 0.142917  [33344/60000]\n",
      "loss: 0.202576  [33984/60000]\n",
      "loss: 0.144327  [34624/60000]\n",
      "loss: 0.052408  [35264/60000]\n",
      "loss: 0.039533  [35904/60000]\n",
      "loss: 0.118785  [36544/60000]\n",
      "loss: 0.076205  [37184/60000]\n",
      "loss: 0.192176  [37824/60000]\n",
      "loss: 0.081868  [38464/60000]\n",
      "loss: 0.258082  [39104/60000]\n",
      "loss: 0.134301  [39744/60000]\n",
      "loss: 0.079362  [40384/60000]\n",
      "loss: 0.105117  [41024/60000]\n",
      "loss: 0.031455  [41664/60000]\n",
      "loss: 0.037337  [42304/60000]\n",
      "loss: 0.159259  [42944/60000]\n",
      "loss: 0.086387  [43584/60000]\n",
      "loss: 0.097094  [44224/60000]\n",
      "loss: 0.081600  [44864/60000]\n",
      "loss: 0.050680  [45504/60000]\n",
      "loss: 0.104508  [46144/60000]\n",
      "loss: 0.190708  [46784/60000]\n",
      "loss: 0.099940  [47424/60000]\n",
      "loss: 0.095193  [48064/60000]\n",
      "loss: 0.087520  [48704/60000]\n",
      "loss: 0.168202  [49344/60000]\n",
      "loss: 0.104523  [49984/60000]\n",
      "loss: 0.110366  [50624/60000]\n",
      "loss: 0.168341  [51264/60000]\n",
      "loss: 0.235648  [51904/60000]\n",
      "loss: 0.058092  [52544/60000]\n",
      "loss: 0.065653  [53184/60000]\n",
      "loss: 0.219599  [53824/60000]\n",
      "loss: 0.080689  [54464/60000]\n",
      "loss: 0.091863  [55104/60000]\n",
      "loss: 0.188718  [55744/60000]\n",
      "loss: 0.091807  [56384/60000]\n",
      "loss: 0.104342  [57024/60000]\n",
      "loss: 0.083961  [57664/60000]\n",
      "loss: 0.148247  [58304/60000]\n",
      "loss: 0.060128  [58944/60000]\n",
      "loss: 0.064521  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.258125 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.099037  [   64/60000]\n",
      "loss: 0.125182  [  704/60000]\n",
      "loss: 0.116868  [ 1344/60000]\n",
      "loss: 0.124132  [ 1984/60000]\n",
      "loss: 0.119441  [ 2624/60000]\n",
      "loss: 0.074212  [ 3264/60000]\n",
      "loss: 0.067779  [ 3904/60000]\n",
      "loss: 0.114905  [ 4544/60000]\n",
      "loss: 0.146811  [ 5184/60000]\n",
      "loss: 0.081042  [ 5824/60000]\n",
      "loss: 0.163710  [ 6464/60000]\n",
      "loss: 0.062500  [ 7104/60000]\n",
      "loss: 0.034638  [ 7744/60000]\n",
      "loss: 0.068442  [ 8384/60000]\n",
      "loss: 0.124738  [ 9024/60000]\n",
      "loss: 0.138127  [ 9664/60000]\n",
      "loss: 0.044445  [10304/60000]\n",
      "loss: 0.155398  [10944/60000]\n",
      "loss: 0.040903  [11584/60000]\n",
      "loss: 0.099380  [12224/60000]\n",
      "loss: 0.230311  [12864/60000]\n",
      "loss: 0.060816  [13504/60000]\n",
      "loss: 0.260602  [14144/60000]\n",
      "loss: 0.048777  [14784/60000]\n",
      "loss: 0.169863  [15424/60000]\n",
      "loss: 0.179707  [16064/60000]\n",
      "loss: 0.097091  [16704/60000]\n",
      "loss: 0.170971  [17344/60000]\n",
      "loss: 0.051684  [17984/60000]\n",
      "loss: 0.139983  [18624/60000]\n",
      "loss: 0.057206  [19264/60000]\n",
      "loss: 0.108336  [19904/60000]\n",
      "loss: 0.053159  [20544/60000]\n",
      "loss: 0.109436  [21184/60000]\n",
      "loss: 0.215787  [21824/60000]\n",
      "loss: 0.150914  [22464/60000]\n",
      "loss: 0.268439  [23104/60000]\n",
      "loss: 0.077720  [23744/60000]\n",
      "loss: 0.041816  [24384/60000]\n",
      "loss: 0.065958  [25024/60000]\n",
      "loss: 0.218856  [25664/60000]\n",
      "loss: 0.207953  [26304/60000]\n",
      "loss: 0.110487  [26944/60000]\n",
      "loss: 0.086683  [27584/60000]\n",
      "loss: 0.084669  [28224/60000]\n",
      "loss: 0.080291  [28864/60000]\n",
      "loss: 0.106133  [29504/60000]\n",
      "loss: 0.096769  [30144/60000]\n",
      "loss: 0.131203  [30784/60000]\n",
      "loss: 0.147220  [31424/60000]\n",
      "loss: 0.057017  [32064/60000]\n",
      "loss: 0.053158  [32704/60000]\n",
      "loss: 0.261584  [33344/60000]\n",
      "loss: 0.144928  [33984/60000]\n",
      "loss: 0.261056  [34624/60000]\n",
      "loss: 0.136854  [35264/60000]\n",
      "loss: 0.070118  [35904/60000]\n",
      "loss: 0.118072  [36544/60000]\n",
      "loss: 0.165665  [37184/60000]\n",
      "loss: 0.097692  [37824/60000]\n",
      "loss: 0.146646  [38464/60000]\n",
      "loss: 0.190637  [39104/60000]\n",
      "loss: 0.090707  [39744/60000]\n",
      "loss: 0.051429  [40384/60000]\n",
      "loss: 0.189324  [41024/60000]\n",
      "loss: 0.108398  [41664/60000]\n",
      "loss: 0.149386  [42304/60000]\n",
      "loss: 0.100301  [42944/60000]\n",
      "loss: 0.139370  [43584/60000]\n",
      "loss: 0.093268  [44224/60000]\n",
      "loss: 0.088273  [44864/60000]\n",
      "loss: 0.075712  [45504/60000]\n",
      "loss: 0.100795  [46144/60000]\n",
      "loss: 0.096535  [46784/60000]\n",
      "loss: 0.118303  [47424/60000]\n",
      "loss: 0.047910  [48064/60000]\n",
      "loss: 0.114628  [48704/60000]\n",
      "loss: 0.087202  [49344/60000]\n",
      "loss: 0.168172  [49984/60000]\n",
      "loss: 0.087060  [50624/60000]\n",
      "loss: 0.072785  [51264/60000]\n",
      "loss: 0.200852  [51904/60000]\n",
      "loss: 0.226757  [52544/60000]\n",
      "loss: 0.025497  [53184/60000]\n",
      "loss: 0.191058  [53824/60000]\n",
      "loss: 0.152631  [54464/60000]\n",
      "loss: 0.135151  [55104/60000]\n",
      "loss: 0.201931  [55744/60000]\n",
      "loss: 0.091567  [56384/60000]\n",
      "loss: 0.210820  [57024/60000]\n",
      "loss: 0.077686  [57664/60000]\n",
      "loss: 0.105832  [58304/60000]\n",
      "loss: 0.235825  [58944/60000]\n",
      "loss: 0.209104  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.263180 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.065839  [   64/60000]\n",
      "loss: 0.065335  [  704/60000]\n",
      "loss: 0.286515  [ 1344/60000]\n",
      "loss: 0.124690  [ 1984/60000]\n",
      "loss: 0.111709  [ 2624/60000]\n",
      "loss: 0.057758  [ 3264/60000]\n",
      "loss: 0.141800  [ 3904/60000]\n",
      "loss: 0.128414  [ 4544/60000]\n",
      "loss: 0.055395  [ 5184/60000]\n",
      "loss: 0.189514  [ 5824/60000]\n",
      "loss: 0.072074  [ 6464/60000]\n",
      "loss: 0.125225  [ 7104/60000]\n",
      "loss: 0.066673  [ 7744/60000]\n",
      "loss: 0.055409  [ 8384/60000]\n",
      "loss: 0.121124  [ 9024/60000]\n",
      "loss: 0.095948  [ 9664/60000]\n",
      "loss: 0.139812  [10304/60000]\n",
      "loss: 0.208000  [10944/60000]\n",
      "loss: 0.241521  [11584/60000]\n",
      "loss: 0.128288  [12224/60000]\n",
      "loss: 0.089245  [12864/60000]\n",
      "loss: 0.071653  [13504/60000]\n",
      "loss: 0.079722  [14144/60000]\n",
      "loss: 0.012984  [14784/60000]\n",
      "loss: 0.076661  [15424/60000]\n",
      "loss: 0.050410  [16064/60000]\n",
      "loss: 0.121405  [16704/60000]\n",
      "loss: 0.069708  [17344/60000]\n",
      "loss: 0.064446  [17984/60000]\n",
      "loss: 0.122398  [18624/60000]\n",
      "loss: 0.129500  [19264/60000]\n",
      "loss: 0.096803  [19904/60000]\n",
      "loss: 0.137143  [20544/60000]\n",
      "loss: 0.059527  [21184/60000]\n",
      "loss: 0.122979  [21824/60000]\n",
      "loss: 0.099764  [22464/60000]\n",
      "loss: 0.187846  [23104/60000]\n",
      "loss: 0.067522  [23744/60000]\n",
      "loss: 0.050501  [24384/60000]\n",
      "loss: 0.128432  [25024/60000]\n",
      "loss: 0.110201  [25664/60000]\n",
      "loss: 0.098615  [26304/60000]\n",
      "loss: 0.227353  [26944/60000]\n",
      "loss: 0.148274  [27584/60000]\n",
      "loss: 0.155331  [28224/60000]\n",
      "loss: 0.121016  [28864/60000]\n",
      "loss: 0.120451  [29504/60000]\n",
      "loss: 0.220489  [30144/60000]\n",
      "loss: 0.132473  [30784/60000]\n",
      "loss: 0.050637  [31424/60000]\n",
      "loss: 0.083124  [32064/60000]\n",
      "loss: 0.233143  [32704/60000]\n",
      "loss: 0.124052  [33344/60000]\n",
      "loss: 0.071572  [33984/60000]\n",
      "loss: 0.121485  [34624/60000]\n",
      "loss: 0.093595  [35264/60000]\n",
      "loss: 0.295996  [35904/60000]\n",
      "loss: 0.124600  [36544/60000]\n",
      "loss: 0.053139  [37184/60000]\n",
      "loss: 0.190485  [37824/60000]\n",
      "loss: 0.087360  [38464/60000]\n",
      "loss: 0.079178  [39104/60000]\n",
      "loss: 0.130855  [39744/60000]\n",
      "loss: 0.117252  [40384/60000]\n",
      "loss: 0.186766  [41024/60000]\n",
      "loss: 0.107165  [41664/60000]\n",
      "loss: 0.110714  [42304/60000]\n",
      "loss: 0.031784  [42944/60000]\n",
      "loss: 0.074263  [43584/60000]\n",
      "loss: 0.186985  [44224/60000]\n",
      "loss: 0.156296  [44864/60000]\n",
      "loss: 0.057677  [45504/60000]\n",
      "loss: 0.195079  [46144/60000]\n",
      "loss: 0.210374  [46784/60000]\n",
      "loss: 0.216658  [47424/60000]\n",
      "loss: 0.074148  [48064/60000]\n",
      "loss: 0.076816  [48704/60000]\n",
      "loss: 0.193454  [49344/60000]\n",
      "loss: 0.112101  [49984/60000]\n",
      "loss: 0.113486  [50624/60000]\n",
      "loss: 0.114381  [51264/60000]\n",
      "loss: 0.104896  [51904/60000]\n",
      "loss: 0.085738  [52544/60000]\n",
      "loss: 0.057781  [53184/60000]\n",
      "loss: 0.086823  [53824/60000]\n",
      "loss: 0.150607  [54464/60000]\n",
      "loss: 0.170848  [55104/60000]\n",
      "loss: 0.133141  [55744/60000]\n",
      "loss: 0.050699  [56384/60000]\n",
      "loss: 0.161173  [57024/60000]\n",
      "loss: 0.118413  [57664/60000]\n",
      "loss: 0.116137  [58304/60000]\n",
      "loss: 0.133373  [58944/60000]\n",
      "loss: 0.086220  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.268697 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.098065  [   64/60000]\n",
      "loss: 0.083449  [  704/60000]\n",
      "loss: 0.104631  [ 1344/60000]\n",
      "loss: 0.192855  [ 1984/60000]\n",
      "loss: 0.037549  [ 2624/60000]\n",
      "loss: 0.058870  [ 3264/60000]\n",
      "loss: 0.107740  [ 3904/60000]\n",
      "loss: 0.092067  [ 4544/60000]\n",
      "loss: 0.061013  [ 5184/60000]\n",
      "loss: 0.081615  [ 5824/60000]\n",
      "loss: 0.095111  [ 6464/60000]\n",
      "loss: 0.071236  [ 7104/60000]\n",
      "loss: 0.157468  [ 7744/60000]\n",
      "loss: 0.085144  [ 8384/60000]\n",
      "loss: 0.047451  [ 9024/60000]\n",
      "loss: 0.129450  [ 9664/60000]\n",
      "loss: 0.135449  [10304/60000]\n",
      "loss: 0.108699  [10944/60000]\n",
      "loss: 0.223041  [11584/60000]\n",
      "loss: 0.127035  [12224/60000]\n",
      "loss: 0.200234  [12864/60000]\n",
      "loss: 0.080693  [13504/60000]\n",
      "loss: 0.102983  [14144/60000]\n",
      "loss: 0.057516  [14784/60000]\n",
      "loss: 0.135481  [15424/60000]\n",
      "loss: 0.154487  [16064/60000]\n",
      "loss: 0.087247  [16704/60000]\n",
      "loss: 0.027005  [17344/60000]\n",
      "loss: 0.033600  [17984/60000]\n",
      "loss: 0.060826  [18624/60000]\n",
      "loss: 0.189052  [19264/60000]\n",
      "loss: 0.116589  [19904/60000]\n",
      "loss: 0.111056  [20544/60000]\n",
      "loss: 0.086689  [21184/60000]\n",
      "loss: 0.062453  [21824/60000]\n",
      "loss: 0.106475  [22464/60000]\n",
      "loss: 0.081106  [23104/60000]\n",
      "loss: 0.142632  [23744/60000]\n",
      "loss: 0.108773  [24384/60000]\n",
      "loss: 0.074241  [25024/60000]\n",
      "loss: 0.171708  [25664/60000]\n",
      "loss: 0.061870  [26304/60000]\n",
      "loss: 0.138243  [26944/60000]\n",
      "loss: 0.131609  [27584/60000]\n",
      "loss: 0.053220  [28224/60000]\n",
      "loss: 0.095178  [28864/60000]\n",
      "loss: 0.116496  [29504/60000]\n",
      "loss: 0.162854  [30144/60000]\n",
      "loss: 0.265437  [30784/60000]\n",
      "loss: 0.124895  [31424/60000]\n",
      "loss: 0.101772  [32064/60000]\n",
      "loss: 0.096469  [32704/60000]\n",
      "loss: 0.073792  [33344/60000]\n",
      "loss: 0.118445  [33984/60000]\n",
      "loss: 0.101297  [34624/60000]\n",
      "loss: 0.118939  [35264/60000]\n",
      "loss: 0.060280  [35904/60000]\n",
      "loss: 0.175232  [36544/60000]\n",
      "loss: 0.123030  [37184/60000]\n",
      "loss: 0.086233  [37824/60000]\n",
      "loss: 0.096459  [38464/60000]\n",
      "loss: 0.058958  [39104/60000]\n",
      "loss: 0.147702  [39744/60000]\n",
      "loss: 0.184384  [40384/60000]\n",
      "loss: 0.136690  [41024/60000]\n",
      "loss: 0.067760  [41664/60000]\n",
      "loss: 0.102030  [42304/60000]\n",
      "loss: 0.169092  [42944/60000]\n",
      "loss: 0.075651  [43584/60000]\n",
      "loss: 0.140523  [44224/60000]\n",
      "loss: 0.147825  [44864/60000]\n",
      "loss: 0.039037  [45504/60000]\n",
      "loss: 0.080911  [46144/60000]\n",
      "loss: 0.064901  [46784/60000]\n",
      "loss: 0.041082  [47424/60000]\n",
      "loss: 0.273272  [48064/60000]\n",
      "loss: 0.083016  [48704/60000]\n",
      "loss: 0.190218  [49344/60000]\n",
      "loss: 0.118109  [49984/60000]\n",
      "loss: 0.133074  [50624/60000]\n",
      "loss: 0.116390  [51264/60000]\n",
      "loss: 0.253274  [51904/60000]\n",
      "loss: 0.064444  [52544/60000]\n",
      "loss: 0.093430  [53184/60000]\n",
      "loss: 0.123569  [53824/60000]\n",
      "loss: 0.224221  [54464/60000]\n",
      "loss: 0.091242  [55104/60000]\n",
      "loss: 0.224664  [55744/60000]\n",
      "loss: 0.114569  [56384/60000]\n",
      "loss: 0.087230  [57024/60000]\n",
      "loss: 0.067961  [57664/60000]\n",
      "loss: 0.111864  [58304/60000]\n",
      "loss: 0.217564  [58944/60000]\n",
      "loss: 0.217277  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.259268 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.090991  [   64/60000]\n",
      "loss: 0.038767  [  704/60000]\n",
      "loss: 0.109885  [ 1344/60000]\n",
      "loss: 0.176256  [ 1984/60000]\n",
      "loss: 0.111076  [ 2624/60000]\n",
      "loss: 0.087356  [ 3264/60000]\n",
      "loss: 0.125726  [ 3904/60000]\n",
      "loss: 0.051426  [ 4544/60000]\n",
      "loss: 0.186924  [ 5184/60000]\n",
      "loss: 0.141186  [ 5824/60000]\n",
      "loss: 0.161623  [ 6464/60000]\n",
      "loss: 0.074466  [ 7104/60000]\n",
      "loss: 0.050984  [ 7744/60000]\n",
      "loss: 0.115453  [ 8384/60000]\n",
      "loss: 0.019533  [ 9024/60000]\n",
      "loss: 0.038893  [ 9664/60000]\n",
      "loss: 0.245664  [10304/60000]\n",
      "loss: 0.119281  [10944/60000]\n",
      "loss: 0.095300  [11584/60000]\n",
      "loss: 0.058583  [12224/60000]\n",
      "loss: 0.165380  [12864/60000]\n",
      "loss: 0.141274  [13504/60000]\n",
      "loss: 0.056217  [14144/60000]\n",
      "loss: 0.042756  [14784/60000]\n",
      "loss: 0.130304  [15424/60000]\n",
      "loss: 0.161388  [16064/60000]\n",
      "loss: 0.040459  [16704/60000]\n",
      "loss: 0.084859  [17344/60000]\n",
      "loss: 0.238522  [17984/60000]\n",
      "loss: 0.170387  [18624/60000]\n",
      "loss: 0.030027  [19264/60000]\n",
      "loss: 0.068595  [19904/60000]\n",
      "loss: 0.162916  [20544/60000]\n",
      "loss: 0.064760  [21184/60000]\n",
      "loss: 0.079026  [21824/60000]\n",
      "loss: 0.135309  [22464/60000]\n",
      "loss: 0.067697  [23104/60000]\n",
      "loss: 0.070522  [23744/60000]\n",
      "loss: 0.081206  [24384/60000]\n",
      "loss: 0.117029  [25024/60000]\n",
      "loss: 0.113248  [25664/60000]\n",
      "loss: 0.044577  [26304/60000]\n",
      "loss: 0.064180  [26944/60000]\n",
      "loss: 0.105786  [27584/60000]\n",
      "loss: 0.212862  [28224/60000]\n",
      "loss: 0.120514  [28864/60000]\n",
      "loss: 0.164595  [29504/60000]\n",
      "loss: 0.249337  [30144/60000]\n",
      "loss: 0.230524  [30784/60000]\n",
      "loss: 0.180939  [31424/60000]\n",
      "loss: 0.145296  [32064/60000]\n",
      "loss: 0.105867  [32704/60000]\n",
      "loss: 0.145535  [33344/60000]\n",
      "loss: 0.117155  [33984/60000]\n",
      "loss: 0.074393  [34624/60000]\n",
      "loss: 0.093795  [35264/60000]\n",
      "loss: 0.057507  [35904/60000]\n",
      "loss: 0.052078  [36544/60000]\n",
      "loss: 0.080572  [37184/60000]\n",
      "loss: 0.093678  [37824/60000]\n",
      "loss: 0.019329  [38464/60000]\n",
      "loss: 0.080358  [39104/60000]\n",
      "loss: 0.037215  [39744/60000]\n",
      "loss: 0.137423  [40384/60000]\n",
      "loss: 0.059119  [41024/60000]\n",
      "loss: 0.091966  [41664/60000]\n",
      "loss: 0.098924  [42304/60000]\n",
      "loss: 0.142116  [42944/60000]\n",
      "loss: 0.120973  [43584/60000]\n",
      "loss: 0.227312  [44224/60000]\n",
      "loss: 0.150405  [44864/60000]\n",
      "loss: 0.093581  [45504/60000]\n",
      "loss: 0.181155  [46144/60000]\n",
      "loss: 0.158983  [46784/60000]\n",
      "loss: 0.164629  [47424/60000]\n",
      "loss: 0.064407  [48064/60000]\n",
      "loss: 0.134196  [48704/60000]\n",
      "loss: 0.056109  [49344/60000]\n",
      "loss: 0.111384  [49984/60000]\n",
      "loss: 0.041415  [50624/60000]\n",
      "loss: 0.112381  [51264/60000]\n",
      "loss: 0.125192  [51904/60000]\n",
      "loss: 0.142665  [52544/60000]\n",
      "loss: 0.077034  [53184/60000]\n",
      "loss: 0.048554  [53824/60000]\n",
      "loss: 0.055694  [54464/60000]\n",
      "loss: 0.235083  [55104/60000]\n",
      "loss: 0.115006  [55744/60000]\n",
      "loss: 0.133779  [56384/60000]\n",
      "loss: 0.074547  [57024/60000]\n",
      "loss: 0.082619  [57664/60000]\n",
      "loss: 0.094801  [58304/60000]\n",
      "loss: 0.111662  [58944/60000]\n",
      "loss: 0.187139  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.266356 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.251013  [   64/60000]\n",
      "loss: 0.100681  [  704/60000]\n",
      "loss: 0.269685  [ 1344/60000]\n",
      "loss: 0.117433  [ 1984/60000]\n",
      "loss: 0.059443  [ 2624/60000]\n",
      "loss: 0.230577  [ 3264/60000]\n",
      "loss: 0.170736  [ 3904/60000]\n",
      "loss: 0.165901  [ 4544/60000]\n",
      "loss: 0.067751  [ 5184/60000]\n",
      "loss: 0.082233  [ 5824/60000]\n",
      "loss: 0.178557  [ 6464/60000]\n",
      "loss: 0.083583  [ 7104/60000]\n",
      "loss: 0.116272  [ 7744/60000]\n",
      "loss: 0.268066  [ 8384/60000]\n",
      "loss: 0.045395  [ 9024/60000]\n",
      "loss: 0.083612  [ 9664/60000]\n",
      "loss: 0.059185  [10304/60000]\n",
      "loss: 0.131013  [10944/60000]\n",
      "loss: 0.375809  [11584/60000]\n",
      "loss: 0.035385  [12224/60000]\n",
      "loss: 0.040898  [12864/60000]\n",
      "loss: 0.098153  [13504/60000]\n",
      "loss: 0.115139  [14144/60000]\n",
      "loss: 0.103584  [14784/60000]\n",
      "loss: 0.055930  [15424/60000]\n",
      "loss: 0.159126  [16064/60000]\n",
      "loss: 0.086842  [16704/60000]\n",
      "loss: 0.184741  [17344/60000]\n",
      "loss: 0.176149  [17984/60000]\n",
      "loss: 0.099147  [18624/60000]\n",
      "loss: 0.068681  [19264/60000]\n",
      "loss: 0.055736  [19904/60000]\n",
      "loss: 0.076625  [20544/60000]\n",
      "loss: 0.200278  [21184/60000]\n",
      "loss: 0.086650  [21824/60000]\n",
      "loss: 0.120828  [22464/60000]\n",
      "loss: 0.174018  [23104/60000]\n",
      "loss: 0.066418  [23744/60000]\n",
      "loss: 0.079120  [24384/60000]\n",
      "loss: 0.160862  [25024/60000]\n",
      "loss: 0.142381  [25664/60000]\n",
      "loss: 0.100274  [26304/60000]\n",
      "loss: 0.066853  [26944/60000]\n",
      "loss: 0.069353  [27584/60000]\n",
      "loss: 0.080262  [28224/60000]\n",
      "loss: 0.051662  [28864/60000]\n",
      "loss: 0.043948  [29504/60000]\n",
      "loss: 0.079978  [30144/60000]\n",
      "loss: 0.112602  [30784/60000]\n",
      "loss: 0.048647  [31424/60000]\n",
      "loss: 0.115821  [32064/60000]\n",
      "loss: 0.150889  [32704/60000]\n",
      "loss: 0.143367  [33344/60000]\n",
      "loss: 0.115447  [33984/60000]\n",
      "loss: 0.139374  [34624/60000]\n",
      "loss: 0.143698  [35264/60000]\n",
      "loss: 0.091427  [35904/60000]\n",
      "loss: 0.061029  [36544/60000]\n",
      "loss: 0.048487  [37184/60000]\n",
      "loss: 0.068064  [37824/60000]\n",
      "loss: 0.182149  [38464/60000]\n",
      "loss: 0.060137  [39104/60000]\n",
      "loss: 0.087443  [39744/60000]\n",
      "loss: 0.087524  [40384/60000]\n",
      "loss: 0.072711  [41024/60000]\n",
      "loss: 0.097465  [41664/60000]\n",
      "loss: 0.255310  [42304/60000]\n",
      "loss: 0.080411  [42944/60000]\n",
      "loss: 0.063981  [43584/60000]\n",
      "loss: 0.137746  [44224/60000]\n",
      "loss: 0.196470  [44864/60000]\n",
      "loss: 0.144637  [45504/60000]\n",
      "loss: 0.109387  [46144/60000]\n",
      "loss: 0.092678  [46784/60000]\n",
      "loss: 0.073769  [47424/60000]\n",
      "loss: 0.239628  [48064/60000]\n",
      "loss: 0.144041  [48704/60000]\n",
      "loss: 0.155913  [49344/60000]\n",
      "loss: 0.147578  [49984/60000]\n",
      "loss: 0.092676  [50624/60000]\n",
      "loss: 0.061263  [51264/60000]\n",
      "loss: 0.041125  [51904/60000]\n",
      "loss: 0.106642  [52544/60000]\n",
      "loss: 0.116304  [53184/60000]\n",
      "loss: 0.116145  [53824/60000]\n",
      "loss: 0.096023  [54464/60000]\n",
      "loss: 0.125635  [55104/60000]\n",
      "loss: 0.097712  [55744/60000]\n",
      "loss: 0.101620  [56384/60000]\n",
      "loss: 0.074968  [57024/60000]\n",
      "loss: 0.082493  [57664/60000]\n",
      "loss: 0.207865  [58304/60000]\n",
      "loss: 0.052134  [58944/60000]\n",
      "loss: 0.170549  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.271229 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.075970  [   64/60000]\n",
      "loss: 0.068417  [  704/60000]\n",
      "loss: 0.413837  [ 1344/60000]\n",
      "loss: 0.075363  [ 1984/60000]\n",
      "loss: 0.065931  [ 2624/60000]\n",
      "loss: 0.128879  [ 3264/60000]\n",
      "loss: 0.098836  [ 3904/60000]\n",
      "loss: 0.122793  [ 4544/60000]\n",
      "loss: 0.103792  [ 5184/60000]\n",
      "loss: 0.102927  [ 5824/60000]\n",
      "loss: 0.127107  [ 6464/60000]\n",
      "loss: 0.129279  [ 7104/60000]\n",
      "loss: 0.069398  [ 7744/60000]\n",
      "loss: 0.067423  [ 8384/60000]\n",
      "loss: 0.097945  [ 9024/60000]\n",
      "loss: 0.216563  [ 9664/60000]\n",
      "loss: 0.065797  [10304/60000]\n",
      "loss: 0.035965  [10944/60000]\n",
      "loss: 0.094218  [11584/60000]\n",
      "loss: 0.155122  [12224/60000]\n",
      "loss: 0.156324  [12864/60000]\n",
      "loss: 0.187098  [13504/60000]\n",
      "loss: 0.100601  [14144/60000]\n",
      "loss: 0.151477  [14784/60000]\n",
      "loss: 0.125640  [15424/60000]\n",
      "loss: 0.084929  [16064/60000]\n",
      "loss: 0.214956  [16704/60000]\n",
      "loss: 0.047470  [17344/60000]\n",
      "loss: 0.080561  [17984/60000]\n",
      "loss: 0.110640  [18624/60000]\n",
      "loss: 0.143397  [19264/60000]\n",
      "loss: 0.133722  [19904/60000]\n",
      "loss: 0.053041  [20544/60000]\n",
      "loss: 0.062673  [21184/60000]\n",
      "loss: 0.219416  [21824/60000]\n",
      "loss: 0.081292  [22464/60000]\n",
      "loss: 0.057319  [23104/60000]\n",
      "loss: 0.098683  [23744/60000]\n",
      "loss: 0.033973  [24384/60000]\n",
      "loss: 0.039471  [25024/60000]\n",
      "loss: 0.095145  [25664/60000]\n",
      "loss: 0.103550  [26304/60000]\n",
      "loss: 0.119320  [26944/60000]\n",
      "loss: 0.123497  [27584/60000]\n",
      "loss: 0.120833  [28224/60000]\n",
      "loss: 0.101158  [28864/60000]\n",
      "loss: 0.089980  [29504/60000]\n",
      "loss: 0.054164  [30144/60000]\n",
      "loss: 0.046105  [30784/60000]\n",
      "loss: 0.143157  [31424/60000]\n",
      "loss: 0.083474  [32064/60000]\n",
      "loss: 0.084779  [32704/60000]\n",
      "loss: 0.039510  [33344/60000]\n",
      "loss: 0.078705  [33984/60000]\n",
      "loss: 0.066949  [34624/60000]\n",
      "loss: 0.226852  [35264/60000]\n",
      "loss: 0.161600  [35904/60000]\n",
      "loss: 0.073579  [36544/60000]\n",
      "loss: 0.295753  [37184/60000]\n",
      "loss: 0.057815  [37824/60000]\n",
      "loss: 0.060352  [38464/60000]\n",
      "loss: 0.088714  [39104/60000]\n",
      "loss: 0.153353  [39744/60000]\n",
      "loss: 0.111949  [40384/60000]\n",
      "loss: 0.176111  [41024/60000]\n",
      "loss: 0.067420  [41664/60000]\n",
      "loss: 0.145685  [42304/60000]\n",
      "loss: 0.132912  [42944/60000]\n",
      "loss: 0.030830  [43584/60000]\n",
      "loss: 0.057995  [44224/60000]\n",
      "loss: 0.129692  [44864/60000]\n",
      "loss: 0.164346  [45504/60000]\n",
      "loss: 0.085921  [46144/60000]\n",
      "loss: 0.138216  [46784/60000]\n",
      "loss: 0.101445  [47424/60000]\n",
      "loss: 0.151354  [48064/60000]\n",
      "loss: 0.096884  [48704/60000]\n",
      "loss: 0.139985  [49344/60000]\n",
      "loss: 0.065914  [49984/60000]\n",
      "loss: 0.076962  [50624/60000]\n",
      "loss: 0.199908  [51264/60000]\n",
      "loss: 0.215541  [51904/60000]\n",
      "loss: 0.180148  [52544/60000]\n",
      "loss: 0.146507  [53184/60000]\n",
      "loss: 0.109717  [53824/60000]\n",
      "loss: 0.076127  [54464/60000]\n",
      "loss: 0.109362  [55104/60000]\n",
      "loss: 0.167824  [55744/60000]\n",
      "loss: 0.155550  [56384/60000]\n",
      "loss: 0.129135  [57024/60000]\n",
      "loss: 0.070356  [57664/60000]\n",
      "loss: 0.201465  [58304/60000]\n",
      "loss: 0.168941  [58944/60000]\n",
      "loss: 0.102871  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.271763 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.061281  [   64/60000]\n",
      "loss: 0.084793  [  704/60000]\n",
      "loss: 0.115084  [ 1344/60000]\n",
      "loss: 0.086497  [ 1984/60000]\n",
      "loss: 0.108386  [ 2624/60000]\n",
      "loss: 0.018412  [ 3264/60000]\n",
      "loss: 0.151633  [ 3904/60000]\n",
      "loss: 0.069777  [ 4544/60000]\n",
      "loss: 0.139681  [ 5184/60000]\n",
      "loss: 0.062472  [ 5824/60000]\n",
      "loss: 0.133660  [ 6464/60000]\n",
      "loss: 0.077155  [ 7104/60000]\n",
      "loss: 0.107365  [ 7744/60000]\n",
      "loss: 0.034438  [ 8384/60000]\n",
      "loss: 0.077902  [ 9024/60000]\n",
      "loss: 0.101769  [ 9664/60000]\n",
      "loss: 0.083159  [10304/60000]\n",
      "loss: 0.038305  [10944/60000]\n",
      "loss: 0.083391  [11584/60000]\n",
      "loss: 0.125203  [12224/60000]\n",
      "loss: 0.164549  [12864/60000]\n",
      "loss: 0.114531  [13504/60000]\n",
      "loss: 0.127648  [14144/60000]\n",
      "loss: 0.087296  [14784/60000]\n",
      "loss: 0.034776  [15424/60000]\n",
      "loss: 0.062315  [16064/60000]\n",
      "loss: 0.146685  [16704/60000]\n",
      "loss: 0.160112  [17344/60000]\n",
      "loss: 0.082878  [17984/60000]\n",
      "loss: 0.151702  [18624/60000]\n",
      "loss: 0.051146  [19264/60000]\n",
      "loss: 0.046794  [19904/60000]\n",
      "loss: 0.091057  [20544/60000]\n",
      "loss: 0.139037  [21184/60000]\n",
      "loss: 0.131988  [21824/60000]\n",
      "loss: 0.121583  [22464/60000]\n",
      "loss: 0.135126  [23104/60000]\n",
      "loss: 0.070700  [23744/60000]\n",
      "loss: 0.022853  [24384/60000]\n",
      "loss: 0.044529  [25024/60000]\n",
      "loss: 0.102493  [25664/60000]\n",
      "loss: 0.227599  [26304/60000]\n",
      "loss: 0.043239  [26944/60000]\n",
      "loss: 0.091697  [27584/60000]\n",
      "loss: 0.070349  [28224/60000]\n",
      "loss: 0.060885  [28864/60000]\n",
      "loss: 0.168054  [29504/60000]\n",
      "loss: 0.122626  [30144/60000]\n",
      "loss: 0.095631  [30784/60000]\n",
      "loss: 0.088597  [31424/60000]\n",
      "loss: 0.064277  [32064/60000]\n",
      "loss: 0.067939  [32704/60000]\n",
      "loss: 0.060411  [33344/60000]\n",
      "loss: 0.058692  [33984/60000]\n",
      "loss: 0.077710  [34624/60000]\n",
      "loss: 0.058729  [35264/60000]\n",
      "loss: 0.224219  [35904/60000]\n",
      "loss: 0.103590  [36544/60000]\n",
      "loss: 0.187777  [37184/60000]\n",
      "loss: 0.045947  [37824/60000]\n",
      "loss: 0.071884  [38464/60000]\n",
      "loss: 0.107732  [39104/60000]\n",
      "loss: 0.091212  [39744/60000]\n",
      "loss: 0.062187  [40384/60000]\n",
      "loss: 0.118237  [41024/60000]\n",
      "loss: 0.149420  [41664/60000]\n",
      "loss: 0.085565  [42304/60000]\n",
      "loss: 0.085129  [42944/60000]\n",
      "loss: 0.184123  [43584/60000]\n",
      "loss: 0.024950  [44224/60000]\n",
      "loss: 0.139898  [44864/60000]\n",
      "loss: 0.071872  [45504/60000]\n",
      "loss: 0.066626  [46144/60000]\n",
      "loss: 0.116179  [46784/60000]\n",
      "loss: 0.134377  [47424/60000]\n",
      "loss: 0.056600  [48064/60000]\n",
      "loss: 0.184892  [48704/60000]\n",
      "loss: 0.081257  [49344/60000]\n",
      "loss: 0.089868  [49984/60000]\n",
      "loss: 0.073536  [50624/60000]\n",
      "loss: 0.021125  [51264/60000]\n",
      "loss: 0.104276  [51904/60000]\n",
      "loss: 0.103596  [52544/60000]\n",
      "loss: 0.283711  [53184/60000]\n",
      "loss: 0.062092  [53824/60000]\n",
      "loss: 0.096716  [54464/60000]\n",
      "loss: 0.169242  [55104/60000]\n",
      "loss: 0.206512  [55744/60000]\n",
      "loss: 0.081780  [56384/60000]\n",
      "loss: 0.211507  [57024/60000]\n",
      "loss: 0.160757  [57664/60000]\n",
      "loss: 0.077956  [58304/60000]\n",
      "loss: 0.145370  [58944/60000]\n",
      "loss: 0.158864  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.272542 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.114436  [   64/60000]\n",
      "loss: 0.131556  [  704/60000]\n",
      "loss: 0.031511  [ 1344/60000]\n",
      "loss: 0.079369  [ 1984/60000]\n",
      "loss: 0.096872  [ 2624/60000]\n",
      "loss: 0.098964  [ 3264/60000]\n",
      "loss: 0.127170  [ 3904/60000]\n",
      "loss: 0.118477  [ 4544/60000]\n",
      "loss: 0.035456  [ 5184/60000]\n",
      "loss: 0.026790  [ 5824/60000]\n",
      "loss: 0.051113  [ 6464/60000]\n",
      "loss: 0.095048  [ 7104/60000]\n",
      "loss: 0.116967  [ 7744/60000]\n",
      "loss: 0.230352  [ 8384/60000]\n",
      "loss: 0.009167  [ 9024/60000]\n",
      "loss: 0.122337  [ 9664/60000]\n",
      "loss: 0.115767  [10304/60000]\n",
      "loss: 0.169988  [10944/60000]\n",
      "loss: 0.039253  [11584/60000]\n",
      "loss: 0.091558  [12224/60000]\n",
      "loss: 0.071364  [12864/60000]\n",
      "loss: 0.092985  [13504/60000]\n",
      "loss: 0.085517  [14144/60000]\n",
      "loss: 0.087544  [14784/60000]\n",
      "loss: 0.048090  [15424/60000]\n",
      "loss: 0.137095  [16064/60000]\n",
      "loss: 0.111823  [16704/60000]\n",
      "loss: 0.064128  [17344/60000]\n",
      "loss: 0.095097  [17984/60000]\n",
      "loss: 0.077764  [18624/60000]\n",
      "loss: 0.042394  [19264/60000]\n",
      "loss: 0.119237  [19904/60000]\n",
      "loss: 0.095361  [20544/60000]\n",
      "loss: 0.149273  [21184/60000]\n",
      "loss: 0.146730  [21824/60000]\n",
      "loss: 0.061336  [22464/60000]\n",
      "loss: 0.120664  [23104/60000]\n",
      "loss: 0.043475  [23744/60000]\n",
      "loss: 0.154461  [24384/60000]\n",
      "loss: 0.084083  [25024/60000]\n",
      "loss: 0.111066  [25664/60000]\n",
      "loss: 0.147519  [26304/60000]\n",
      "loss: 0.134573  [26944/60000]\n",
      "loss: 0.169068  [27584/60000]\n",
      "loss: 0.085588  [28224/60000]\n",
      "loss: 0.125665  [28864/60000]\n",
      "loss: 0.055489  [29504/60000]\n",
      "loss: 0.074018  [30144/60000]\n",
      "loss: 0.054383  [30784/60000]\n",
      "loss: 0.101652  [31424/60000]\n",
      "loss: 0.099525  [32064/60000]\n",
      "loss: 0.131768  [32704/60000]\n",
      "loss: 0.116411  [33344/60000]\n",
      "loss: 0.119340  [33984/60000]\n",
      "loss: 0.167239  [34624/60000]\n",
      "loss: 0.124827  [35264/60000]\n",
      "loss: 0.023106  [35904/60000]\n",
      "loss: 0.059636  [36544/60000]\n",
      "loss: 0.100427  [37184/60000]\n",
      "loss: 0.033661  [37824/60000]\n",
      "loss: 0.057198  [38464/60000]\n",
      "loss: 0.034424  [39104/60000]\n",
      "loss: 0.123748  [39744/60000]\n",
      "loss: 0.064448  [40384/60000]\n",
      "loss: 0.133197  [41024/60000]\n",
      "loss: 0.159960  [41664/60000]\n",
      "loss: 0.142670  [42304/60000]\n",
      "loss: 0.107697  [42944/60000]\n",
      "loss: 0.093988  [43584/60000]\n",
      "loss: 0.046851  [44224/60000]\n",
      "loss: 0.094121  [44864/60000]\n",
      "loss: 0.097413  [45504/60000]\n",
      "loss: 0.210163  [46144/60000]\n",
      "loss: 0.154444  [46784/60000]\n",
      "loss: 0.150395  [47424/60000]\n",
      "loss: 0.209776  [48064/60000]\n",
      "loss: 0.047190  [48704/60000]\n",
      "loss: 0.110710  [49344/60000]\n",
      "loss: 0.057732  [49984/60000]\n",
      "loss: 0.072428  [50624/60000]\n",
      "loss: 0.106714  [51264/60000]\n",
      "loss: 0.045829  [51904/60000]\n",
      "loss: 0.082096  [52544/60000]\n",
      "loss: 0.088485  [53184/60000]\n",
      "loss: 0.044978  [53824/60000]\n",
      "loss: 0.120481  [54464/60000]\n",
      "loss: 0.092576  [55104/60000]\n",
      "loss: 0.065211  [55744/60000]\n",
      "loss: 0.049605  [56384/60000]\n",
      "loss: 0.070301  [57024/60000]\n",
      "loss: 0.073067  [57664/60000]\n",
      "loss: 0.077244  [58304/60000]\n",
      "loss: 0.073859  [58944/60000]\n",
      "loss: 0.039138  [59584/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.281631 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = train_net(model, train_dataloader, test_dataloader,\n",
    "                  epochs=10, learning_rate=1e-4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9fa149-a697-42a6-9cf0-e6c103ffefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Trained_Model_fashionMNIST_resnet18_dropout.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c212e2bb-2dd5-4626-83ff-2cf787b6027c",
   "metadata": {},
   "source": [
    "# Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "LY5DB4EOxA5A",
   "metadata": {
    "id": "LY5DB4EOxA5A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.281631 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from nnhelpers_modified import train_loop, test_loop, train_net\n",
    "\n",
    "X_train, y_train, X_test, y_test = Custom_FashionMNIST_Loader('fashion_dataset')\n",
    "test_dataset = FashionMNISTDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "model = ResNet18().to('cuda')\n",
    "model.load_state_dict(torch.load('Trained_Model_fashionMNIST_resnet18_dropout.pth'))\n",
    "model.eval()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a85114-e86a-453c-96d7-dec658503415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
